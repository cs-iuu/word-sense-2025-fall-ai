{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-iuu/word-sense-2025-fall-ai/blob/main/notebooks/15.2.wsi_niv_cht_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Preprocessing: Extract Common Nouns"
      ],
      "metadata": {
        "id": "OwnCnpqk0M7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy jieba pandas --break-system-packages\n",
        "!python -m spacy download en_core_web_sm\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZDh6BuKL3z-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers numpy pandas --break-system-packages"
      ],
      "metadata": {
        "id": "1uzzTQ5ogE7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn numpy pandas --break-system-packages"
      ],
      "metadata": {
        "id": "SATWTZIEgLXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk scipy matplotlib seaborn pandas numpy --break-system-packages"
      ],
      "metadata": {
        "id": "p8FfnACQgObB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hdbscan"
      ],
      "metadata": {
        "id": "2FohS4GdIdxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 2: Preprocessing\n",
        "======================\n",
        "Tokenizes, POS-tags, and lemmatizes both corpora.\n",
        "Extracts common nouns only (no proper nouns, pronouns, or stopwords).\n",
        "Applies a minimum frequency threshold to filter rare words.\n",
        "\n",
        "Outputs:\n",
        "  - data/english_nouns.csv   : lemma, verse_id, token, context (full verse)\n",
        "  - data/chinese_nouns.csv   : lemma, verse_id, token, context\n",
        "  - data/english_noun_freq.csv\n",
        "  - data/chinese_noun_freq.csv\n",
        "\n",
        "Usage:\n",
        "  pip install spacy jieba pandas --break-system-packages\n",
        "  python -m spacy download en_core_web_sm\n",
        "  python 02_preprocessing.py\n",
        "\n",
        "Design decisions (paper §3.2):\n",
        "  - English: spaCy en_core_web_sm for tokenization, POS, lemmatization\n",
        "  - Chinese: jieba for word segmentation + custom POS (jieba.posseg)\n",
        "  - POS filters: English NOUN tag; Chinese POS prefix 'n' (common noun)\n",
        "  - Proper noun exclusion: English PROPN tag excluded; Chinese 'nr','ns','nt','nz' excluded\n",
        "  - Minimum frequency: MIN_FREQ = 30 (ensures sufficient WSI context)\n",
        "  - Stopwords: NLTK English stopwords; custom Chinese stopword list\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR = Path(\"/content\") / \"bible_data\"\n",
        "MIN_FREQ = 30          # Minimum occurrences per lemma for WSI\n",
        "MAX_CONTEXT_LEN = 512  # Characters — prevents overlong inputs to transformers\n",
        "\n",
        "# Chinese POS tags for common nouns (jieba.posseg notation)\n",
        "ZH_NOUN_PREFIXES = {\"n\"}           # Common noun prefix\n",
        "ZH_EXCLUDE_TAGS  = {\"nr\", \"ns\", \"nt\", \"nz\", \"nw\"}  # Proper nouns to exclude\n",
        "\n",
        "# ── Theological proper noun exclusion lists ───────────────────────────────────\n",
        "# These terms are proper nouns in English (God, Lord, Christ etc.) — excluded\n",
        "# by spaCy's PROPN tag — but are tagged as common nouns n by jieba in Chinese\n",
        "# due to the absence of capitalisation. They must be excluded explicitly from\n",
        "# the Chinese data to ensure cross-lingual comparability.\n",
        "#\n",
        "# English side: spaCy correctly tags God/Lord/Christ as PROPN (excluded).\n",
        "# Exception: \"Spirit\" (Holy Spirit) is sometimes tagged NOUN by spaCy, so it\n",
        "# is added to EN_THEOLOGICAL_EXCLUDE as a lemma-level backstop.\n",
        "#\n",
        "# Borderline cases kept in both languages:\n",
        "#   先知/prophet  — generic occupational noun, polysemous, common in both\n",
        "#   天使/angel    — generic supernatural being, common noun in both\n",
        "#   魔鬼/devil    — common noun in EN; jieba tags n in ZH\n",
        "\n",
        "ZH_THEOLOGICAL_EXCLUDE = {\n",
        "    # Core deity names / titles\n",
        "    \"神\",     # God (most frequent — 1244 occurrences)\n",
        "    \"主\",     # Lord\n",
        "    \"上帝\",   # God (formal)\n",
        "    \"耶和華\", # Yahweh / LORD\n",
        "    \"基督\",   # Christ\n",
        "    \"耶穌\",   # Jesus (also usually tagged nr, but belt-and-suspenders)\n",
        "    \"聖靈\",   # Holy Spirit\n",
        "    \"聖神\",   # Holy Spirit (alternate form in some CUV editions)\n",
        "    \"彌賽亞\", # Messiah\n",
        "    # Adversarial proper nouns\n",
        "    \"撒但\",   # Satan\n",
        "    \"別西卜\", # Beelzebub\n",
        "}\n",
        "\n",
        "EN_THEOLOGICAL_EXCLUDE = {\n",
        "    # Lemma-level backstop for cases where spaCy tags as NOUN not PROPN\n",
        "    \"spirit\",    # \"Holy Spirit\" — spaCy inconsistently tags as NOUN\n",
        "    \"ghost\",     # \"Holy Ghost\" (KJV form; rare in NIV but present)\n",
        "}\n",
        "\n",
        "# KJV-specific: exclude archaic pronouns/verbs mis-tagged as nouns\n",
        "KJV_ARCHAIC_EXCLUDE = {\n",
        "    # Archaic pronouns\n",
        "    \"thou\",       # 1853\n",
        "    \"ye\",         # 1382\n",
        "    \"thee\",       # 926\n",
        "    \"thine\",      # 645\n",
        "    \"thy\",        # 1\n",
        "\n",
        "    # Archaic verbs\n",
        "    \"shalt\",      # 1582\n",
        "    \"hath\",       # 497\n",
        "    \"art\",        # 482\n",
        "    \"hast\",       # 377\n",
        "    \"wilt\",       # 204\n",
        "    \"begat\",      # 161\n",
        "    \"goeth\",      # 78\n",
        "    \"doth\",       # 67\n",
        "    \"endureth\",   # 58\n",
        "    \"cometh\",     # 55\n",
        "    \"mayest\",     # 55\n",
        "    \"dwelleth\",   # 47\n",
        "    \"liveth\",     # 43\n",
        "    \"didst\",      # 39\n",
        "    \"remaineth\",  # 32\n",
        "    \"walketh\",    # 29\n",
        "    \"goest\",      # 28\n",
        "    \"passeth\",    # 28\n",
        "    \"knoweth\",    # 27\n",
        "    \"speaketh\",   # 22\n",
        "    \"saidst\",     # 20\n",
        "    \"saith\",      # 20\n",
        "    \"eateth\",     # 19\n",
        "    \"belongeth\",  # 17\n",
        "    \"beareth\",    # 15\n",
        "    \"turneth\",    # 15\n",
        "    \"bringeth\",   # 14\n",
        "    \"reacheth\",   # 13\n",
        "    \"seemeth\",    # 13\n",
        "    \"putteth\",    # 13\n",
        "    \"burneth\",    # 12\n",
        "    \"spreadeth\",  # 12\n",
        "    \"calleth\",    # 12\n",
        "    \"mourneth\",   # 11\n",
        "    \"sweareth\",   # 10\n",
        "    \"doest\",      # 10\n",
        "    \"committeth\", # 10\n",
        "    \"sitteth\",    # 10\n",
        "    \"seeth\",      # 10\n",
        "    \"crieth\",     # 10\n",
        "    \"seeketh\",    # 9\n",
        "    \"toucheth\",   # 9\n",
        "    \"perisheth\",  # 9\n",
        "    \"seeketh\",    # 9\n",
        "    \"groweth\",    # 9\n",
        "    \"reigneth\",   # 9\n",
        "    \"dieth\",      # 9\n",
        "    \"appeareth\",  # 9\n",
        "    \"waiteth\",    # 9\n",
        "    \"abideth\",    # 8\n",
        "    \"judgeth\",    # 8\n",
        "    \"languisheth\",# 8\n",
        "    \"delighteth\", # 8\n",
        "    \"faileth\",    # 8\n",
        "    \"causeth\",    # 8\n",
        "    \"standeth\",   # 7\n",
        "    \"spake\",      # 7\n",
        "    \"runneth\",    # 7\n",
        "    \"aileth\",     # 7\n",
        "    \"withereth\",  # 6\n",
        "    \"falleth\",    # 6\n",
        "    \"looketh\",    # 6\n",
        "    \"hideth\",     # 6\n",
        "    \"keepeth\",    # 6\n",
        "    \"soweth\",     # 6\n",
        "    \"desireth\",   # 6\n",
        "    \"fleeth\",     # 6\n",
        "    \"understandeth\",# 6\n",
        "    \"trustest\",   # 6\n",
        "    \"treadeth\",   # 5\n",
        "    \"reproacheth\",# 5\n",
        "    \"delivereth\", # 5\n",
        "    \"commandeth\", # 5\n",
        "    \"pertaineth\", # 5\n",
        "    \"shineth\",    # 5\n",
        "    \"taketh\",     # 5\n",
        "    \"fadeth\",     # 5\n",
        "    \"ariseth\",    # 5\n",
        "    \"answereth\",  # 4\n",
        "    \"availeth\",   # 4\n",
        "    \"escapeth\",   # 4\n",
        "    \"trusteth\",   # 4\n",
        "    \"travaileth\", # 4\n",
        "    \"troubleth\",  # 4\n",
        "    \"melteth\",    # 4\n",
        "    \"proceedeth\", # 4\n",
        "    \"maketh\",     # 4\n",
        "    \"destroyeth\", # 4\n",
        "    \"devoureth\",  # 4\n",
        "    \"riseth\",     # 4\n",
        "    \"heareth\",    # 4\n",
        "    \"sheweth\",    # 4\n",
        "    \"sinneth\",    # 4\n",
        "    \"followeth\",  # 4\n",
        "    \"moveth\",     # 4\n",
        "    \"longeth\",    # 4\n",
        "    \"pisseth\",    # 3\n",
        "    \"trustedst\",  # 3\n",
        "    \"stirreth\",   # 3\n",
        "    \"stoodest\",   # 3\n",
        "    \"careth\",     # 3\n",
        "    \"hatest\",     # 3\n",
        "    \"roareth\",    # 3\n",
        "    \"sacrificeth\",# 3\n",
        "    \"ruleth\",     # 3\n",
        "    \"dealeth\",    # 3\n",
        "    \"decayeth\",   # 3\n",
        "    \"serveth\",    # 3\n",
        "    \"calledst\",   # 3\n",
        "    \"teacheth\",   # 3\n",
        "    \"rewardeth\",  # 3\n",
        "    \"deliveredst\",# 3\n",
        "    \"meaneth\",    # 3\n",
        "    \"gathereth\",  # 3\n",
        "    \"strengtheneth\",# 3\n",
        "    \"camest\",     # 3\n",
        "    \"breaketh\",   # 3\n",
        "    \"bewrayeth\",  # 3\n",
        "    \"dwellest\",   # 3\n",
        "    \"offereth\",   # 3\n",
        "    \"mocketh\",    # 3\n",
        "    \"spakest\",    # 3\n",
        "    \"sojourneth\", # 3\n",
        "    \"increaseth\", # 2\n",
        "    \"withholdeth\",# 2\n",
        "    \"witnesseth\", # 2\n",
        "    \"baptizeth\",  # 2\n",
        "    \"fighteth\",   # 2\n",
        "    \"blesseth\",   # 2\n",
        "    \"trieth\",     # 2\n",
        "    \"trembleth\",  # 2\n",
        "    \"kindleth\",   # 2\n",
        "    \"boasteth\",   # 2\n",
        "    ## skipped\n",
        "    \"shouldest\",  # 1\n",
        "    \"wouldest\",   # 0\n",
        "    \"couldest\",   # 0\n",
        "\n",
        "    # Other archaic words\n",
        "    \"nigh\",       # 81\n",
        "}\n",
        "\n",
        "# Path to custom jieba dictionary for biblical proper names\n",
        "JIEBA_DICT_PATH = Path(\"/content\") / \"bible_data\" / \"jieba_biblical_dict.txt\"\n",
        "\n",
        "# ── Post-segmentation POS correction ─────────────────────────────────────────\n",
        "# jieba's POS tagger runs independently of the segmentation dictionary and\n",
        "# can assign incorrect tags even for dictionary entries. These words are\n",
        "# forced to tag n after segmentation regardless of what the POS tagger assigned.\n",
        "#\n",
        "# 地: jieba assigns uv (虛詞/copular particle) in classical subject-predicate\n",
        "#     constructions like 地是空虛混沌 (Gen.1.2) because it parses 地 as a\n",
        "#     topic marker rather than a subject noun. This is a known jieba limitation\n",
        "#     with literary Chinese. Since English \"earth\" (freq=739) is always tagged\n",
        "#     NOUN by spaCy, forcing 地 to n is required for cross-lingual comparability.\n",
        "ZH_FORCE_NOUN_TAG = {\n",
        "    \"地\",   # earth/ground/land — incorrectly tagged uv in copular constructions\n",
        "}\n",
        "\n",
        "# ─── English Preprocessing ────────────────────────────────────────────────────\n",
        "\n",
        "\n",
        "def preprocess_english(verse_csv: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Process English verses with spaCy.\n",
        "    Returns long-format DataFrame: one row per noun occurrence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import spacy\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Run: pip install spacy --break-system-packages && python -m spacy download en_core_web_sm\")\n",
        "\n",
        "    print(\"  [EN] Loading spaCy model…\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"textcat\"])\n",
        "\n",
        "    df = pd.read_csv(verse_csv)\n",
        "    print(f\"  [EN] Processing {len(df):,} verses…\")\n",
        "\n",
        "    import time\n",
        "    records   = []\n",
        "    texts     = df[\"text\"].tolist()\n",
        "    verse_ids = df[\"verse_id\"].tolist()\n",
        "    total     = len(texts)\n",
        "    t0        = time.time()\n",
        "\n",
        "    for i, (doc, vid) in enumerate(zip(nlp.pipe(texts, batch_size=512), verse_ids), 1):\n",
        "        context = doc.text[:MAX_CONTEXT_LEN]\n",
        "        for token in doc:\n",
        "            # Keep only common nouns; exclude proper nouns and pronouns\n",
        "            if (\n",
        "                token.pos_ == \"NOUN\"\n",
        "                and not token.is_stop\n",
        "                and not token.is_punct\n",
        "                and len(token.lemma_) > 1\n",
        "                and token.lemma_.isalpha()\n",
        "                and token.lemma_.lower() not in EN_THEOLOGICAL_EXCLUDE\n",
        "                ## for KJV processing-only\n",
        "                and token.lemma_.lower() not in KJV_ARCHAIC_EXCLUDE\n",
        "            ):\n",
        "                records.append({\n",
        "                    \"verse_id\": vid,\n",
        "                    \"token\":    token.text,\n",
        "                    \"lemma\":    token.lemma_.lower(),\n",
        "                    \"context\":  context,\n",
        "                })\n",
        "        if i % 1000 == 0 or i == total:\n",
        "            elapsed = time.time() - t0\n",
        "            rate    = i / elapsed if elapsed > 0 else 0\n",
        "            eta_min = (total - i) / rate / 60 if rate > 0 else 0\n",
        "            print(f\"    … {i:,}/{total:,} verses  \"\n",
        "                  f\"({rate:.0f} v/s)  \"\n",
        "                  f\"ETA {eta_min:.1f} min  \"\n",
        "                  f\"nouns so far: {len(records):,}\",\n",
        "                  end=\"\\r\")\n",
        "\n",
        "    elapsed_total = time.time() - t0\n",
        "    print(f\"\\n  [EN] Done in {elapsed_total/60:.1f} min. \"\n",
        "          f\"Extracted {len(records):,} noun occurrences.\")\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "# ─── Chinese Preprocessing ────────────────────────────────────────────────────\n",
        "\n",
        "\n",
        "def preprocess_chinese(verse_csv: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Process Chinese verses with jieba (word segmentation + POS tagging).\n",
        "    Returns long-format DataFrame: one row per noun occurrence.\n",
        "    \"\"\"\n",
        "    import time\n",
        "    try:\n",
        "        import jieba\n",
        "        import jieba.posseg as pseg\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Run: pip install jieba --break-system-packages\")\n",
        "\n",
        "    # Silence jieba logging FIRST, before any other jieba calls\n",
        "    jieba.setLogLevel(\"ERROR\")\n",
        "\n",
        "    # Load custom dictionary\n",
        "    if JIEBA_DICT_PATH.exists():\n",
        "        jieba.load_userdict(str(JIEBA_DICT_PATH))\n",
        "        print(f\"  [ZH] Loaded custom dictionary: {JIEBA_DICT_PATH.name}\", flush=True)\n",
        "    else:\n",
        "        print(f\"  [ZH] WARNING: custom dictionary not found at {JIEBA_DICT_PATH}\", flush=True)\n",
        "\n",
        "    # Force jieba to build its internal trie NOW with a visible message.\n",
        "    # Without this explicit call, the first pseg.cut() silently blocks\n",
        "    # for 30-60 seconds before any progress lines appear.\n",
        "    print(\"  [ZH] Building jieba model (one-time, ~10-30s)...\", flush=True)\n",
        "    jieba.initialize()\n",
        "    print(\"  [ZH] Model ready.\", flush=True)\n",
        "\n",
        "    zh_stopwords = _load_chinese_stopwords()\n",
        "\n",
        "    df    = pd.read_csv(verse_csv)\n",
        "    total = len(df)\n",
        "    print(f\"  [ZH] Processing {total:,} verses...\", flush=True)\n",
        "    t0 = time.time()\n",
        "\n",
        "    records = []\n",
        "    for i, row in enumerate(df.itertuples(index=False), 1):\n",
        "        verse_id = row.verse_id\n",
        "        text     = str(row.text)\n",
        "        context  = text[:MAX_CONTEXT_LEN]\n",
        "\n",
        "        for word, flag in pseg.cut(text):\n",
        "            flag_str = str(flag)\n",
        "            # Force known mis-tagged tokens to correct POS\n",
        "            if word in ZH_FORCE_NOUN_TAG:\n",
        "                flag_str = \"n\"\n",
        "            if (\n",
        "                flag_str[:1] in ZH_NOUN_PREFIXES\n",
        "                and flag_str not in ZH_EXCLUDE_TAGS\n",
        "                and word not in zh_stopwords\n",
        "                and word not in ZH_THEOLOGICAL_EXCLUDE\n",
        "                and len(word) >= 1\n",
        "                and not word.isdigit()\n",
        "            ):\n",
        "                records.append({\n",
        "                    \"verse_id\": verse_id,\n",
        "                    \"token\":    word,\n",
        "                    \"lemma\":    word,\n",
        "                    \"context\":  context,\n",
        "                })\n",
        "\n",
        "        # Progress every 100 verses — print on new lines so nothing is missed\n",
        "        if i % 100 == 0 or i == total:\n",
        "            elapsed = time.time() - t0\n",
        "            rate    = i / elapsed if elapsed > 0 else 0\n",
        "            eta_min = (total - i) / rate / 60 if rate > 0 else 0\n",
        "            print(\n",
        "                f\"    ... {i:,}/{total:,} verses\"\n",
        "                f\"  ({rate:.0f} v/s)\"\n",
        "                f\"  ETA {eta_min:.1f} min\"\n",
        "                f\"  nouns: {len(records):,}\",\n",
        "                flush=True\n",
        "            )\n",
        "\n",
        "    elapsed_total = time.time() - t0\n",
        "    print(f\"  [ZH] Done in {elapsed_total/60:.1f} min. \"\n",
        "          f\"Extracted {len(records):,} noun occurrences.\")\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "def _load_chinese_stopwords() -> set:\n",
        "    \"\"\"\n",
        "    Chinese function word stoplist for CUV Traditional (CHT) text.\n",
        "\n",
        "    Design decisions:\n",
        "    ─────────────────────────────────────────────────────────────\n",
        "    1. CHT variants included alongside CHS equivalents for all\n",
        "       characters that differ between scripts (說/说, 會/会, etc.)\n",
        "\n",
        "    2. 人 is NOT a stopword. It is a genuine common noun meaning\n",
        "       \"person / people / man / humanity\" and is highly polysemous\n",
        "       in biblical text. Jieba tags it as n (common noun) in most\n",
        "       contexts, so it passes the POS filter correctly. Removing it\n",
        "       would discard one of the most semantically rich words in the\n",
        "       corpus.\n",
        "\n",
        "    3. Pronouns (他/她/祂/你/我 etc.) are NOT listed here. They are\n",
        "       tagged by jieba as r (pronoun), which is already excluded by\n",
        "       the POS filter (we keep only n* tags). Listing them would be\n",
        "       redundant. The various gendered and honorific variants\n",
        "       (他/她/它/祂) all carry the r tag and are excluded uniformly.\n",
        "\n",
        "    4. This list covers only high-frequency grammatical function\n",
        "       words that jieba may occasionally mis-tag as nouns.\n",
        "       It is intentionally conservative.\n",
        "    ─────────────────────────────────────────────────────────────\n",
        "    \"\"\"\n",
        "    return {\n",
        "        # Structural particles (occasionally mis-tagged as n by jieba)\n",
        "        # NOTE: 地 is intentionally NOT listed here.\n",
        "        # In CUV literary style, 地 is overwhelmingly used as a noun\n",
        "        # (earth/land/ground) matching English \"earth\" (freq=739).\n",
        "        # The adverbial particle use of 地 is rare in classical biblical text.\n",
        "        # Removing it would create an asymmetry with English where \"earth\"\n",
        "        # is correctly retained as a high-frequency common noun.\n",
        "        \"的\", \"得\",\n",
        "        # Aspect markers — CHT: 著, CHS: 着\n",
        "        \"了\", \"著\", \"着\",\n",
        "        # Conjunctions / connectives\n",
        "        \"和\", \"與\", \"与\", \"及\", \"或\", \"但\", \"而\", \"且\",\n",
        "        # Adverbs sometimes mis-tagged\n",
        "        \"也\", \"都\", \"就\", \"才\", \"又\", \"還\", \"还\", \"已\",\n",
        "        \"很\", \"更\", \"最\", \"太\", \"非常\",\n",
        "        # Negation\n",
        "        \"不\", \"沒有\", \"没有\", \"未\", \"無\", \"无\",\n",
        "        # Existential / copular\n",
        "        \"是\", \"有\", \"在\",\n",
        "        # Determiners / quantifiers\n",
        "        \"一\", \"這\", \"这\", \"那\", \"各\", \"每\", \"某\", \"其\",\n",
        "        # Directional / locative words with no sense variation\n",
        "        \"上\", \"下\", \"中\", \"內\", \"内\", \"外\", \"前\", \"後\", \"后\",\n",
        "        \"裡\", \"里\", \"間\", \"间\",\n",
        "        # Common verbs jieba occasionally tags as nouns in CUV\n",
        "        \"說\", \"说\", \"看\", \"去\", \"來\", \"来\", \"到\", \"給\", \"给\",\n",
        "        \"要\", \"會\", \"会\",\n",
        "    }\n",
        "\n",
        "\n",
        "# ─── Frequency Filtering ──────────────────────────────────────────────────────\n",
        "\n",
        "\n",
        "def apply_frequency_filter(df: pd.DataFrame, min_freq: int = MIN_FREQ) -> tuple:\n",
        "    \"\"\"\n",
        "    Keep only lemmas appearing at least `min_freq` times.\n",
        "    Returns (filtered_df, freq_df).\n",
        "    \"\"\"\n",
        "    freq = df.groupby(\"lemma\").size().reset_index(name=\"count\")\n",
        "    freq = freq.sort_values(\"count\", ascending=False)\n",
        "    valid_lemmas = set(freq[freq[\"count\"] >= min_freq][\"lemma\"])\n",
        "    filtered = df[df[\"lemma\"].isin(valid_lemmas)].copy()\n",
        "    return filtered, freq"
      ],
      "metadata": {
        "id": "iApWnLav0Ltb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Step 2: Preprocessing\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ── English ───────────────────────────────────────────────────\n",
        "# en_raw = preprocess_english(DATA_DIR / \"english_verses.csv\")\n",
        "# en_filtered, en_freq = apply_frequency_filter(en_raw)\n",
        "# en_filtered.to_csv(DATA_DIR / \"english_nouns.csv\", index=False, encoding=\"utf-8\")\n",
        "# en_freq.to_csv(DATA_DIR / \"english_noun_freq.csv\", index=False, encoding=\"utf-8\")\n",
        "# print(f\"  [EN] {en_filtered['lemma'].nunique():,} lemmas ≥ {MIN_FREQ} occurrences retained.\")\n",
        "\n",
        "# ── Chinese ───────────────────────────────────────────────────\n",
        "zh_raw = preprocess_chinese(DATA_DIR / \"chinese_verses.csv\")\n",
        "zh_filtered, zh_freq = apply_frequency_filter(zh_raw)\n",
        "zh_filtered.to_csv(DATA_DIR / \"chinese_nouns.csv\", index=False, encoding=\"utf-8\")\n",
        "zh_freq.to_csv(DATA_DIR / \"chinese_noun_freq.csv\", index=False, encoding=\"utf-8\")\n",
        "print(f\"  [ZH] {zh_filtered['lemma'].nunique():,} lemmas ≥ {MIN_FREQ} occurrences retained.\")\n",
        "\n",
        "# ── Summary ───────────────────────────────────────────────────\n",
        "print(\"\\n── Preprocessing Summary ──\")\n",
        "# print(f\"  EN noun tokens (filtered) : {len(en_filtered):,}\")\n",
        "# print(f\"  EN unique lemmas          : {en_filtered['lemma'].nunique():,}\")\n",
        "print(f\"  ZH noun tokens (filtered) : {len(zh_filtered):,}\")\n",
        "print(f\"  ZH unique lemmas          : {zh_filtered['lemma'].nunique():,}\")\n",
        "\n",
        "# print(\"\\n  Top 10 English nouns:\")\n",
        "# print(en_freq.head(10).to_string(index=False))\n",
        "print(\"\\n  Top 10 Chinese nouns:\")\n",
        "print(zh_freq.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\n✓ Step 2 complete.\\n\")"
      ],
      "metadata": {
        "id": "ldNNKu9q0emn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26aad815-6006-4ae1-f474-b4b6ac2ff4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Step 2: Preprocessing\n",
            "============================================================\n",
            "  [ZH] WARNING: custom dictionary not found at /content/bible_data/jieba_biblical_dict.txt\n",
            "  [ZH] Building jieba model (one-time, ~10-30s)...\n",
            "  [ZH] Model ready.\n",
            "  [ZH] Processing 31,027 verses...\n",
            "    ... 100/31,027 verses  (41 v/s)  ETA 12.5 min  nouns: 359\n",
            "    ... 200/31,027 verses  (46 v/s)  ETA 11.2 min  nouns: 652\n",
            "    ... 300/31,027 verses  (49 v/s)  ETA 10.5 min  nouns: 937\n",
            "    ... 400/31,027 verses  (45 v/s)  ETA 11.4 min  nouns: 1,241\n",
            "    ... 500/31,027 verses  (41 v/s)  ETA 12.3 min  nouns: 1,550\n",
            "    ... 600/31,027 verses  (42 v/s)  ETA 12.0 min  nouns: 1,862\n",
            "    ... 700/31,027 verses  (42 v/s)  ETA 12.0 min  nouns: 2,221\n",
            "    ... 800/31,027 verses  (43 v/s)  ETA 11.8 min  nouns: 2,524\n",
            "    ... 900/31,027 verses  (43 v/s)  ETA 11.6 min  nouns: 2,858\n",
            "    ... 1,000/31,027 verses  (44 v/s)  ETA 11.5 min  nouns: 3,167\n",
            "    ... 1,100/31,027 verses  (44 v/s)  ETA 11.3 min  nouns: 3,496\n",
            "    ... 1,200/31,027 verses  (44 v/s)  ETA 11.4 min  nouns: 3,808\n",
            "    ... 1,300/31,027 verses  (42 v/s)  ETA 11.7 min  nouns: 4,081\n",
            "    ... 1,400/31,027 verses  (42 v/s)  ETA 11.8 min  nouns: 4,392\n",
            "    ... 1,500/31,027 verses  (42 v/s)  ETA 11.7 min  nouns: 4,763\n",
            "    ... 1,600/31,027 verses  (42 v/s)  ETA 11.7 min  nouns: 5,080\n",
            "    ... 1,700/31,027 verses  (42 v/s)  ETA 11.6 min  nouns: 5,364\n",
            "    ... 1,800/31,027 verses  (42 v/s)  ETA 11.6 min  nouns: 5,726\n",
            "    ... 1,900/31,027 verses  (41 v/s)  ETA 11.7 min  nouns: 6,072\n",
            "    ... 2,000/31,027 verses  (41 v/s)  ETA 11.8 min  nouns: 6,369\n",
            "    ... 2,100/31,027 verses  (41 v/s)  ETA 11.7 min  nouns: 6,639\n",
            "    ... 2,200/31,027 verses  (41 v/s)  ETA 11.7 min  nouns: 6,968\n",
            "    ... 2,300/31,027 verses  (41 v/s)  ETA 11.6 min  nouns: 7,437\n",
            "    ... 2,400/31,027 verses  (41 v/s)  ETA 11.7 min  nouns: 7,901\n",
            "    ... 2,500/31,027 verses  (41 v/s)  ETA 11.7 min  nouns: 8,237\n",
            "    ... 2,600/31,027 verses  (41 v/s)  ETA 11.7 min  nouns: 8,665\n",
            "    ... 2,700/31,027 verses  (40 v/s)  ETA 11.7 min  nouns: 9,195\n",
            "    ... 2,800/31,027 verses  (41 v/s)  ETA 11.6 min  nouns: 9,629\n",
            "    ... 2,900/31,027 verses  (40 v/s)  ETA 11.6 min  nouns: 10,066\n",
            "    ... 3,000/31,027 verses  (40 v/s)  ETA 11.6 min  nouns: 10,437\n",
            "    ... 3,100/31,027 verses  (40 v/s)  ETA 11.7 min  nouns: 10,855\n",
            "    ... 3,200/31,027 verses  (39 v/s)  ETA 11.7 min  nouns: 11,284\n",
            "    ... 3,300/31,027 verses  (39 v/s)  ETA 11.7 min  nouns: 11,672\n",
            "    ... 3,400/31,027 verses  (39 v/s)  ETA 11.7 min  nouns: 12,040\n",
            "    ... 3,500/31,027 verses  (39 v/s)  ETA 11.7 min  nouns: 12,349\n",
            "    ... 3,600/31,027 verses  (39 v/s)  ETA 11.7 min  nouns: 12,710\n",
            "    ... 3,700/31,027 verses  (39 v/s)  ETA 11.5 min  nouns: 13,055\n",
            "    ... 3,800/31,027 verses  (40 v/s)  ETA 11.5 min  nouns: 13,485\n",
            "    ... 3,900/31,027 verses  (39 v/s)  ETA 11.5 min  nouns: 13,916\n",
            "    ... 4,000/31,027 verses  (39 v/s)  ETA 11.5 min  nouns: 14,281\n",
            "    ... 4,100/31,027 verses  (39 v/s)  ETA 11.5 min  nouns: 14,584\n",
            "    ... 4,200/31,027 verses  (39 v/s)  ETA 11.6 min  nouns: 14,860\n",
            "    ... 4,300/31,027 verses  (38 v/s)  ETA 11.6 min  nouns: 15,242\n",
            "    ... 4,400/31,027 verses  (38 v/s)  ETA 11.6 min  nouns: 15,599\n",
            "    ... 4,500/31,027 verses  (38 v/s)  ETA 11.5 min  nouns: 15,896\n",
            "    ... 4,600/31,027 verses  (38 v/s)  ETA 11.5 min  nouns: 16,229\n",
            "    ... 4,700/31,027 verses  (38 v/s)  ETA 11.5 min  nouns: 16,598\n",
            "    ... 4,800/31,027 verses  (38 v/s)  ETA 11.4 min  nouns: 16,849\n",
            "    ... 4,900/31,027 verses  (38 v/s)  ETA 11.3 min  nouns: 17,208\n",
            "    ... 5,000/31,027 verses  (38 v/s)  ETA 11.4 min  nouns: 17,555\n",
            "    ... 5,100/31,027 verses  (38 v/s)  ETA 11.3 min  nouns: 17,845\n",
            "    ... 5,200/31,027 verses  (38 v/s)  ETA 11.3 min  nouns: 18,118\n",
            "    ... 5,300/31,027 verses  (38 v/s)  ETA 11.3 min  nouns: 18,423\n",
            "    ... 5,400/31,027 verses  (38 v/s)  ETA 11.3 min  nouns: 18,794\n",
            "    ... 5,500/31,027 verses  (38 v/s)  ETA 11.3 min  nouns: 19,166\n",
            "    ... 5,600/31,027 verses  (38 v/s)  ETA 11.2 min  nouns: 19,505\n",
            "    ... 5,700/31,027 verses  (38 v/s)  ETA 11.2 min  nouns: 19,822\n",
            "    ... 5,800/31,027 verses  (38 v/s)  ETA 11.2 min  nouns: 20,167\n",
            "    ... 5,900/31,027 verses  (37 v/s)  ETA 11.2 min  nouns: 20,541\n",
            "    ... 6,000/31,027 verses  (37 v/s)  ETA 11.2 min  nouns: 20,964\n",
            "    ... 6,100/31,027 verses  (37 v/s)  ETA 11.2 min  nouns: 21,344\n",
            "    ... 6,200/31,027 verses  (37 v/s)  ETA 11.1 min  nouns: 21,728\n",
            "    ... 6,300/31,027 verses  (37 v/s)  ETA 11.0 min  nouns: 22,067\n",
            "    ... 6,400/31,027 verses  (38 v/s)  ETA 10.9 min  nouns: 22,531\n",
            "    ... 6,500/31,027 verses  (37 v/s)  ETA 11.0 min  nouns: 22,941\n",
            "    ... 6,600/31,027 verses  (37 v/s)  ETA 10.9 min  nouns: 23,306\n",
            "    ... 6,700/31,027 verses  (37 v/s)  ETA 10.9 min  nouns: 23,738\n",
            "    ... 6,800/31,027 verses  (37 v/s)  ETA 10.9 min  nouns: 24,156\n",
            "    ... 6,900/31,027 verses  (37 v/s)  ETA 10.9 min  nouns: 24,569\n",
            "    ... 7,000/31,027 verses  (37 v/s)  ETA 10.9 min  nouns: 24,965\n",
            "    ... 7,100/31,027 verses  (37 v/s)  ETA 10.8 min  nouns: 25,386\n",
            "    ... 7,200/31,027 verses  (37 v/s)  ETA 10.8 min  nouns: 25,689\n",
            "    ... 7,300/31,027 verses  (37 v/s)  ETA 10.8 min  nouns: 26,059\n",
            "    ... 7,400/31,027 verses  (37 v/s)  ETA 10.8 min  nouns: 26,435\n",
            "    ... 7,500/31,027 verses  (36 v/s)  ETA 10.8 min  nouns: 26,725\n",
            "    ... 7,600/31,027 verses  (36 v/s)  ETA 10.7 min  nouns: 27,057\n",
            "    ... 7,700/31,027 verses  (36 v/s)  ETA 10.7 min  nouns: 27,384\n",
            "    ... 7,800/31,027 verses  (36 v/s)  ETA 10.6 min  nouns: 27,724\n",
            "    ... 7,900/31,027 verses  (36 v/s)  ETA 10.6 min  nouns: 28,044\n",
            "    ... 8,000/31,027 verses  (36 v/s)  ETA 10.6 min  nouns: 28,386\n",
            "    ... 8,100/31,027 verses  (36 v/s)  ETA 10.5 min  nouns: 28,764\n",
            "    ... 8,200/31,027 verses  (36 v/s)  ETA 10.5 min  nouns: 29,077\n",
            "    ... 8,300/31,027 verses  (36 v/s)  ETA 10.4 min  nouns: 29,456\n",
            "    ... 8,400/31,027 verses  (36 v/s)  ETA 10.4 min  nouns: 29,774\n",
            "    ... 8,500/31,027 verses  (36 v/s)  ETA 10.4 min  nouns: 30,133\n",
            "    ... 8,600/31,027 verses  (36 v/s)  ETA 10.4 min  nouns: 30,512\n",
            "    ... 8,700/31,027 verses  (36 v/s)  ETA 10.3 min  nouns: 30,837\n",
            "    ... 8,800/31,027 verses  (36 v/s)  ETA 10.2 min  nouns: 31,164\n",
            "    ... 8,900/31,027 verses  (36 v/s)  ETA 10.2 min  nouns: 31,561\n",
            "    ... 9,000/31,027 verses  (36 v/s)  ETA 10.1 min  nouns: 31,972\n",
            "    ... 9,100/31,027 verses  (36 v/s)  ETA 10.1 min  nouns: 32,325\n",
            "    ... 9,200/31,027 verses  (36 v/s)  ETA 10.1 min  nouns: 32,737\n",
            "    ... 9,300/31,027 verses  (36 v/s)  ETA 10.0 min  nouns: 33,096\n",
            "    ... 9,400/31,027 verses  (36 v/s)  ETA 10.0 min  nouns: 33,442\n",
            "    ... 9,500/31,027 verses  (36 v/s)  ETA 9.9 min  nouns: 33,765\n",
            "    ... 9,600/31,027 verses  (36 v/s)  ETA 9.9 min  nouns: 34,119\n",
            "    ... 9,700/31,027 verses  (36 v/s)  ETA 9.9 min  nouns: 34,548\n",
            "    ... 9,800/31,027 verses  (36 v/s)  ETA 9.8 min  nouns: 34,928\n",
            "    ... 9,900/31,027 verses  (36 v/s)  ETA 9.8 min  nouns: 35,356\n",
            "    ... 10,000/31,027 verses  (36 v/s)  ETA 9.7 min  nouns: 35,705\n",
            "    ... 10,100/31,027 verses  (36 v/s)  ETA 9.7 min  nouns: 36,055\n",
            "    ... 10,200/31,027 verses  (36 v/s)  ETA 9.7 min  nouns: 36,480\n",
            "    ... 10,300/31,027 verses  (36 v/s)  ETA 9.6 min  nouns: 36,802\n",
            "    ... 10,400/31,027 verses  (36 v/s)  ETA 9.5 min  nouns: 37,162\n",
            "    ... 10,500/31,027 verses  (36 v/s)  ETA 9.4 min  nouns: 37,599\n",
            "    ... 10,600/31,027 verses  (36 v/s)  ETA 9.3 min  nouns: 37,998\n",
            "    ... 10,700/31,027 verses  (37 v/s)  ETA 9.3 min  nouns: 38,360\n",
            "    ... 10,800/31,027 verses  (37 v/s)  ETA 9.2 min  nouns: 38,703\n",
            "    ... 10,900/31,027 verses  (36 v/s)  ETA 9.2 min  nouns: 39,057\n",
            "    ... 11,000/31,027 verses  (37 v/s)  ETA 9.1 min  nouns: 39,406\n",
            "    ... 11,100/31,027 verses  (37 v/s)  ETA 9.1 min  nouns: 39,843\n",
            "    ... 11,200/31,027 verses  (37 v/s)  ETA 9.0 min  nouns: 40,313\n",
            "    ... 11,300/31,027 verses  (37 v/s)  ETA 9.0 min  nouns: 40,742\n",
            "    ... 11,400/31,027 verses  (37 v/s)  ETA 9.0 min  nouns: 41,099\n",
            "    ... 11,500/31,027 verses  (37 v/s)  ETA 8.9 min  nouns: 41,435\n",
            "    ... 11,600/31,027 verses  (36 v/s)  ETA 8.9 min  nouns: 41,758\n",
            "    ... 11,700/31,027 verses  (36 v/s)  ETA 8.9 min  nouns: 42,231\n",
            "    ... 11,800/31,027 verses  (36 v/s)  ETA 8.8 min  nouns: 42,650\n",
            "    ... 11,900/31,027 verses  (36 v/s)  ETA 8.8 min  nouns: 43,046\n",
            "    ... 12,000/31,027 verses  (36 v/s)  ETA 8.7 min  nouns: 43,473\n",
            "    ... 12,100/31,027 verses  (36 v/s)  ETA 8.7 min  nouns: 43,835\n",
            "    ... 12,200/31,027 verses  (36 v/s)  ETA 8.6 min  nouns: 44,269\n",
            "    ... 12,300/31,027 verses  (36 v/s)  ETA 8.6 min  nouns: 44,673\n",
            "    ... 12,400/31,027 verses  (36 v/s)  ETA 8.5 min  nouns: 45,092\n",
            "    ... 12,500/31,027 verses  (36 v/s)  ETA 8.5 min  nouns: 45,462\n",
            "    ... 12,600/31,027 verses  (36 v/s)  ETA 8.4 min  nouns: 45,823\n",
            "    ... 12,700/31,027 verses  (36 v/s)  ETA 8.4 min  nouns: 46,269\n",
            "    ... 12,800/31,027 verses  (36 v/s)  ETA 8.3 min  nouns: 46,656\n",
            "    ... 12,900/31,027 verses  (36 v/s)  ETA 8.3 min  nouns: 46,982\n",
            "    ... 13,000/31,027 verses  (37 v/s)  ETA 8.2 min  nouns: 47,224\n",
            "    ... 13,100/31,027 verses  (37 v/s)  ETA 8.2 min  nouns: 47,427\n",
            "    ... 13,200/31,027 verses  (37 v/s)  ETA 8.1 min  nouns: 47,647\n",
            "    ... 13,300/31,027 verses  (37 v/s)  ETA 8.0 min  nouns: 47,853\n",
            "    ... 13,400/31,027 verses  (37 v/s)  ETA 8.0 min  nouns: 48,060\n",
            "    ... 13,500/31,027 verses  (37 v/s)  ETA 7.9 min  nouns: 48,315\n",
            "    ... 13,600/31,027 verses  (37 v/s)  ETA 7.8 min  nouns: 48,560\n",
            "    ... 13,700/31,027 verses  (37 v/s)  ETA 7.8 min  nouns: 48,759\n",
            "    ... 13,800/31,027 verses  (37 v/s)  ETA 7.7 min  nouns: 48,995\n",
            "    ... 13,900/31,027 verses  (37 v/s)  ETA 7.6 min  nouns: 49,269\n",
            "    ... 14,000/31,027 verses  (37 v/s)  ETA 7.6 min  nouns: 49,491\n",
            "    ... 14,100/31,027 verses  (37 v/s)  ETA 7.5 min  nouns: 49,749\n",
            "    ... 14,200/31,027 verses  (38 v/s)  ETA 7.5 min  nouns: 49,956\n",
            "    ... 14,300/31,027 verses  (38 v/s)  ETA 7.4 min  nouns: 50,173\n",
            "    ... 14,400/31,027 verses  (38 v/s)  ETA 7.4 min  nouns: 50,392\n",
            "    ... 14,500/31,027 verses  (38 v/s)  ETA 7.3 min  nouns: 50,637\n",
            "    ... 14,600/31,027 verses  (38 v/s)  ETA 7.3 min  nouns: 50,859\n",
            "    ... 14,700/31,027 verses  (38 v/s)  ETA 7.2 min  nouns: 51,085\n",
            "    ... 14,800/31,027 verses  (38 v/s)  ETA 7.1 min  nouns: 51,320\n",
            "    ... 14,900/31,027 verses  (38 v/s)  ETA 7.1 min  nouns: 51,589\n",
            "    ... 15,000/31,027 verses  (38 v/s)  ETA 7.0 min  nouns: 51,800\n",
            "    ... 15,100/31,027 verses  (38 v/s)  ETA 7.0 min  nouns: 52,026\n",
            "    ... 15,200/31,027 verses  (38 v/s)  ETA 6.9 min  nouns: 52,268\n",
            "    ... 15,300/31,027 verses  (38 v/s)  ETA 6.9 min  nouns: 52,469\n",
            "    ... 15,400/31,027 verses  (38 v/s)  ETA 6.8 min  nouns: 52,681\n",
            "    ... 15,500/31,027 verses  (38 v/s)  ETA 6.8 min  nouns: 52,901\n",
            "    ... 15,600/31,027 verses  (38 v/s)  ETA 6.7 min  nouns: 53,147\n",
            "    ... 15,700/31,027 verses  (38 v/s)  ETA 6.7 min  nouns: 53,350\n",
            "    ... 15,800/31,027 verses  (38 v/s)  ETA 6.6 min  nouns: 53,558\n",
            "    ... 15,900/31,027 verses  (39 v/s)  ETA 6.5 min  nouns: 53,721\n",
            "    ... 16,000/31,027 verses  (39 v/s)  ETA 6.5 min  nouns: 53,931\n",
            "    ... 16,100/31,027 verses  (39 v/s)  ETA 6.4 min  nouns: 54,131\n",
            "    ... 16,200/31,027 verses  (39 v/s)  ETA 6.4 min  nouns: 54,308\n",
            "    ... 16,300/31,027 verses  (39 v/s)  ETA 6.3 min  nouns: 54,542\n",
            "    ... 16,400/31,027 verses  (39 v/s)  ETA 6.3 min  nouns: 54,767\n",
            "    ... 16,500/31,027 verses  (39 v/s)  ETA 6.2 min  nouns: 54,974\n",
            "    ... 16,600/31,027 verses  (39 v/s)  ETA 6.2 min  nouns: 55,188\n",
            "    ... 16,700/31,027 verses  (39 v/s)  ETA 6.1 min  nouns: 55,486\n",
            "    ... 16,800/31,027 verses  (39 v/s)  ETA 6.1 min  nouns: 55,759\n",
            "    ... 16,900/31,027 verses  (39 v/s)  ETA 6.0 min  nouns: 56,044\n",
            "    ... 17,000/31,027 verses  (39 v/s)  ETA 5.9 min  nouns: 56,299\n",
            "    ... 17,100/31,027 verses  (39 v/s)  ETA 5.9 min  nouns: 56,557\n",
            "    ... 17,200/31,027 verses  (39 v/s)  ETA 5.8 min  nouns: 56,860\n",
            "    ... 17,300/31,027 verses  (39 v/s)  ETA 5.8 min  nouns: 57,155\n",
            "    ... 17,400/31,027 verses  (39 v/s)  ETA 5.8 min  nouns: 57,467\n",
            "    ... 17,500/31,027 verses  (39 v/s)  ETA 5.7 min  nouns: 57,857\n",
            "    ... 17,600/31,027 verses  (39 v/s)  ETA 5.7 min  nouns: 58,298\n",
            "    ... 17,700/31,027 verses  (39 v/s)  ETA 5.6 min  nouns: 58,697\n",
            "    ... 17,800/31,027 verses  (39 v/s)  ETA 5.6 min  nouns: 59,100\n",
            "    ... 17,900/31,027 verses  (39 v/s)  ETA 5.6 min  nouns: 59,475\n",
            "    ... 18,000/31,027 verses  (39 v/s)  ETA 5.5 min  nouns: 59,882\n",
            "    ... 18,100/31,027 verses  (39 v/s)  ETA 5.5 min  nouns: 60,248\n",
            "    ... 18,200/31,027 verses  (39 v/s)  ETA 5.4 min  nouns: 60,662\n",
            "    ... 18,300/31,027 verses  (39 v/s)  ETA 5.4 min  nouns: 61,063\n",
            "    ... 18,400/31,027 verses  (39 v/s)  ETA 5.4 min  nouns: 61,388\n",
            "    ... 18,500/31,027 verses  (39 v/s)  ETA 5.3 min  nouns: 61,712\n",
            "    ... 18,600/31,027 verses  (39 v/s)  ETA 5.3 min  nouns: 62,027\n",
            "    ... 18,700/31,027 verses  (39 v/s)  ETA 5.3 min  nouns: 62,374\n",
            "    ... 18,800/31,027 verses  (39 v/s)  ETA 5.2 min  nouns: 62,784\n",
            "    ... 18,900/31,027 verses  (39 v/s)  ETA 5.2 min  nouns: 63,152\n",
            "    ... 19,000/31,027 verses  (39 v/s)  ETA 5.2 min  nouns: 63,476\n",
            "    ... 19,100/31,027 verses  (39 v/s)  ETA 5.1 min  nouns: 63,837\n",
            "    ... 19,200/31,027 verses  (39 v/s)  ETA 5.1 min  nouns: 64,241\n",
            "    ... 19,300/31,027 verses  (38 v/s)  ETA 5.1 min  nouns: 64,594\n",
            "    ... 19,400/31,027 verses  (38 v/s)  ETA 5.0 min  nouns: 64,978\n",
            "    ... 19,500/31,027 verses  (38 v/s)  ETA 5.0 min  nouns: 65,328\n",
            "    ... 19,600/31,027 verses  (38 v/s)  ETA 5.0 min  nouns: 65,685\n",
            "    ... 19,700/31,027 verses  (38 v/s)  ETA 4.9 min  nouns: 66,023\n",
            "    ... 19,800/31,027 verses  (38 v/s)  ETA 4.9 min  nouns: 66,444\n",
            "    ... 19,900/31,027 verses  (38 v/s)  ETA 4.9 min  nouns: 66,834\n",
            "    ... 20,000/31,027 verses  (38 v/s)  ETA 4.8 min  nouns: 67,229\n",
            "    ... 20,100/31,027 verses  (38 v/s)  ETA 4.8 min  nouns: 67,558\n",
            "    ... 20,200/31,027 verses  (38 v/s)  ETA 4.8 min  nouns: 67,947\n",
            "    ... 20,300/31,027 verses  (38 v/s)  ETA 4.7 min  nouns: 68,358\n",
            "    ... 20,400/31,027 verses  (38 v/s)  ETA 4.7 min  nouns: 68,588\n",
            "    ... 20,500/31,027 verses  (38 v/s)  ETA 4.6 min  nouns: 68,970\n",
            "    ... 20,600/31,027 verses  (38 v/s)  ETA 4.6 min  nouns: 69,389\n",
            "    ... 20,700/31,027 verses  (38 v/s)  ETA 4.6 min  nouns: 69,740\n",
            "    ... 20,800/31,027 verses  (38 v/s)  ETA 4.5 min  nouns: 70,113\n",
            "    ... 20,900/31,027 verses  (38 v/s)  ETA 4.5 min  nouns: 70,487\n",
            "    ... 21,000/31,027 verses  (38 v/s)  ETA 4.4 min  nouns: 70,854\n",
            "    ... 21,100/31,027 verses  (38 v/s)  ETA 4.4 min  nouns: 71,278\n",
            "    ... 21,200/31,027 verses  (38 v/s)  ETA 4.3 min  nouns: 71,616\n",
            "    ... 21,300/31,027 verses  (38 v/s)  ETA 4.3 min  nouns: 72,056\n",
            "    ... 21,400/31,027 verses  (38 v/s)  ETA 4.3 min  nouns: 72,425\n",
            "    ... 21,500/31,027 verses  (38 v/s)  ETA 4.2 min  nouns: 72,965\n",
            "    ... 21,600/31,027 verses  (38 v/s)  ETA 4.2 min  nouns: 73,443\n",
            "    ... 21,700/31,027 verses  (38 v/s)  ETA 4.1 min  nouns: 73,862\n",
            "    ... 21,800/31,027 verses  (37 v/s)  ETA 4.1 min  nouns: 74,291\n",
            "    ... 21,900/31,027 verses  (37 v/s)  ETA 4.1 min  nouns: 74,725\n",
            "    ... 22,000/31,027 verses  (37 v/s)  ETA 4.0 min  nouns: 75,114\n",
            "    ... 22,100/31,027 verses  (37 v/s)  ETA 4.0 min  nouns: 75,441\n",
            "    ... 22,200/31,027 verses  (37 v/s)  ETA 3.9 min  nouns: 75,774\n",
            "    ... 22,300/31,027 verses  (37 v/s)  ETA 3.9 min  nouns: 76,170\n",
            "    ... 22,400/31,027 verses  (37 v/s)  ETA 3.9 min  nouns: 76,515\n",
            "    ... 22,500/31,027 verses  (37 v/s)  ETA 3.8 min  nouns: 76,858\n",
            "    ... 22,600/31,027 verses  (37 v/s)  ETA 3.8 min  nouns: 77,246\n",
            "    ... 22,700/31,027 verses  (37 v/s)  ETA 3.7 min  nouns: 77,618\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3095711721.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# ── Chinese ───────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mzh_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_chinese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"chinese_verses.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mzh_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzh_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_frequency_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzh_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mzh_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"chinese_nouns.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3669632545.py\u001b[0m in \u001b[0;36mpreprocess_chinese\u001b[0;34m(verse_csv)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mcontext\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mMAX_CONTEXT_LEN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mflag_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# Force known mis-tagged tokens to correct POS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py\u001b[0m in \u001b[0;36mcut\u001b[0;34m(sentence, HMM, use_paddle)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjieba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHMM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHMM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py\u001b[0m in \u001b[0;36mcut\u001b[0;34m(self, sentence, HMM)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHMM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cut_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHMM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHMM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py\u001b[0m in \u001b[0;36m__cut_internal\u001b[0;34m(self, sentence, HMM)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mre_han_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcut_blk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py\u001b[0m in \u001b[0;36m__cut_DAG\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFREQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mrecognized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cut_detail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecognized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py\u001b[0m in \u001b[0;36m__cut_detail\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mre_han_detail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py\u001b[0m in \u001b[0;36m__cut\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__cut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         prob, pos_list = viterbi(\n\u001b[0m\u001b[1;32m    119\u001b[0m             sentence, char_state_tab_P, start_P, trans_P, emit_P)\n\u001b[1;32m    120\u001b[0m         \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnexti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jieba/posseg/viterbi.py\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(obs, states, start_p, trans_p, emit_p)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             prob, state = max((V[t - 1][y0] + trans_p[y0].get(y, MIN_INF) +\n\u001b[0m\u001b[1;32m     38\u001b[0m                                emit_p[y].get(obs[t], MIN_FLOAT), y0) for y0 in prev_states)\n\u001b[1;32m     39\u001b[0m             \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jieba/posseg/viterbi.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             prob, state = max((V[t - 1][y0] + trans_p[y0].get(y, MIN_INF) +\n\u001b[0m\u001b[1;32m     38\u001b[0m                                emit_p[y].get(obs[t], MIN_FLOAT), y0) for y0 in prev_states)\n\u001b[1;32m     39\u001b[0m             \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Extract Context Embeddings"
      ],
      "metadata": {
        "id": "1CZa8ZJVWMeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from typing import List, Tuple\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR    = Path(\"/content\") / \"bible_data\"\n",
        "MODEL_NAME  = \"xlm-roberta-base\"   # Multilingual; same model for EN and ZH\n",
        "BATCH_SIZE  = 32                   # Reduce to 8-16 if OOM on CPU\n",
        "LAYERS      = [-1, -2, -3, -4]     # Last 4 layers averaged (standard WSI practice)\n",
        "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MAX_SEQ_LEN = 128                  # Max subword tokens per sentence\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ─── Model Loading ────────────────────────────────────────────────────────────\n",
        "\n",
        "def load_model():\n",
        "    print(f\"  [model] Loading {MODEL_NAME}…\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model     = AutoModel.from_pretrained(MODEL_NAME, output_hidden_states=True)\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "# ─── Embedding Extraction ─────────────────────────────────────────────────────\n",
        "\n",
        "def get_target_embedding(\n",
        "    tokenizer,\n",
        "    model,\n",
        "    sentences:  List[str],\n",
        "    target_words: List[str],\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    For each (sentence, target_word) pair, extract the contextual embedding\n",
        "    of the target by:\n",
        "      1. Tokenizing the sentence\n",
        "      2. Finding subword token positions for the target word\n",
        "      3. Averaging hidden states across the last 4 layers at those positions\n",
        "      4. Mean-pooling across subwords for multi-token targets\n",
        "\n",
        "    Returns: np.ndarray of shape (N, hidden_dim)\n",
        "    \"\"\"\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in range(0, len(sentences), BATCH_SIZE):\n",
        "        batch_sents  = sentences[i : i + BATCH_SIZE]\n",
        "        batch_targets = target_words[i : i + BATCH_SIZE]\n",
        "\n",
        "        encoded = tokenizer(\n",
        "            batch_sents,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=MAX_SEQ_LEN,\n",
        "            return_offsets_mapping=True,\n",
        "        )\n",
        "        offset_mappings = encoded.pop(\"offset_mapping\")  # not passed to model\n",
        "\n",
        "        encoded = {k: v.to(DEVICE) for k, v in encoded.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encoded)\n",
        "\n",
        "        # Stack selected hidden layers: shape (n_layers, batch, seq_len, hidden)\n",
        "        hidden_states = torch.stack(\n",
        "            [outputs.hidden_states[l] for l in LAYERS], dim=0\n",
        "        )\n",
        "        # Mean over selected layers: (batch, seq_len, hidden)\n",
        "        layer_mean = hidden_states.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        input_ids = encoded[\"input_ids\"].cpu().numpy()\n",
        "\n",
        "        for j, (target, offsets_j) in enumerate(zip(batch_targets, offset_mappings)):\n",
        "            # Re-encode the target word alone to find its subword tokens\n",
        "            target_enc = tokenizer.encode(\n",
        "                target, add_special_tokens=False\n",
        "            )\n",
        "            # Find target subword positions in the sentence encoding\n",
        "            target_positions = _find_subword_positions(\n",
        "                input_ids[j].tolist(), target_enc\n",
        "            )\n",
        "            if target_positions:\n",
        "                token_emb = layer_mean[j][target_positions].mean(axis=0)\n",
        "            else:\n",
        "                # Fallback: mean-pool entire sequence (excluding [CLS]/[SEP])\n",
        "                seq_len = (input_ids[j] != tokenizer.pad_token_id).sum()\n",
        "                token_emb = layer_mean[j][1 : seq_len - 1].mean(axis=0)\n",
        "\n",
        "            all_embeddings.append(token_emb)\n",
        "\n",
        "        if (i // BATCH_SIZE) % 10 == 0:\n",
        "            print(f\"    … batch {i//BATCH_SIZE} / {len(sentences)//BATCH_SIZE}\", end=\"\\r\")\n",
        "\n",
        "    embeddings = np.array(all_embeddings, dtype=np.float32)\n",
        "    # L2 normalize for cosine-based clustering\n",
        "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    norms = np.where(norms == 0, 1, norms)\n",
        "    return embeddings / norms\n",
        "\n",
        "\n",
        "def _find_subword_positions(\n",
        "    sentence_ids: List[int], target_ids: List[int]\n",
        ") -> List[int]:\n",
        "    \"\"\"Find the start position of `target_ids` as a subsequence in `sentence_ids`.\"\"\"\n",
        "    n, m = len(sentence_ids), len(target_ids)\n",
        "    for start in range(n - m + 1):\n",
        "        if sentence_ids[start : start + m] == target_ids:\n",
        "            return list(range(start, start + m))\n",
        "    return []\n",
        "\n",
        "\n",
        "# ─── Per-language Pipeline ────────────────────────────────────────────────────\n",
        "\n",
        "def extract_embeddings_for_language(\n",
        "    lang: str,\n",
        "    noun_csv: Path,\n",
        "    tokenizer,\n",
        "    model,\n",
        ") -> None:\n",
        "    \"\"\"Load nouns, extract embeddings, and save as .npz.\"\"\"\n",
        "    out_path = DATA_DIR / f\"{lang}_embeddings.npz\"\n",
        "    if out_path.exists():\n",
        "        print(f\"  [{lang.upper()}] Embeddings already exist — skipping.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(noun_csv)\n",
        "    print(f\"  [{lang.upper()}] Extracting embeddings for {len(df):,} noun occurrences…\")\n",
        "\n",
        "    embeddings = get_target_embedding(\n",
        "        tokenizer,\n",
        "        model,\n",
        "        sentences    = df[\"context\"].tolist(),\n",
        "        target_words = df[\"token\"].tolist(),\n",
        "    )\n",
        "    print()  # newline after progress indicator\n",
        "\n",
        "    np.savez_compressed(\n",
        "        out_path,\n",
        "        embeddings = embeddings,\n",
        "        lemmas     = df[\"lemma\"].to_numpy(dtype=str),\n",
        "        verse_ids  = df[\"verse_id\"].to_numpy(dtype=str),\n",
        "        tokens     = df[\"token\"].to_numpy(dtype=str),\n",
        "    )\n",
        "    print(f\"  [{lang.upper()}] Saved {embeddings.shape} embeddings → {out_path.name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJF9kXsnWQDa",
        "outputId": "eff66f74-6232-4354-c800-78efbe401721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Step 3: Contextual Embedding Extraction (XLM-R)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "extract_embeddings_for_language(\n",
        "    \"english\",\n",
        "    DATA_DIR / \"english_nouns.csv\",\n",
        "    tokenizer, model,\n",
        ")\n",
        "# extract_embeddings_for_language(\n",
        "#     \"chinese\",\n",
        "#     DATA_DIR / \"chinese_nouns.csv\",\n",
        "#     tokenizer, model,\n",
        "# )\n",
        "\n",
        "print(\"\\n✓ Step 3 complete.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444,
          "referenced_widgets": [
            "cbddc251b728458088b98361030d2e73",
            "5fe2324afb8a4fa9b62394119fcbf549",
            "6845e4268f4343a28eba9abe96aeb23f",
            "08281ac3d3c84208affddfdf3d2cbac5",
            "715a48b2d61e49afb53bcdc90a2eea11",
            "a4db27e32a904cfe808fd29d72793cd7",
            "c45f060ad7bd46799574136229beb632",
            "117754bd6f2b49e89705f13363a8f06a",
            "f3a896ced3e0430dac268e9969bdac8d",
            "0ed5a3f87380453ca1fe163a9a40c387",
            "37c162edcb5d44748b7233e69c94b7c1"
          ]
        },
        "id": "ZwpfEQinX-ri",
        "outputId": "4ad24d93-6095-411a-cecc-edb46c0c7a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Step 3: Contextual Embedding Extraction (XLM-R)\n",
            "============================================================\n",
            "  [model] Loading xlm-roberta-base…\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbddc251b728458088b98361030d2e73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "XLMRobertaModel LOAD REPORT from: xlm-roberta-base\n",
            "Key                       | Status     |  | \n",
            "--------------------------+------------+--+-\n",
            "lm_head.layer_norm.bias   | UNEXPECTED |  | \n",
            "lm_head.dense.weight      | UNEXPECTED |  | \n",
            "lm_head.dense.bias        | UNEXPECTED |  | \n",
            "lm_head.layer_norm.weight | UNEXPECTED |  | \n",
            "lm_head.bias              | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [ENGLISH] Extracting embeddings for 106,524 noun occurrences…\n",
            "\n",
            "  [ENGLISH] Saved (106524, 768) embeddings → english_embeddings.npz\n",
            "\n",
            "✓ Step 3 complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: WSI Clustering"
      ],
      "metadata": {
        "id": "meHGlTr8aErA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import normalize\n",
        "from typing import Tuple, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR    = Path(\"/content\") / \"bible_data\"\n",
        "K_RANGE              = range(2, 9)           # Test k = 2, 3, …, 8\n",
        "SILHOUETTE_THRESHOLD = 0.30                  # Below this → monosemous (k=1)\n",
        "# NOTE: 0.05 caused 0% monosemy — XLM-R embeddings always score > 0.05\n",
        "# even for genuinely monosemous words. 0.30 is the literature standard\n",
        "# for meaningful cluster structure (Ustalov et al. 2019; Neelakantan et al. 2014).\n",
        "# Run sensitivity check at SILHOUETTE_THRESHOLD = 0.20 and report both.\n",
        "MIN_INSTANCES        = 30                    # Min occurrences to attempt clustering\n",
        "# Raised from 5 to 30 to ensure UMAP dimensionality reduction works reliably.\n",
        "# UMAP requires n_samples > n_components (60 > 50). Words with 30-59 occurrences\n",
        "# are excluded from clustering as they lack sufficient contextual diversity for\n",
        "# robust sense induction (cf. Ustalov et al. 2019 who use threshold of 50).\n",
        "USE_UMAP             = True                  # Reduce to 50D before clustering\n",
        "UMAP_N_COMPONENTS    = 30\n",
        "RANDOM_STATE         = 42\n",
        "\n",
        "# ─── Optional UMAP reduction ─────────────────────────────────────────────────\n",
        "#     \"\"\"\n",
        "#     Optionally reduce embedding dimensionality with UMAP before clustering.\n",
        "#     UMAP (McInnes et al. 2018) improves cluster separation for high-dim data.\n",
        "#     Falls back to PCA if umap-learn is not installed or if UMAP fails.\n",
        "#     \"\"\"\n",
        "#     if not USE_UMAP or embeddings.shape[0] <= MIN_INSTANCES: # Added <= MIN_INSTANCES for robustness\n",
        "#         return embeddings\n",
        "\n",
        "#     try:\n",
        "#         import umap\n",
        "#         # Ensure n_components is always less than the number of samples\n",
        "#         n_components_umap = min(UMAP_N_COMPONENTS, embeddings.shape[0] - 1)\n",
        "#         if n_components_umap <= 0: # Handle cases where n_samples is 1\n",
        "#             return embeddings\n",
        "\n",
        "#         reducer = umap.UMAP(\n",
        "#             n_components=n_components_umap,\n",
        "#             metric=\"cosine\",\n",
        "#             random_state=RANDOM_STATE,\n",
        "#             n_jobs=1,\n",
        "#         )\n",
        "#         return reducer.fit_transform(embeddings)\n",
        "#     except (ImportError, TypeError) as e: # Catch both ImportError and TypeError\n",
        "#         if isinstance(e, ImportError):\n",
        "#             print(\"    [warn] umap-learn not found — using PCA fallback. \"\n",
        "#                   \"Install: pip install umap-learn --break-system-packages\")\n",
        "#         else:\n",
        "#             print(f\"    [warn] UMAP failed ({e}) — using PCA fallback for this lemma. \"\n",
        "#                   f\"Embeddings shape: {embeddings.shape}\")\n",
        "#         from sklearn.decomposition import PCA\n",
        "#         # Ensure n_components for PCA is also less than number of samples and features\n",
        "#         n_components_pca = min(UMAP_N_COMPONENTS, embeddings.shape[0] - 1, embeddings.shape[1])\n",
        "#         if n_components_pca <= 0: # Handle cases where n_samples is 1\n",
        "#             return embeddings\n",
        "#         return PCA(n_components=n_components_pca, random_state=RANDOM_STATE).fit_transform(embeddings)\n",
        "\n",
        "def reduce_embeddings(embeddings: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Reduce embedding dimensionality with UMAP before clustering.\n",
        "    UMAP (McInnes et al. 2018) improves cluster separation for high-dim data.\n",
        "    Falls back to PCA if umap-learn is not installed.\n",
        "\n",
        "    With MIN_INSTANCES=60, we always have n_samples ≥ 60 > 50 = n_components,\n",
        "    so UMAP will never fail with the k >= N error.\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    Reduce embedding dimensionality with UMAP before clustering.\n",
        "    UMAP (McInnes et al. 2018) improves cluster separation for high-dim data.\n",
        "    Falls back to PCA if umap-learn is not installed.\n",
        "\n",
        "    With MIN_INSTANCES=60, we always have n_samples ≥ 60 > 50 = n_components,\n",
        "    so UMAP will never fail with the k >= N error.\n",
        "    \"\"\"\n",
        "    # Define n from embeddings shape\n",
        "    n = embeddings.shape[0]\n",
        "\n",
        "    # Adaptive n_components based on sample size\n",
        "    n_components = min(50, n - 10)  # Leave buffer\n",
        "\n",
        "    # if not USE_UMAP or embeddings.shape[0] < UMAP_N_COMPONENTS:\n",
        "    if not USE_UMAP or n < n_components + 1:  # ✓ Uses adaptive value\n",
        "        return embeddings\n",
        "    try:\n",
        "        import umap\n",
        "        reducer = umap.UMAP(\n",
        "            n_components=n_components,\n",
        "            n_neighbors=min(15, n-1),  # Also adaptive\n",
        "            metric=\"cosine\",\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=1,\n",
        "        )\n",
        "        return reducer.fit_transform(embeddings)\n",
        "    except ImportError:\n",
        "        print(\"    [warn] umap-learn not found — using PCA fallback. \"\n",
        "              \"Install: pip install umap-learn --break-system-packages\")\n",
        "        from sklearn.decomposition import PCA\n",
        "        n = min(UMAP_N_COMPONENTS, embeddings.shape[0] - 1, embeddings.shape[1])\n",
        "        return PCA(n_components=n, random_state=RANDOM_STATE).fit_transform(embeddings)\n",
        "\n",
        "\n",
        "# ─── Core WSI for a single lemma ──────────────────────────────────────────────\n",
        "def induce_senses_direct(\n",
        "    embeddings: np.ndarray,\n",
        ") -> Tuple[int, int, float, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    WSI using direct hierarchical clustering on embeddings.\n",
        "    No UMAP - works for any n.\n",
        "\n",
        "    Returns same format as induce_senses_for_lemma:\n",
        "        k_ward, k_kmeans, best_silhouette_ward,\n",
        "        labels_ward (np.ndarray), labels_kmeans (np.ndarray)\n",
        "    \"\"\"\n",
        "    from scipy.spatial.distance import pdist, squareform\n",
        "    from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "    from sklearn.metrics import silhouette_score\n",
        "\n",
        "    n = len(embeddings)\n",
        "\n",
        "    # Insufficient data → monosemous\n",
        "    if n < 2:\n",
        "        ones = np.zeros(n, dtype=int)\n",
        "        return 1, 1, 0.0, ones, ones\n",
        "\n",
        "    # Compute pairwise cosine distances\n",
        "    distances = squareform(pdist(embeddings, metric='cosine'))\n",
        "\n",
        "    # Initialize best results for both methods\n",
        "    best_k_ward, best_sil_ward, best_labels_ward = 1, -1.0, np.zeros(n, dtype=int)\n",
        "    best_k_km, best_sil_km, best_labels_km = 1, -1.0, np.zeros(n, dtype=int)\n",
        "\n",
        "    for k in range(2, min(9, n)):\n",
        "        # Ward hierarchical clustering\n",
        "        try:\n",
        "            ward = AgglomerativeClustering(\n",
        "                n_clusters=k,\n",
        "                metric='precomputed',\n",
        "                linkage='average'  # Use 'average' instead of 'ward' for precomputed\n",
        "            )\n",
        "            labels_w = ward.fit_predict(distances)\n",
        "\n",
        "            if len(np.unique(labels_w)) > 1:\n",
        "                sil_w = silhouette_score(\n",
        "                    distances, labels_w,\n",
        "                    metric='precomputed',\n",
        "                    sample_size=min(1000, n)\n",
        "                )\n",
        "                if sil_w > best_sil_ward:\n",
        "                    best_sil_ward, best_k_ward, best_labels_ward = sil_w, k, labels_w\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # K-Means clustering on raw embeddings\n",
        "        try:\n",
        "            km = KMeans(\n",
        "                n_clusters=k,\n",
        "                random_state=RANDOM_STATE,\n",
        "                n_init=10,\n",
        "                max_iter=300\n",
        "            )\n",
        "            labels_k = km.fit_predict(embeddings)\n",
        "\n",
        "            if len(np.unique(labels_k)) > 1:\n",
        "                sil_k = silhouette_score(\n",
        "                    embeddings, labels_k,\n",
        "                    metric='euclidean',\n",
        "                    sample_size=min(1000, n)\n",
        "                )\n",
        "                if sil_k > best_sil_km:\n",
        "                    best_sil_km, best_k_km, best_labels_km = sil_k, k, labels_k\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Apply monosemy threshold\n",
        "    if best_sil_ward < SILHOUETTE_THRESHOLD:\n",
        "        best_k_ward = 1\n",
        "        best_labels_ward = np.zeros(n, dtype=int)\n",
        "\n",
        "    if best_sil_km < SILHOUETTE_THRESHOLD:\n",
        "        best_k_km = 1\n",
        "        best_labels_km = np.zeros(n, dtype=int)\n",
        "\n",
        "    return (best_k_ward, best_k_km, max(best_sil_ward, 0.0),\n",
        "            best_labels_ward, best_labels_km)\n",
        "\n",
        "def induce_senses_for_lemma(\n",
        "    embeddings: np.ndarray,\n",
        ") -> Tuple[int, int, float, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Given embeddings for all occurrences of a lemma, find the optimal k\n",
        "    using silhouette score for both Ward and KMeans clustering.\n",
        "\n",
        "    Returns:\n",
        "        k_ward, k_kmeans, best_silhouette_ward,\n",
        "        labels_ward (np.ndarray), labels_kmeans (np.ndarray)\n",
        "    \"\"\"\n",
        "    n = len(embeddings)\n",
        "\n",
        "    # Insufficient data → monosemous\n",
        "    if n < MIN_INSTANCES:\n",
        "        ones = np.zeros(n, dtype=int)\n",
        "        return 1, 1, 0.0, ones, ones\n",
        "\n",
        "    reduced = reduce_embeddings(embeddings)\n",
        "\n",
        "    best_k_ward, best_sil_ward, best_labels_ward   = 1, -1.0, np.zeros(n, dtype=int)\n",
        "    best_k_km,   best_sil_km,   best_labels_km     = 1, -1.0, np.zeros(n, dtype=int)\n",
        "\n",
        "    for k in K_RANGE:\n",
        "        if k >= n:\n",
        "            break  # Can't have more clusters than data points\n",
        "\n",
        "        # Ward agglomerative\n",
        "        try:\n",
        "            ward = AgglomerativeClustering(n_clusters=k, linkage=\"ward\")\n",
        "            labels_w = ward.fit_predict(reduced)\n",
        "            if len(np.unique(labels_w)) > 1:\n",
        "                sil_w = silhouette_score(reduced, labels_w, metric=\"euclidean\",\n",
        "                                         sample_size=min(1000, n))\n",
        "                if sil_w > best_sil_ward:\n",
        "                    best_sil_ward, best_k_ward, best_labels_ward = sil_w, k, labels_w\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # K-Means\n",
        "        try:\n",
        "            km = KMeans(n_clusters=k, random_state=RANDOM_STATE,\n",
        "                        n_init=10, max_iter=300)\n",
        "            labels_k = km.fit_predict(reduced)\n",
        "            if len(np.unique(labels_k)) > 1:\n",
        "                sil_k = silhouette_score(reduced, labels_k, metric=\"euclidean\",\n",
        "                                          sample_size=min(1000, n))\n",
        "                if sil_k > best_sil_km:\n",
        "                    best_sil_km, best_k_km, best_labels_km = sil_k, k, labels_k\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Apply monosemy threshold\n",
        "    if best_sil_ward < SILHOUETTE_THRESHOLD:\n",
        "        best_k_ward    = 1\n",
        "        best_labels_ward = np.zeros(n, dtype=int)\n",
        "\n",
        "    if best_sil_km < SILHOUETTE_THRESHOLD:\n",
        "        best_k_km    = 1\n",
        "        best_labels_km = np.zeros(n, dtype=int)\n",
        "\n",
        "    return (best_k_ward, best_k_km, max(best_sil_ward, 0.0),\n",
        "            best_labels_ward, best_labels_km)\n",
        "\n",
        "# ─── HDBSCAN ──────────────────────────────────────────────\n",
        "\n",
        "import hdbscan\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def induce_senses_hdbscan(embeddings: np.ndarray):\n",
        "    n_samples, n_features = embeddings.shape\n",
        "\n",
        "    if n_samples < 20:\n",
        "        return 1, np.zeros(n_samples, dtype=int)\n",
        "\n",
        "    # L2 normalize\n",
        "    embeddings = normalize(embeddings)\n",
        "\n",
        "    # Optional PCA only if large sample size\n",
        "    if n_samples > 200:\n",
        "        n_components = min(100, n_samples - 1, n_features)\n",
        "        embeddings = PCA(\n",
        "            n_components=n_components,\n",
        "            random_state=RANDOM_STATE\n",
        "        ).fit_transform(embeddings)\n",
        "        embeddings = normalize(embeddings)\n",
        "\n",
        "    min_cluster_size = max(8, int(0.05 * n_samples))\n",
        "\n",
        "    clusterer = hdbscan.HDBSCAN(\n",
        "        metric=\"euclidean\", # Changed from \"cosine\" to \"euclidean\"\n",
        "        min_cluster_size=min_cluster_size,\n",
        "        min_samples=max(5, min_cluster_size // 2),\n",
        "        cluster_selection_method=\"eom\"\n",
        "    )\n",
        "\n",
        "    labels = clusterer.fit_predict(embeddings)\n",
        "\n",
        "    clusters = set(labels)\n",
        "    clusters.discard(-1)\n",
        "\n",
        "    k = len(clusters)\n",
        "\n",
        "    if k <= 1:\n",
        "        return 1, np.zeros(n_samples, dtype=int)\n",
        "\n",
        "    sizes = sorted([sum(labels == c) for c in clusters], reverse=True)\n",
        "\n",
        "    if sizes[1] / n_samples < 0.12:\n",
        "        return 1, np.zeros(n_samples, dtype=int)\n",
        "\n",
        "    return k, labels\n",
        "\n",
        "# def induce_senses_hdbscan(embeddings: np.ndarray):\n",
        "#     n = len(embeddings)\n",
        "\n",
        "#     if n < 20:\n",
        "#         labels = np.zeros(n, dtype=int)\n",
        "#         return 1, labels\n",
        "\n",
        "#     # L2 normalize\n",
        "#     embeddings = normalize(embeddings)\n",
        "\n",
        "#     # Optional PCA to 100D (NOT UMAP)\n",
        "#     if embeddings.shape[1] > 100:\n",
        "#         embeddings = PCA(n_components=100, random_state=RANDOM_STATE).fit_transform(embeddings)\n",
        "#         embeddings = normalize(embeddings)\n",
        "\n",
        "#     min_cluster_size = max(8, int(0.05 * n))\n",
        "\n",
        "#     clusterer = hdbscan.HDBSCAN(\n",
        "#         metric=\"cosine\",\n",
        "#         min_cluster_size=min_cluster_size,\n",
        "#         min_samples=max(5, min_cluster_size // 2),\n",
        "#         cluster_selection_method=\"eom\"\n",
        "#     )\n",
        "\n",
        "#     labels = clusterer.fit_predict(embeddings)\n",
        "\n",
        "#     unique_clusters = set(labels)\n",
        "#     if -1 in unique_clusters:\n",
        "#         unique_clusters.remove(-1)\n",
        "\n",
        "#     k = len(unique_clusters)\n",
        "\n",
        "#     # Conservative monosemy guardrail\n",
        "#     if k <= 1:\n",
        "#         return 1, np.zeros(n, dtype=int)\n",
        "\n",
        "#     cluster_sizes = [sum(labels == c) for c in unique_clusters]\n",
        "#     cluster_sizes.sort(reverse=True)\n",
        "\n",
        "#     if cluster_sizes[1] / n < 0.12:  # tiny second cluster\n",
        "#         return 1, np.zeros(n, dtype=int)\n",
        "\n",
        "#     return k, labels\n",
        "\n",
        "# ─── Run WSI for entire language ──────────────────────────────────────────────\n",
        "\n",
        "def run_wsi_for_language(lang: str):\n",
        "    \"\"\"\n",
        "    L Load embeddings and run WSI for all lemmas in a language.\n",
        "    Saves two files:\n",
        "      1. {lang}_wsi_results.csv    - summary stats per lemma\n",
        "      2. {lang}_sense_labels.csv   - cluster assignments per occurrence\n",
        "    \"\"\"\n",
        "    embeddings_file = DATA_DIR / f\"{lang}_embeddings.npz\"\n",
        "    nouns_file      = DATA_DIR / f\"{lang}_nouns.csv\"\n",
        "\n",
        "    if not embeddings_file.exists():\n",
        "        print(f\"  [{lang.upper()}] ERROR: {embeddings_file.name} not found. Run Step 3 first.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n  [{lang.upper()}] Loading embeddings…\")\n",
        "    data = np.load(embeddings_file, allow_pickle=True)\n",
        "    lemmas_array = data[\"lemmas\"]\n",
        "    embeddings   = data[\"embeddings\"]\n",
        "    verse_ids    = data[\"verse_ids\"]\n",
        "    unique_lemmas = np.unique(lemmas_array)\n",
        "\n",
        "    print(f\"  [{lang.upper()}] Running WSI for {len(unique_lemmas):,} lemmas…\")\n",
        "\n",
        "    results = []\n",
        "    all_labels = []  # Collect per-instance labels for sense_labels.csv\n",
        "\n",
        "    for i, lemma in enumerate(unique_lemmas):\n",
        "        mask = (lemmas_array == lemma)\n",
        "        lemma_embeds = embeddings[mask]\n",
        "        lemma_vids   = verse_ids[mask]\n",
        "\n",
        "        # k_ward, k_km, sil_ward, labels_ward, labels_km = induce_senses_for_lemma(lemma_embeds)\n",
        "        # k_ward, k_km, sil_ward, labels_ward, labels_km = induce_senses_direct(lemma_embeds)\n",
        "        k_hdb, labels_hdb = induce_senses_hdbscan(lemma_embeds)\n",
        "\n",
        "        # # Agreement: what % of instances assigned to same cluster by both methods?\n",
        "        # if len(labels_ward) > 0:\n",
        "        #     agree = (labels_ward == labels_km).mean() * 100\n",
        "        # else:\n",
        "        #     agree = 100.0\n",
        "\n",
        "        # results.append({\n",
        "        #     \"lemma\":            lemma,\n",
        "        #     \"n_instances\":      len(lemma_embeds),\n",
        "        #     \"k_ward\":           k_ward,\n",
        "        #     \"k_kmeans\":         k_km,\n",
        "        #     \"silhouette_ward\":  round(sil_ward, 4),\n",
        "        #     \"agreement_pct\":    round(agree, 2),\n",
        "        # })\n",
        "        results.append({\n",
        "            \"lemma\": lemma,\n",
        "            \"n_instances\": len(lemma_embeds),\n",
        "            \"k_hdbscan\": k_hdb,\n",
        "        })\n",
        "\n",
        "        # # Collect per-instance cluster assignments\n",
        "        # for vid, cluster_w, cluster_k in zip(lemma_vids, labels_ward, labels_km):\n",
        "        #     all_labels.append({\n",
        "        #         \"lemma\":          lemma,\n",
        "        #         \"verse_id\":       vid,\n",
        "        #         \"cluster_ward\":   int(cluster_w),\n",
        "        #         \"cluster_kmeans\": int(cluster_k),\n",
        "        #     })\n",
        "        for vid, cluster in zip(lemma_vids, labels_hdb):\n",
        "            all_labels.append({\n",
        "                \"lemma\": lemma,\n",
        "                \"verse_id\": vid,\n",
        "                \"cluster_hdbscan\": int(cluster),\n",
        "            })\n",
        "\n",
        "        if (i + 1) % 50 == 0 or (i + 1) == len(unique_lemmas):\n",
        "            print(f\"    … {i + 1:,}/{len(unique_lemmas):,} lemmas\", end=\"\\r\")\n",
        "\n",
        "\n",
        "    # Save summary results\n",
        "    df = pd.DataFrame(results)\n",
        "    out_path = DATA_DIR / f\"{lang}_wsi_results.csv\"\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(f\"\\n  [{lang.upper()}] Saved: {out_path.name}\")\n",
        "\n",
        "    # Save per-instance cluster labels\n",
        "    labels_df = pd.DataFrame(all_labels)\n",
        "    labels_path = DATA_DIR / f\"{lang}_sense_labels.csv\"\n",
        "    labels_df.to_csv(labels_path, index=False)\n",
        "    print(f\"  [{lang.upper()}] Saved: {labels_path.name}\")\n",
        "\n",
        "    # print(f\"  [{lang.upper()}] Mean k (Ward): {df['k_ward'].mean():.2f}  \"\n",
        "    #       f\"Median: {df['k_ward'].median():.0f}  \"\n",
        "    #       f\"Monosemous (k=1): {(df['k_ward']==1).sum()} / {len(df)}\")\n",
        "    print(f\"  [{lang.upper()}] Mean k (HDBSCAN): {df['k_hdbscan'].mean():.2f}  \"\n",
        "      f\"Median: {df['k_hdbscan'].median():.0f}  \"\n",
        "      f\"Monosemous (k=1): {(df['k_hdbscan']==1).sum()} / {len(df)}\")"
      ],
      "metadata": {
        "id": "wCI4OOXjYSNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Step 4: Word Sense Induction (WSI)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "run_wsi_for_language(\"english\")\n",
        "# run_wsi_for_language(\"chinese\")\n",
        "\n",
        "# Quick comparison preview\n",
        "en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "# zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "# print(\"\\n── Quick Comparison Preview ──\")\n",
        "# print(f\"  EN | mean senses/lemma (Ward) : {en['k_ward'].mean():.3f}\")\n",
        "# print(f\"  ZH | mean senses/lemma (Ward) : {zh['k_ward'].mean():.3f}\")\n",
        "# print(f\"  EN | % polysemous lemmas       : {(en['k_ward'] > 1).mean()*100:.1f}%\")\n",
        "# print(f\"  ZH | % polysemous lemmas       : {(zh['k_ward'] > 1).mean()*100:.1f}%\")\n",
        "print(\"\\n── Quick Comparison Preview ──\")\n",
        "print(f\"  EN | mean senses/lemma (Ward) : {en['k_hdbscan'].mean():.3f}\")\n",
        "# print(f\"  ZH | mean senses/lemma (Ward) : {zh['k_hdbscan'].mean():.3f}\")\n",
        "print(f\"  EN | % polysemous lemmas       : {(en['k_hdbscan'] > 1).mean()*100:.1f}%\")\n",
        "# print(f\"  ZH | % polysemous lemmas       : {(zh['k_hdbscan'] > 1).mean()*100:.1f}%\")\n",
        "\n",
        "print(\"\\n✓ Step 4 complete.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUNKMUx1aRI5",
        "outputId": "17c11621-10b5-4792-9770-18c59321e57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Step 4: Word Sense Induction (WSI)\n",
            "============================================================\n",
            "\n",
            "  [ENGLISH] Loading embeddings…\n",
            "  [ENGLISH] Running WSI for 606 lemmas…\n",
            "    … 606/606 lemmas\n",
            "  [ENGLISH] Saved: english_wsi_results.csv\n",
            "  [ENGLISH] Saved: english_sense_labels.csv\n",
            "  [ENGLISH] Mean k (HDBSCAN): 1.56  Median: 1  Monosemous (k=1): 322 / 606\n",
            "\n",
            "── Quick Comparison Preview ──\n",
            "  EN | mean senses/lemma (Ward) : 1.556\n",
            "  EN | % polysemous lemmas       : 46.9%\n",
            "\n",
            "✓ Step 4 complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Validation and Statistical Analysis"
      ],
      "metadata": {
        "id": "lX7M7-Toc3Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from scipy import stats\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR    = Path(\"/content\") / \"bible_data\"\n",
        "OUTPUT_DIR = Path(\"/content\") / \"output\"\n",
        "# DATA_DIR   = Path(__file__).parent.parent / \"data\"\n",
        "# OUTPUT_DIR = Path(__file__).parent.parent / \"output\"\n",
        "FIG_DIR    = OUTPUT_DIR / \"figures\"\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "FIG_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"font.family\":  \"DejaVu Sans\",\n",
        "    \"font.size\":    11,\n",
        "    \"axes.titlesize\": 13,\n",
        "    \"axes.labelsize\": 12,\n",
        "})\n",
        "\n",
        "\n",
        "# ─── WordNet Validation (English) ────────────────────────────────────────────\n",
        "\n",
        "def get_wordnet_sense_counts(lemmas: list) -> dict:\n",
        "    \"\"\"\n",
        "    Look up the number of synsets for each lemma in Princeton WordNet.\n",
        "    Noun synsets only (pos='n').\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from nltk.corpus import wordnet as wn\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Run: pip install nltk --break-system-packages && \"\n",
        "                          \"python -c \\\"import nltk; nltk.download('wordnet')\\\"\")\n",
        "\n",
        "    counts = {}\n",
        "    for lemma in lemmas:\n",
        "        synsets = wn.synsets(lemma.lower(), pos=wn.NOUN)\n",
        "        counts[lemma] = len(synsets)\n",
        "    return counts\n",
        "\n",
        "\n",
        "def validate_english(en_results: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Correlate WSI-induced k_ward with WordNet sense counts for English nouns.\n",
        "    Returns a merged DataFrame with both counts.\n",
        "    \"\"\"\n",
        "    print(\"  [validate] Looking up Princeton WordNet sense counts…\")\n",
        "    lemmas = en_results[\"lemma\"].tolist()\n",
        "    wn_counts = get_wordnet_sense_counts(lemmas)\n",
        "\n",
        "    en_results = en_results.copy()\n",
        "    en_results[\"wn_senses\"] = en_results[\"lemma\"].map(wn_counts).fillna(0).astype(int)\n",
        "\n",
        "    # Keep only lemmas with at least 1 WordNet entry\n",
        "    valid = en_results[en_results[\"wn_senses\"] > 0].copy()\n",
        "\n",
        "    # rho, p = stats.spearmanr(valid[\"k_ward\"], valid[\"wn_senses\"])\n",
        "    rho, p = stats.spearmanr(valid[\"k_hdbscan\"], valid[\"wn_senses\"])\n",
        "    # print(f\"  [validate] EN Spearman ρ(k_ward, WN_senses) = {rho:.3f}  p = {p:.4f}  \"\n",
        "    print(f\"  [validate] EN Spearman ρ(k_hdbscan, WN_senses) = {rho:.3f}  p = {p:.4f}  \"\n",
        "          f\"(n={len(valid)})\")\n",
        "\n",
        "    return valid, rho, p\n",
        "\n",
        "\n",
        "# ─── WordNet Validation (Chinese) ────────────────────────────────────────────\n",
        "\n",
        "def get_chinese_wordnet_sense_counts(lemmas: list) -> dict:\n",
        "    \"\"\"\n",
        "    Look up the number of synsets for each lemma in Chinese WordNet (cmn).\n",
        "    Noun synsets only (pos='n').\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from nltk.corpus import wordnet as wn\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Run: pip install nltk --break-system-packages && \"\n",
        "                          \"python -c \\\"import nltk; nltk.download('wordnet')\\\"\")\n",
        "\n",
        "    counts = {}\n",
        "    for lemma in lemmas:\n",
        "        # 'cmn' is the language code for Mandarin Chinese in WordNet\n",
        "        # Note: Chinese WordNet coverage in NLTK might be limited compared to English\n",
        "        synsets = wn.synsets(lemma, lang=\"cmn\", pos=wn.NOUN)\n",
        "        counts[lemma] = len(synsets)\n",
        "    return counts\n",
        "\n",
        "\n",
        "def validate_chinese(zh_results: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Correlate WSI-induced k_ward with Chinese WordNet sense counts for Chinese nouns.\n",
        "    Returns a merged DataFrame with both counts.\n",
        "    \"\"\"\n",
        "    print(\"  [validate] Looking up Chinese WordNet sense counts…\")\n",
        "    lemmas = zh_results[\"lemma\"].tolist()\n",
        "    cwn_counts = get_chinese_wordnet_sense_counts(lemmas)\n",
        "\n",
        "    zh_results = zh_results.copy()\n",
        "    zh_results[\"cwn_senses\"] = zh_results[\"lemma\"].map(cwn_counts).fillna(0).astype(int)\n",
        "\n",
        "    # Keep only lemmas with at least 1 WordNet entry\n",
        "    valid = zh_results[zh_results[\"cwn_senses\"] > 0].copy()\n",
        "\n",
        "    if len(valid) == 0:\n",
        "        print(\"  [validate] No Chinese lemmas found in NLTK's Chinese WordNet. Skipping Spearman correlation.\")\n",
        "        rho, p = np.nan, np.nan # No correlation if no data\n",
        "    elif len(valid) == 1:\n",
        "        print(\"  [validate] Only one Chinese lemma found in NLTK's Chinese WordNet. Skipping Spearman correlation.\")\n",
        "        rho, p = np.nan, np.nan # Spearman requires at least two data points\n",
        "    else:\n",
        "        # rho, p = stats.spearmanr(valid[\"k_ward\"], valid[\"cwn_senses\"])\n",
        "        rho, p = stats.spearmanr(valid[\"k_hdbscan\"], valid[\"cwn_senses\"])\n",
        "        # print(f\"  [validate] ZH Spearman ρ(k_ward, CWN_senses) = {rho:.3f}  p = {p:.4f}  \"\n",
        "        print(f\"  [validate] ZH Spearman ρ(k_hdbscan, CWN_senses) = {rho:.3f}  p = {p:.4f}  \"\n",
        "              f\"(n={len(valid)})\")\n",
        "\n",
        "    return valid, rho, p\n",
        "\n",
        "\n",
        "# ─── Statistical Comparison ──────────────────────────────────────────────────\n",
        "\n",
        "def mann_whitney_comparison(\n",
        "    en_k: np.ndarray,\n",
        "    zh_k: np.ndarray,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Mann-Whitney U test comparing mean sense counts between EN and ZH.\n",
        "    Also computes Cohen's d and the common language effect size (CLES).\n",
        "    \"\"\"\n",
        "    u_stat, p_val = stats.mannwhitneyu(en_k, zh_k, alternative=\"two-sided\")\n",
        "    n1, n2        = len(en_k), len(zh_k)\n",
        "    cles          = u_stat / (n1 * n2)  # Common Language Effect Size\n",
        "\n",
        "    # Cohen's d (for reference alongside CLES)\n",
        "    pooled_std = np.sqrt(\n",
        "        ((n1 - 1) * en_k.std(ddof=1) ** 2 + (n2 - 1) * zh_k.std(ddof=1) ** 2)\n",
        "        / (n1 + n2 - 2)\n",
        "    )\n",
        "    cohens_d = (en_k.mean() - zh_k.mean()) / (pooled_std + 1e-9)\n",
        "\n",
        "    return {\n",
        "        \"en_mean_k\":   round(en_k.mean(), 4),\n",
        "        \"zh_mean_k\":   round(zh_k.mean(), 4),\n",
        "        \"en_median_k\": round(float(np.median(en_k)), 4),\n",
        "        \"zh_median_k\": round(float(np.median(zh_k)), 4),\n",
        "        \"en_std_k\":    round(en_k.std(ddof=1), 4),\n",
        "        \"zh_std_k\":    round(zh_k.std(ddof=1), 4),\n",
        "        \"U_statistic\": round(u_stat, 2),\n",
        "        \"p_value\":     round(p_val, 6),\n",
        "        \"CLES\":        round(cles, 4),\n",
        "        \"cohens_d\":    round(cohens_d, 4),\n",
        "        \"n_en\":        int(n1),\n",
        "        \"n_zh\":        int(n2),\n",
        "    }\n",
        "\n",
        "\n",
        "# ─── Figures ─────────────────────────────────────────────────────────────────\n",
        "\n",
        "# def plot_sense_distribution(df: pd.DataFrame, lang: str, col: str = \"k_ward\") -> None:\n",
        "def plot_sense_distribution(df: pd.DataFrame, lang: str, col: str = \"k_hdbscan\") -> None:\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    counts = df[col].value_counts().sort_index()\n",
        "    ax.bar(counts.index, counts.values, color=\"#4C72B0\", edgecolor=\"white\", linewidth=0.5)\n",
        "    ax.set_xlabel(\"Number of Induced Senses (k)\")\n",
        "    ax.set_ylabel(\"Number of Lemmas\")\n",
        "    ax.set_title(f\"{lang.capitalize()} — Distribution of Induced Senses per Noun Lemma\")\n",
        "    ax.set_xticks(range(1, df[col].max() + 1))\n",
        "    fig.tight_layout()\n",
        "    path = FIG_DIR / f\"sense_distribution_{lang}.png\"\n",
        "    fig.savefig(path, dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(f\"  [fig] Saved: {path.name}\")\n",
        "\n",
        "\n",
        "def plot_comparison_boxplot(en_df: pd.DataFrame, zh_df: pd.DataFrame) -> None:\n",
        "    combined = pd.concat([\n",
        "        # en_df[[\"k_ward\"]].assign(Language=\"English\"),\n",
        "        # zh_df[[\"k_ward\"]].assign(Language=\"Chinese\"),\n",
        "        en_df[[\"k_hdbscan\"]].assign(Language=\"English\"),\n",
        "        zh_df[[\"k_hdbscan\"]].assign(Language=\"Chinese\"),\n",
        "    ])\n",
        "    fig, ax = plt.subplots(figsize=(7, 5))\n",
        "    # sns.violinplot(data=combined, x=\"Language\", y=\"k_ward\",\n",
        "    sns.violinplot(data=combined, x=\"Language\", y=\"k_hdbscan\",\n",
        "                   palette=[\"#4C72B0\", \"#DD8452\"], inner=\"box\",\n",
        "                   cut=0,   # ← add this to fix sns artifact of extending beyond 8\n",
        "                   ax=ax)\n",
        "    ax.set_ylabel(\"Induced Senses per Lemma (k, Ward)\")\n",
        "    ax.set_title(\"Distribution of Polysemy Degree: English vs. Chinese Common Nouns\\n\"\n",
        "                 \"(Bible Parallel Corpus, WSI via XLM-R + Agglomerative Clustering)\")\n",
        "    fig.tight_layout()\n",
        "    path = FIG_DIR / \"comparison_violinplot.png\"\n",
        "    fig.savefig(path, dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(f\"  [fig] Saved: {path.name}\")\n",
        "\n",
        "\n",
        "def plot_wordnet_correlation(valid_df: pd.DataFrame, rho: float, p: float) -> None:\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    # ax.scatter(valid_df[\"wn_senses\"], valid_df[\"k_ward\"],\n",
        "    ax.scatter(valid_df[\"wn_senses\"], valid_df[\"k_hdbscan\"],\n",
        "               alpha=0.4, s=20, color=\"#4C72B0\")\n",
        "    ax.set_xlabel(\"WordNet Noun Synset Count\")\n",
        "    ax.set_ylabel(\"WSI-Induced k (Ward)\")\n",
        "    ax.set_title(f\"Validation: WSI k vs. WordNet Senses (English Nouns)\\n\"\n",
        "                 f\"Spearman ρ = {rho:.3f}, p = {p:.4f}\")\n",
        "    # Trend line\n",
        "    # m, b = np.polyfit(valid_df[\"wn_senses\"], valid_df[\"k_ward\"], 1)\n",
        "    m, b = np.polyfit(valid_df[\"wn_senses\"], valid_df[\"k_hdbscan\"], 1)\n",
        "    x_line = np.linspace(valid_df[\"wn_senses\"].min(), valid_df[\"wn_senses\"].max(), 100)\n",
        "    ax.plot(x_line, m * x_line + b, color=\"red\", linewidth=1.5, linestyle=\"--\")\n",
        "    fig.tight_layout()\n",
        "    path = FIG_DIR / \"wordnet_correlation_en.png\"\n",
        "    fig.savefig(path, dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(f\"  [fig] Saved: {path.name}\")\n",
        "\n",
        "def plot_wordnet_correlation_chinese(valid_df: pd.DataFrame, rho: float, p: float) -> None:\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    # ax.scatter(valid_df[\"cwn_senses\"], valid_df[\"k_ward\"],\n",
        "    ax.scatter(valid_df[\"cwn_senses\"], valid_df[\"k_hdbscan\"],\n",
        "               alpha=0.4, s=20, color=\"#DD8452\") # Using a different color for Chinese\n",
        "    ax.set_xlabel(\"Chinese WordNet Noun Synset Count\")\n",
        "    ax.set_ylabel(\"WSI-Induced k (Ward)\")\n",
        "    ax.set_title(f\"Validation: WSI k vs. Chinese WordNet Senses\\n\"\n",
        "                 f\"Spearman ρ = {rho:.3f}, p = {p:.4f}\")\n",
        "    # Trend line\n",
        "    # Only plot trend line if there's enough data and correlation is valid\n",
        "    if not np.isnan(rho) and len(valid_df) > 1:\n",
        "        # m, b = np.polyfit(valid_df[\"cwn_senses\"], valid_df[\"k_ward\"], 1)\n",
        "        m, b = np.polyfit(valid_df[\"cwn_senses\"], valid_df[\"k_hdbscan\"], 1)\n",
        "        x_line = np.linspace(valid_df[\"cwn_senses\"].min(), valid_df[\"cwn_senses\"].max(), 100)\n",
        "        ax.plot(x_line, m * x_line + b, color=\"red\", linewidth=1.5, linestyle=\"--\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    path = FIG_DIR / \"wordnet_correlation_zh.png\"\n",
        "    fig.savefig(path, dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(f\"  [fig] Saved: {path.name}\")\n",
        "\n",
        "\n",
        "def plot_silhouette_distribution(en_df: pd.DataFrame, zh_df: pd.DataFrame,\n",
        "                                  threshold: float = 0.30) -> None:\n",
        "    \"\"\"\n",
        "    Plot silhouette score distributions for both languages.\n",
        "    Shows the threshold τ that separates monosemous (k=1) from polysemous words.\n",
        "\n",
        "    Why this figure matters:\n",
        "      - Validates that τ=0.30 is correctly positioned in the distribution\n",
        "      - Shows monosemous vs polysemous words have different silhouette profiles\n",
        "      - Confirms the threshold is not arbitrary\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4.5), sharey=False)\n",
        "    fig.suptitle(\"Silhouette Score Distributions with Monosemy Threshold τ = 0.30\",\n",
        "                 fontsize=13, fontweight=\"bold\")\n",
        "\n",
        "    for ax, df, lang, color in zip(\n",
        "        axes,\n",
        "        [en_df, zh_df],\n",
        "        [\"English\", \"Chinese\"],\n",
        "        [\"#4C72B0\", \"#DD8452\"]\n",
        "    ):\n",
        "        mono = df[df[\"k_ward\"] == 1][\"silhouette_ward\"]\n",
        "        poly = df[df[\"k_ward\"] >  1][\"silhouette_ward\"]\n",
        "\n",
        "        # Monosemous words: silhouette = 0 (they were never clustered)\n",
        "        # Only plot polysemous words' silhouette scores — monosemous are always 0\n",
        "        ax.hist(poly, bins=20, color=color, alpha=0.75,\n",
        "                edgecolor=\"white\", linewidth=0.5,\n",
        "                label=f\"Polysemous (k≥2, n={len(poly)})\")\n",
        "        ax.hist(mono, bins=20, color=\"lightgray\", alpha=0.75,\n",
        "                edgecolor=\"white\", linewidth=0.5,\n",
        "                label=f\"Monosemous (k=1, n={len(mono)})\")\n",
        "\n",
        "        # Draw threshold line\n",
        "        ax.axvline(threshold, color=\"red\", linewidth=2, linestyle=\"--\",\n",
        "                   label=f\"Threshold τ={threshold}\")\n",
        "\n",
        "        # Annotate monosemy rate\n",
        "        mono_rate = len(mono) / len(df) * 100\n",
        "        ax.text(threshold + 0.01, ax.get_ylim()[1] * 0.9 if ax.get_ylim()[1] > 0 else 10,\n",
        "                f\"{mono_rate:.1f}%\\nmonosemous\",\n",
        "                color=\"red\", fontsize=9, va=\"top\")\n",
        "\n",
        "        ax.set_xlabel(\"Silhouette Score\", fontsize=11)\n",
        "        ax.set_ylabel(\"Number of Lemmas\", fontsize=11)\n",
        "        ax.set_title(f\"{lang} (n={len(df)})\", fontsize=12)\n",
        "        ax.set_xlim(-0.05, 0.75)\n",
        "        ax.legend(fontsize=9, loc=\"upper right\")\n",
        "        ax.grid(True, alpha=0.3, axis=\"y\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    path = FIG_DIR / \"silhouette_distribution.png\"\n",
        "    fig.savefig(path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    print(f\"  [fig] Saved: {path.name}\")"
      ],
      "metadata": {
        "id": "A2wqaZynajnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fe3cad1",
        "outputId": "80b9870a-6c15-4820-e069-7ef0c3a9db3c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cad16907",
        "outputId": "86585d22-cfe9-4bc8-aea4-e194f9710715"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure the 'zh' DataFrame is loaded, if not already in memory\n",
        "# (assuming DATA_DIR is defined from previous cells)\n",
        "if 'zh' not in locals():\n",
        "    DATA_DIR = Path(\"/content\") / \"bible_data\"\n",
        "    zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "chinese_lemmas = zh['lemma'].tolist()\n",
        "n_with_synsets = sum(1 for lemma in chinese_lemmas\n",
        "                     if len(wn.synsets(lemma, lang=\"cmn\")) > 0)\n",
        "\n",
        "total_lemmas = len(chinese_lemmas)\n",
        "print(f\"Coverage: {n_with_synsets}/{total_lemmas} = {n_with_synsets/total_lemmas:.1%}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage: 146/574 = 25.4%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 14869976-n in '14869976-n\tcmn:lemma\t污点\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 14869977-n in '14869977-n\tcmn:lemma\t小斑\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15168570-n in '15168570-n\tcmn:lemma\t规定的睡觉时间\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15171146-n in '15171146-n\tcmn:lemma\t节日\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15171147-n in '15171147-n\tcmn:lemma\t纪念日\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15171739-n in '15171739-n\tcmn:lemma\t竞技状态不佳的日子\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15171858-n in '15171858-n\tcmn:lemma\t存取时间\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15172882-n in '15172882-n\tcmn:lemma\t选举日\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15173065-n in '15173065-n\tcmn:lemma\t教会年\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15176162-n in '15176162-n\tcmn:lemma\t雾月\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15177867-n in '15177867-n\tcmn:lemma\t希伯来历\n",
            "'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py:2214: UserWarning: cmn: invalid offset 15178842-n in '15178842-n\tcmn:lemma\t回历\n",
            "'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f7bbc42",
        "outputId": "77be4742-a3c3-4b15-ba27-4dd041177a6f"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure the 'en' DataFrame is loaded, if not already in memory\n",
        "# (assuming DATA_DIR is defined from previous cells)\n",
        "if 'en' not in locals():\n",
        "    DATA_DIR = Path(\"/content\") / \"bible_data\"\n",
        "    en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "\n",
        "english_lemmas = en['lemma'].tolist()\n",
        "n_with_synsets_en = sum(1 for lemma in english_lemmas\n",
        "                          if len(wn.synsets(lemma.lower(), pos=wn.NOUN)) > 0)\n",
        "\n",
        "total_lemmas_en = len(english_lemmas)\n",
        "print(f\"English WordNet Coverage: {n_with_synsets_en}/{total_lemmas_en} = {n_with_synsets_en/total_lemmas_en:.1%}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English WordNet Coverage: 591/606 = 97.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98c2852b",
        "outputId": "3b8f3d4e-470b-423c-f1d2-eb2770f17d5b"
      },
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Step 5: Validation and Statistical Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "# ── Validation (English vs. WordNet) ──────────────────────────\n",
        "valid_en, rho_en, p_en = validate_english(en)\n",
        "valid_en.to_csv(OUTPUT_DIR / \"validation_correlation_en.csv\", index=False)\n",
        "\n",
        "# ── Validation (Chinese vs. WordNet) ──────────────────────────\n",
        "valid_zh, rho_zh, p_zh = validate_chinese(zh)\n",
        "valid_zh.to_csv(OUTPUT_DIR / \"validation_correlation_zh.csv\", index=False)\n",
        "\n",
        "# ── Statistical Comparison ────────────────────────────────────\n",
        "# stats_result = mann_whitney_comparison(\n",
        "#     en[\"k_ward\"].values,\n",
        "\n",
        "\n",
        "#     zh[\"k_ward\"].values,\n",
        "# )\n",
        "stats_result = mann_whitney_comparison(\n",
        "    en[\"k_hdbscan\"].values,\n",
        "    zh[\"k_hdbscan\"].values,\n",
        ")\n",
        "stats_df = pd.DataFrame([stats_result])\n",
        "stats_df.to_csv(OUTPUT_DIR / \"statistical_comparison.csv\", index=False)\n",
        "\n",
        "print(\"\\n── Statistical Comparison Results ──\")\n",
        "for k, v in stats_result.items():\n",
        "    print(f\"  {k:22s}: {v}\")\n",
        "\n",
        "# # ── Silhouette score diagnostic ───────────────────────────────\n",
        "# # Shows whether the threshold is calibrated correctly.\n",
        "# # If monosemy rate is 0%, raise SILHOUETTE_THRESHOLD in 04_wsi_clustering.py\n",
        "# # Target: 20-50% monosemous words. Rerun Step 4 after changing threshold.\n",
        "# print(\"\\n── Silhouette Diagnostic (tune threshold if monosemy=0%) ──\")\n",
        "# for label, df_lang in [(\"EN\", en), (\"ZH\", zh)]:\n",
        "#     sil = df_lang[\"silhouette_ward\"]\n",
        "#     # mono_rate = (df_lang[\"k_ward\"] == 1).mean() * 100\n",
        "#     mono_rate = (df_lang[\"k_hdbscan\"] == 1).mean() * 100\n",
        "#     print(f\"  {label} silhouette: \"\n",
        "#             f\"min={sil.min():.3f}  \"\n",
        "#             f\"p25={sil.quantile(0.25):.3f}  \"\n",
        "#             f\"median={sil.median():.3f}  \"\n",
        "#             f\"p75={sil.quantile(0.75):.3f}  \"\n",
        "#             f\"max={sil.max():.3f}\")\n",
        "#     print(f\"  {label} monosemy rate (k=1): {mono_rate:.1f}%\")\n",
        "\n",
        "# ── Figures ───────────────────────────────────────────────────\n",
        "plot_sense_distribution(en, \"english\")\n",
        "plot_sense_distribution(zh, \"chinese\")\n",
        "plot_comparison_boxplot(en, zh)\n",
        "plot_wordnet_correlation(valid_en, rho_en, p_en)\n",
        "# You might want to create a plot for Chinese WordNet correlation as well, if coverage is good\n",
        "# plot_wordnet_correlation_chinese(valid_zh, rho_zh, p_zh) # This would require a new function\n",
        "# plot_silhouette_distribution(en, zh)\n",
        "\n",
        "# ── Interpretation ────────────────────────────────────────────\n",
        "print(\"\\n── Interpretation ──\")\n",
        "if stats_result[\"p_value\"] < 0.05:\n",
        "    direction = \"English\" if stats_result[\"en_mean_k\"] > stats_result[\"zh_mean_k\"] else \"Chinese\"\n",
        "    print(f\"  Significant difference found (p={stats_result['p_value']:.4f}).\")\n",
        "    print(f\"  {direction} nouns show higher mean polysemy degree.\")\n",
        "else:\n",
        "    print(f\"  No significant difference found (p={stats_result['p_value']:.4f}).\")\n",
        "\n",
        "d = abs(stats_result[\"cohens_d\"])\n",
        "magnitude = \"small\" if d < 0.2 else (\"medium\" if d < 0.5 else \"large\")\n",
        "print(f\"  Effect size: Cohen's d = {stats_result['cohens_d']:.3f} ({magnitude})\")\n",
        "print(f\"  Spearman ρ (EN WSI vs. WordNet): {rho_en:.3f} (p={p_en:.4f})\")\n",
        "print(f\"  Spearman ρ (ZH WSI vs. WordNet): {rho_zh:.3f} (p={p_zh:.4f})\")\n",
        "\n",
        "print(\"\\n✓ Step 5 complete.\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Step 5: Validation and Statistical Analysis\n",
            "============================================================\n",
            "  [validate] Looking up Princeton WordNet sense counts…\n",
            "  [validate] EN Spearman ρ(k_hdbscan, WN_senses) = 0.064  p = 0.1189  (n=591)\n",
            "  [validate] Looking up Chinese WordNet sense counts…\n",
            "  [validate] ZH Spearman ρ(k_hdbscan, CWN_senses) = 0.100  p = 0.2481  (n=134)\n",
            "\n",
            "── Statistical Comparison Results ──\n",
            "  en_mean_k             : 1.5561\n",
            "  zh_mean_k             : 1.1376\n",
            "  en_median_k           : 1.0\n",
            "  zh_median_k           : 1.0\n",
            "  en_std_k              : 0.6822\n",
            "  zh_std_k              : 0.418\n",
            "  U_statistic           : 235227.0\n",
            "  p_value               : 0.0\n",
            "  CLES                  : 0.6762\n",
            "  cohens_d              : 0.7351\n",
            "  n_en                  : 606\n",
            "  n_zh                  : 574\n",
            "  [fig] Saved: sense_distribution_english.png\n",
            "  [fig] Saved: sense_distribution_chinese.png\n",
            "  [fig] Saved: comparison_violinplot.png\n",
            "  [fig] Saved: wordnet_correlation_en.png\n",
            "\n",
            "── Interpretation ──\n",
            "  Significant difference found (p=0.0000).\n",
            "  English nouns show higher mean polysemy degree.\n",
            "  Effect size: Cohen's d = 0.735 (large)\n",
            "  Spearman ρ (EN WSI vs. WordNet): 0.064 (p=0.1189)\n",
            "  Spearman ρ (ZH WSI vs. WordNet): 0.100 (p=0.2481)\n",
            "\n",
            "✓ Step 5 complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration\n",
        "DATA_DIR = Path(\"/content\") / \"bible_data\"\n",
        "OUTPUT_DIR = Path(\"/content\") / \"output\"\n",
        "\n",
        "# Load 'en' and 'zh' dataframes\n",
        "en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "# Combine the k_hdbscan values from both dataframes into a single DataFrame\n",
        "combined_k_hdbscan = pd.concat([\n",
        "    en[['k_hdbscan']].assign(Language='English NIV'),\n",
        "    zh[['k_hdbscan']].assign(Language='Chinese CUV-T')\n",
        "])\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(\n",
        "    data=combined_k_hdbscan,\n",
        "    x='k_hdbscan',\n",
        "    hue='Language',\n",
        "    multiple='dodge', # Plots bars side-by-side\n",
        "    shrink=0.8,       # Narrows the bars slightly for better separation\n",
        "    # kde=True,         # Adds a Kernel Density Estimate line\n",
        "    kde=True,         # Adds a Kernel Density Estimate line\n",
        "    bins=range(1, int(combined_k_hdbscan['k_hdbscan'].max()) + 2) # Ensures bins are centered on integers\n",
        ")\n",
        "\n",
        "plt.title('Distribution of Induced Senses (k_hdbscan): English NIV vs. Chinese CUV-T')\n",
        "plt.xlabel('Number of Induced Senses (k)')\n",
        "plt.ylabel('Number of Lemmas')\n",
        "plt.xticks(range(1, int(combined_k_hdbscan['k_hdbscan'].max()) + 1))\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot to the output directory if it's defined\n",
        "if 'OUTPUT_DIR' in locals() or 'OUTPUT_DIR' in globals():\n",
        "    plot_filename = OUTPUT_DIR / \"k_hdbscan_distribution_en_zh.png\"\n",
        "    plt.savefig(plot_filename, dpi=300)\n",
        "    print(f\"Saved plot to {plot_filename}\")\n",
        "else:\n",
        "    print(\"OUTPUT_DIR not defined. Plot not saved to file.\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "FRKftg4VOIr7",
        "outputId": "f01a012d-cafd-4399-a0d8-a0a4f3cbe3b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot to /content/output/k_hdbscan_distribution_en_zh.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# Ensure DATA_DIR is defined\n",
        "DATA_DIR = Path(\"/content\") / \"bible_data\" # Corrected path to match preprocessing output\n",
        "OUTPUT_DIR = Path(\"/content\") / \"output\"\n",
        "FIG_DIR = OUTPUT_DIR / \"figures\"\n",
        "FIG_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Load Chinese noun frequency data\n",
        "chinese_freq_path = DATA_DIR / \"chinese_noun_freq.csv\"\n",
        "try:\n",
        "    chinese_freq_df = pd.read_csv(chinese_freq_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {chinese_freq_path} was not found. Please ensure Chinese preprocessing steps were run.\")\n",
        "    # Exit would terminate the kernel, preventing further corrections. Instead, raise an error or handle gracefully.\n",
        "    raise # Re-raise the error to stop execution gracefully for now\n",
        "\n",
        "# Calculate lemma length (character count)\n",
        "chinese_freq_df['lemma_length'] = chinese_freq_df['lemma'].apply(len)\n",
        "\n",
        "# --- Font Configuration for Chinese Characters ---\n",
        "# This block ensures Chinese characters display correctly in the plot\n",
        "font_files = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
        "chosen_font_path = None\n",
        "for fpath in font_files:\n",
        "    if 'NotoSansCJK' in fpath:\n",
        "        chosen_font_path = fpath\n",
        "        break\n",
        "\n",
        "if chosen_font_path:\n",
        "    fm.fontManager.addfont(chosen_font_path)\n",
        "    prop = fm.FontProperties(fname=chosen_font_path)\n",
        "    actual_font_name = prop.get_name()\n",
        "    plt.rcParams['font.family'] = ['sans-serif']\n",
        "    plt.rcParams['font.sans-serif'] = [actual_font_name] + plt.rcParams['font.sans-serif']\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "    plt.rcParams[\"font.size\"] = 11\n",
        "    plt.rcParams[\"axes.titlesize\"] = 13\n",
        "    plt.rcParams[\"axes.labelsize\"] = 12\n",
        "else:\n",
        "    print(\"Warning: No Noto Sans CJK font found. Chinese characters might not display correctly.\")\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=chinese_freq_df, x='lemma_length', bins=range(1, chinese_freq_df['lemma_length'].max() + 2), kde=False, color='skyblue', edgecolor='black')\n",
        "\n",
        "plt.title('Distribution of Chinese Noun Character Length (CUV-T)')\n",
        "plt.xlabel('Number of Characters in Lemma')\n",
        "plt.ylabel('Number of Nouns')\n",
        "plt.xticks(range(1, chinese_freq_df['lemma_length'].max() + 1))\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "plot_filename = FIG_DIR / \"chinese_char_length_distribution.png\"\n",
        "plt.savefig(plot_filename, dpi=300)\n",
        "print(f\"Saved plot to {plot_filename}\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "fE-oawe4PyCf",
        "outputId": "4deb4cab-677a-4fcb-af81-030381a6201f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No Noto Sans CJK font found. Chinese characters might not display correctly.\n",
            "Saved plot to /content/output/figures/chinese_char_length_distribution.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdAtJREFUeJzt3XlcVHX7//H3mYEBRAEXQBFFXFJxw+02Ms3SJLOyssyyNLMdK7Ss7Fdu3bmVpZZp3ZVad5ZLaaapmabeuaUGua9hZIi7EC5sc35/+GVyBJRRTii+no8H96O5zmfOXBccuH3POTNjmKZpCgAAAAAAFDtbSTcAAAAAAEBpRegGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AZQ6g0ZMkSGYfwjj9WuXTu1a9fOdXvZsmUyDEOzZs36Rx7/4YcfVo0aNf6Rx7pYGRkZevTRR1W5cmUZhqH4+Phi2W/ez/nw4cMXXFujRg09/PDDxfK4+OcYhqG+ffuWdBuw2MMPP6yyZcte0j6cTqcaNmyoN954o5i6ujx0795d3bp1K+k2AHiI0A3gijJlyhQZhuH68vX1VVhYmGJjYzV+/Hj99ddfxfI4KSkpGjJkiBITE4tlf8Xpcu6tKIYPH64pU6boqaee0meffaaHHnrovOtzc3M1efJktWvXThUqVJCPj49q1Kih3r17a/369f9Q15efvCd0DMPQhg0b8m0vjuDyT9mzZ4+eeOIJ1axZU76+vgoICFDr1q01btw4nTp1qqTbu2Ql8Tv7Tz/h56mTJ09qyJAhWrZsmSX7/+KLL/THH38U+CRNUY+38z3JM2vWLBmGoWXLlik7O1uVKlXS9ddfX2g/pmmqWrVqatasmVs978nCC33lPZn70ksv6auvvtKvv/56Ed8VACXFq6QbAICLMWzYMEVGRio7O1upqalatmyZ4uPj9fbbb2vu3Llq3Lixa+2rr76ql19+2aP9p6SkaOjQoapRo4aio6OLfL/vv//eo8e5GOfr7T//+Y+cTqflPVyKpUuX6tprr9XgwYMvuPbUqVO6++67tXDhQrVt21avvPKKKlSooL1792rGjBmaOnWqkpOTFR4e7lEPO3bskM1Wep53HjJkiL799tuSbuOizJ8/X/fee698fHzUs2dPNWzYUFlZWfrpp580YMAAbdmyRR9++GFJt3lJLvbvSWl28uRJDR06VJLcrg4qLm+++aa6d++uwMBAt7oVx5u3t7fuvfdeffDBB/r9998VERGRb82KFSu0b98+9evXz61+9913q3bt2q7bGRkZeuqpp3TXXXfp7rvvdtVDQ0MlSU2bNlWLFi00ZswYffrppx71CaDkELoBXJE6deqkFi1auG4PHDhQS5cu1W233aY77rhD27Ztk5+fnyTJy8tLXl7W/rk7efKkypQpI4fDYenjXIi3t3eJPn5RHDx4UFFRUUVaO2DAAC1cuFDvvPNOvsvQBw8erHfeeeeievDx8bmo+12OoqOjNW/ePP3yyy/5zqJd7pKSktS9e3dFRERo6dKlqlKlimtbXFycdu/erfnz5/+jPZ04cUL+/v7/6GNerCup139SQkKCfv31V40ZM8atbuXx1qNHD02aNElffPFFgU/yTps2TTabTd27d3erN27c2O1J4sOHD+upp55S48aN9eCDDxb4WN26ddPgwYP1/vvvXzFXswBXu9LzND+Aq95NN92k1157Tb///rv++9//uuoFvaZ78eLFuv766xUUFKSyZcuqbt26euWVVySduSyzZcuWkqTevXu7Lu+bMmWKpDNnZRo2bKgNGzaobdu2KlOmjOu+576mO09ubq5eeeUVVa5cWf7+/rrjjjv0xx9/uK0p7HXGZ+/zQr0V9JruEydO6Pnnn1e1atXk4+OjunXr6q233pJpmm7r8i6lnDNnjho2bCgfHx81aNBACxcuLPgbfo6DBw+qT58+Cg0Nla+vr5o0aaKpU6e6tudd7pqUlKT58+e7et+7d2+B+9u3b58++OAD3XzzzQW+7ttut+uFF17Id5b7+PHjevjhhxUUFKTAwED17t1bJ0+edFtz7vc672ULK1euVP/+/RUcHCx/f3/dddddOnToUL7HXrBggdq0aSN/f3+VK1dOnTt31pYtW9zWpKamqnfv3goPD5ePj4+qVKmiLl265Ju3KPs6n2eeeUbly5fXkCFDirT+/fffV4MGDeTj46OwsDDFxcXp+PHjbmuKcixKf/9MZ8yYoTfeeEPh4eHy9fVV+/bttXv37gv2Mnr0aGVkZOjjjz92C0B5ateureeeey5f/ULH6O+//66nn35adevWlZ+fnypWrKh777033/c+7+e+fPlyPf300woJCXEdT0Xdh3TmmOvXr59q1KghHx8fhYeHq2fPnjp8+PAFf2clae3atbrlllsUGBioMmXK6IYbbtDKlSvdHiPv79jWrVv1wAMPqHz58ue9nLmojh8/rvj4eNffh9q1a2vUqFFuV8zs3btXhmHorbfe0ocffqhatWrJx8dHLVu21Lp16/Ltc+bMmYqKipKvr68aNmyo2bNnu/1t2rt3r4KDgyVJQ4cOdX1Pzj2G//zzT915550qW7asgoOD9cILLyg3N/eCM82ZM0cOh0Nt27Z1q1/s8VYUrVu3Vo0aNTRt2rR827KzszVr1izdeOONCgsLu6j9n+3mm2/WiRMntHjx4kveF4B/Bme6AZQqDz30kF555RV9//33euyxxwpcs2XLFt12221q3Lixhg0bJh8fH+3evdv1j9z69etr2LBhGjRokB5//HG1adNGknTddde59nHkyBF16tRJ3bt314MPPui69K8wb7zxhgzD0EsvvaSDBw9q7Nix6tChgxITE11n5IuiKL2dzTRN3XHHHfrxxx/Vp08fRUdHa9GiRRowYID+/PPPfGeKf/rpJ3399dd6+umnVa5cOY0fP15du3ZVcnKyKlasWGhfp06dUrt27bR792717dtXkZGRmjlzph5++GEdP35czz33nOrXr6/PPvtM/fr1U3h4uJ5//nlJcv3j+1wLFixQTk7OBV/zfa5u3bopMjJSI0aM0C+//KKPPvpIISEhGjVq1AXvmxdgBw8erL1792rs2LHq27evpk+f7lrz2WefqVevXoqNjdWoUaN08uRJTZw4Uddff70SEhJcwaJr167asmWLnnnmGdWoUUMHDx7U4sWLlZyc7FpT1H2dT0BAgPr166dBgwZd8Gz3kCFDNHToUHXo0EFPPfWUduzYoYkTJ2rdunVauXLlRV8pMXLkSNlsNr3wwgtKS0vT6NGj1aNHD61du/a89/v2229Vs2bNQo/fghTlGF23bp1WrVql7t27Kzw8XHv37tXEiRPVrl07bd26VWXKlHHb59NPP63g4GANGjRIJ06c8GgfGRkZatOmjbZt26ZHHnlEzZo10+HDhzV37lzt27fvgr+zS5cuVadOndS8eXMNHjxYNptNkydP1k033aT//e9/+te//uXW67333qs6depo+PDh+Z4489TJkyd1ww036M8//9QTTzyh6tWra9WqVRo4cKD279+vsWPHuq2fNm2a/vrrLz3xxBMyDEOjR4/W3Xffrd9++8117MyfP1/33XefGjVqpBEjRujYsWPq06ePqlat6tpPcHCwJk6cmO8y6rPP+Obm5io2NlatWrXSW2+9pR9++EFjxoxRrVq19NRTT513rlWrVqlhw4b5jueLOd6KyjAMPfDAAxo+fLi2bNmiBg0auLYtXLhQR48eVY8ePYrlsaKiouTn56eVK1fqrrvuKpZ9ArCYCQBXkMmTJ5uSzHXr1hW6JjAw0GzatKnr9uDBg82z/9y98847piTz0KFDhe5j3bp1piRz8uTJ+bbdcMMNpiRz0qRJBW674YYbXLd//PFHU5JZtWpVMz093VWfMWOGKckcN26cqxYREWH26tXrgvs8X2+9evUyIyIiXLfnzJljSjL//e9/u6275557TMMwzN27d7tqkkyHw+FW+/XXX01J5rvvvpvvsc42duxYU5L53//+11XLysoyY2JizLJly7rNHhERYXbu3Pm8+zNN0+zXr58pyUxISLjgWtP8++f8yCOPuNXvuusus2LFim61c7/XecdVhw4dTKfT6daD3W43jx8/bpqmaf71119mUFCQ+dhjj7ntLzU11QwMDHTVjx07Zkoy33zzzUL7Leq+CpN3bM2cOdM8fvy4Wb58efOOO+5wbe/Vq5fp7+/vun3w4EHT4XCYHTt2NHNzc1319957z5RkfvLJJ4V+f/IUdnzXr1/fzMzMdNXHjRtnSjI3bdpUaP9paWmmJLNLly7nnfNsRT1GT548me++q1evNiWZn376qauW93O//vrrzZycHLf1Rd3HoEGDTEnm119/nW993rFU2O+s0+k069SpY8bGxroddydPnjQjIyPNm2++2VXLO77vv//+fI9TkLOPj8K8/vrrpr+/v7lz5063+ssvv2za7XYzOTnZNE3TTEpKMiWZFStWNI8ePepa980335iSzG+//dZVa9SokRkeHm7+9ddfrtqyZctMSW5/mw4dOmRKMgcPHpyvr169epmSzGHDhrnVmzZtajZv3vyCs4eHh5tdu3Z1q13s8RYXF1fgtpkzZ5qSzB9//NFV27JliynJHDhwoNva7t27m76+vmZaWtoFH/N835ezXXPNNWanTp0uuD8AlwcuLwdQ6pQtW/a872IeFBQkSfrmm28u+k3HfHx81Lt37yKv79mzp8qVK+e6fc8996hKlSr67rvvLurxi+q7776T3W7Xs88+61Z//vnnZZqmFixY4Fbv0KGDatWq5brduHFjBQQE6Lfffrvg41SuXFn333+/q+bt7a1nn31WGRkZWr58uce9p6enS5Lb960onnzySbfbbdq00ZEjR1z7O5/HH3/c7aUIbdq0UW5urn7//XdJZ16WcPz4cd1///06fPiw68tut6tVq1b68ccfJUl+fn5yOBxatmyZjh07VuBjFXVfRREYGKj4+HjNnTtXCQkJBa754YcflJWVpfj4eLc3kXvssccUEBBwSa+d7t27t9v7GeSdzT3fcXOxP9+iHKNnXz2SnZ2tI0eOqHbt2goKCtIvv/ySb5+PPfaY7Ha7W62o+/jqq6/UpEmTAs84XuijChMTE7Vr1y498MADOnLkiOsYOHHihNq3b68VK1bk+xt17vF9KWbOnKk2bdqofPnybsdghw4dlJubqxUrVritv++++1S+fHnX7XN/zikpKdq0aZN69uzp9lrjG264QY0aNfK4v4J+ly/0t0g6cyXS2X1KF3+8eSIqKkpNmzbVl19+6aqdOHFCc+fO1W233aaAgIBie6y8nxmAKwOhG0Cpk5GRcd5/WN13331q3bq1Hn30UYWGhqp79+6aMWOGRwG8atWqHr1pWp06ddxuG4ah2rVrF/p65uLy+++/KywsLN/3o379+q7tZ6tevXq+fZQvX77Q4Hj249SpUyffO4IX9jhFkfcPVE8/Bu7cGfL+8X2hGYpy3127dkk68/4BwcHBbl/ff/+9Dh48KOnMkzKjRo3SggULFBoaqrZt22r06NFKTU117buo+yqq5557TkFBQYW+tjvvZ1C3bl23usPhUM2aNS/qZ5TnYr7nxfXzzXu8sx/r1KlTGjRokOt1ypUqVVJwcLCOHz+utLS0fPePjIzMVyvqPvbs2aOGDRt6NEOevGOgV69e+Y6Bjz76SJmZmfn6LajXi7Vr1y4tXLgw32N36NBBkvIdgxf6OecdQ2e/G3eegmrn4+vrm++lJ0X5W5THPOfS+4s93i7k3CdWevTooaSkJK1atUrSmdeXnzx50nVpeW5urlJTU92+srKyPH5c0zQv+KQOgMsHr+kGUKrs27dPaWlp5/0Hnp+fn1asWKEff/xR8+fP18KFCzV9+nTddNNN+v777/Od8SpsH8WtsH9A5ebmFqmn4lDY45z7D9h/Qr169SRJmzZt8uhjli5lhgvdN++Jmc8++0yVK1fOt+7sd8mPj4/X7bffrjlz5mjRokV67bXXNGLECC1dulRNmzb1aF9FkXe2e8iQIYWe7S4qT4/Fi/meBwQEKCwsTJs3b/aot6I81jPPPKPJkycrPj5eMTExCgwMlGEY6t69e4FPrhX0++zpPi5G3n7efPPNQo/xc9+dujj/9jidTt1888168cUXC9x+zTXXuN3+J/8+XMrfvIoVK+YL5xdzvPn4+BT6OfF5b87o6+vrVr///vv14osvatq0abruuus0bdo0lS9fXrfeeqsk6Y8//sj3xMmPP/7o8cemHTt2LN+TuQAuX4RuAKXKZ599JkmKjY097zqbzab27durffv2evvttzV8+HD9v//3//Tjjz+qQ4cOxX4GIe+MVh7TNLV79263Nw4qX758vneRls6cPapZs6brtie9RURE6IcfftBff/3ldrZ7+/btru3FISIiQhs3bpTT6XQ7230pj9OpUyfZ7Xb997//9fjN1KySd1lzSEiI62zghdY///zzev7557Vr1y5FR0drzJgx+u9//+vxvooiPj5eY8eO1dChQ10vo8iT9zPYsWOH2/GUlZWlpKQktx6Keixeqttuu00ffvihVq9erZiYmGLb76xZs9SrVy+3j4w6ffp0gTNd6j5q1ap1wSBX2O9s3jEQEBBQbMeAJ2rVqqWMjIxie+y8Y6ygd64/t2blWdp69eopKSkpX93T4y0iIkI7duwocFte/dy/bWFhYbrxxhs1c+ZMvfbaa1q8eLEefvhh15VRlStXzveu402aNCnSXHlycnL0xx9/6I477vDofgBKDpeXAyg1li5dqtdff12RkZHnfZfYo0eP5qvlnWXKzMyUJNdn33ryj/Tz+fTTT90ua5w1a5b279+vTp06uWq1atXSmjVr3C41nDdvXr6PFvOkt1tvvVW5ubl677333OrvvPOODMNwe/xLceuttyo1NdXtXb5zcnL07rvvqmzZsrrhhhs83me1atX02GOP6fvvv9e7776bb7vT6dSYMWO0b9++S+rdE7GxsQoICNDw4cOVnZ2db3vex4udPHlSp0+fdttWq1YtlStXznWMFXVfnsg72/3NN98oMTHRbVuHDh3kcDg0fvx4tzOTH3/8sdLS0tS5c2e3XotyLF6qF198Uf7+/nr00Ud14MCBfNv37NmjcePGebxfu92e7+zru+++W6SPm/J0H127dtWvv/6q2bNn59tH3v0L+51t3ry5atWqpbfeeksZGRn57n8xx4AnunXrptWrV2vRokX5th0/flw5OTke7S8sLEwNGzbUp59+6jbP8uXLtWnTJre1ee/+Xlx/Y88WExOjzZs3u37X8nh6vN16661as2aNNmzY4Lbu+PHj+vzzzxUdHV3gVSo9evTQwYMH9cQTTyg7O9vt/498fX3VoUMHt69zX39+IVu3btXp06cteRd2ANbgTDeAK9KCBQu0fft25eTk6MCBA1q6dKkWL16siIgIzZ07N98lf2cbNmyYVqxYoc6dOysiIkIHDx7U+++/r/DwcNfn3taqVUtBQUGaNGmSypUrJ39/f7Vq1eqiX09ZoUIFXX/99erdu7cOHDigsWPHqnbt2m4fa/boo49q1qxZuuWWW9StWzft2bPH7YxoHk96u/3223XjjTfq//2//6e9e/eqSZMm+v777/XNN98oPj4+374v1uOPP64PPvhADz/8sDZs2KAaNWpo1qxZWrlypcaOHXvRb140ZswY7dmzR88++6y+/vpr3XbbbSpfvrySk5M1c+ZMbd++Xd27dy+WGYoiICBAEydO1EMPPaRmzZqpe/fuCg4OVnJysubPn6/WrVvrvffe086dO9W+fXt169ZNUVFR8vLy0uzZs3XgwAFXv0Xdl6eee+45vfPOO/r1119dYU868zFNAwcO1NChQ3XLLbfojjvu0I4dO/T++++rZcuWevDBB11ri3osXqpatWpp2rRpuu+++1S/fn317NlTDRs2VFZWllatWuX62DlP3Xbbbfrss88UGBioqKgorV69Wj/88MN5P/buYvcxYMAAzZo1S/fee68eeeQRNW/eXEePHtXcuXM1adIkNWnS5Ly/sx999JE6deqkBg0aqHfv3qpatar+/PNP/fjjjwoICNC3337r8fxn++qrr1xXnJytV69eGjBggOtNvh5++GE1b95cJ06c0KZNmzRr1izt3btXlSpV8ujxhg8fri5duqh169bq3bu3jh07pvfee08NGzZ0C+J+fn6KiorS9OnTdc0116hChQpq2LDhRb8+/mxdunTR66+/ruXLl6tjx46uuqfH28svv6yZM2eqbdu2euKJJ1SvXj2lpKRoypQp2r9/vyZPnlzg43ft2lVPP/20vvnmG1WrVi3f54VfqsWLF6tMmTK6+eabi3W/ACxUEm+ZDgAXK+8jfvK+HA6HWblyZfPmm282x40b5/bRVHnO/ciwJUuWmF26dDHDwsJMh8NhhoWFmffff3++j8355ptvzKioKNPLy8vt435uuOEGs0GDBgX2V9hHKn3xxRfmwIEDzZCQENPPz8/s3Lmz+fvvv+e7/5gxY8yqVauaPj4+ZuvWrc3169fn2+f5ejv3I8NM88xHU/Xr188MCwszvb29zTp16phvvvmm20cUmWbhH49T2MdHnevAgQNm7969zUqVKpkOh8Ns1KhRgR9rVtSPDMuTk5NjfvTRR2abNm3MwMBA09vb24yIiDB79+7t9nFieT/ncz8KLu+YSUpKKnSmwj6KLu/nd/bHAuXVY2NjzcDAQNPX19esVauW+fDDD5vr1683TdM0Dx8+bMbFxZn16tUz/f39zcDAQLNVq1bmjBkz8s13oX0V5nwfCZX3vTj7I8PyvPfee2a9evVMb29vMzQ01HzqqafMY8eO5VtXlGOxsB7yPmKqoJ9/QXbu3Gk+9thjZo0aNUyHw2GWK1fObN26tfnuu++ap0+fdq0r6jF67Ngx17FYtmxZMzY21ty+fXuRf+6e7MM0TfPIkSNm3759zapVq5oOh8MMDw83e/XqZR4+fNi1prDfWdM0zYSEBPPuu+82K1asaPr4+JgRERFmt27dzCVLlrjWFHZ8FybvZ1PY1//+9z/TNM/8fRg4cKBZu3Zt0+FwmJUqVTKvu+4686233jKzsrJM0/z751nQR+CpgI+3+vLLL8169eqZPj4+ZsOGDc25c+eaXbt2NevVq+e2btWqVWbz5s1Nh8Phtp9zP+7u3O9BUTRu3Njs06dPgduKeryZpmnu27fPfPTRR82qVauaXl5eZoUKFczbbrvNXLNmzXkf/9577zUlmS+++GKR+s1TlI8Ma9Wqlfnggw96tF8AJcswzRJ4dxwAAABcNaKjoxUcHJzv9cxW+eyzzxQXF6fk5OR8729wJUtMTFSzZs30yy+/ePQGkwBKFq/pBgAAQLHIzs7O91rwZcuW6ddff/X4HbovRY8ePVS9enVNmDDhH3vMf8LIkSN1zz33ELiBKwxnugEAAFAs9u7dqw4dOujBBx9UWFiYtm/frkmTJikwMFCbN2/26HX1AFBa8EZqAAAAKBbly5dX8+bN9dFHH+nQoUPy9/dX586dNXLkSAI3gKsWZ7oBAAAAALAIr+kGAAAAAMAihG4AAAAAACzCa7qLwOl0KiUlReXKlZNhGCXdDgAAAACghJmmqb/++kthYWGy2Qo/n03oLoKUlBRVq1atpNsAAAAAAFxm/vjjD4WHhxe6ndBdBOXKlZN05psZEBBQwt0AAAAAAEpaenq6qlWr5sqLhSF0F0HeJeUBAQGEbgAAAACAy4VegswbqQEAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFvEq6QYA/LOSk5N1+PDhkm4Dl7FKlSqpevXqJd0GAABAqUDoBq4iycnJqle/vk6dPFnSreAy5lemjLZv20bwBgAAKAaEbuAqcvjwYZ06eVJPv/WhwmpdU9Lt4DKUsmen3n/hcR0+fJjQDQAAUAwI3cBVKKzWNYpsEF3SbQAAAAClHm+kBgAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYpMRD959//qkHH3xQFStWlJ+fnxo1aqT169e7tpumqUGDBqlKlSry8/NThw4dtGvXLrd9HD16VD169FBAQICCgoLUp08fZWRkuK3ZuHGj2rRpI19fX1WrVk2jR4/+R+YDAAAAAFy9SjR0Hzt2TK1bt5a3t7cWLFigrVu3asyYMSpfvrxrzejRozV+/HhNmjRJa9eulb+/v2JjY3X69GnXmh49emjLli1avHix5s2bpxUrVujxxx93bU9PT1fHjh0VERGhDRs26M0339SQIUP04Ycf/qPzAgAAAACuLl4l+eCjRo1StWrVNHnyZFctMjLS9d+maWrs2LF69dVX1aVLF0nSp59+qtDQUM2ZM0fdu3fXtm3btHDhQq1bt04tWrSQJL377ru69dZb9dZbbyksLEyff/65srKy9Mknn8jhcKhBgwZKTEzU22+/7RbOAQAAAAAoTiUauufOnavY2Fjde++9Wr58uapWraqnn35ajz32mCQpKSlJqamp6tChg+s+gYGBatWqlVavXq3u3btr9erVCgoKcgVuSerQoYNsNpvWrl2ru+66S6tXr1bbtm3lcDhca2JjYzVq1CgdO3bM7cy6JGVmZiozM9N1Oz09XZKUk5OjnJwcSZLNZpPNZpPT6ZTT6XStzavn5ubKNM0L1u12uwzDcO337Lok5ebmFqnu5eUl0zTd6oZhyG635+uxsDozlf6ZnE6nHA6HDJmSaUqGITnde5TxfxfAmM6i1W32M/sqsO48s+1CdcM4s//C6vl6LKxuY6ZLnMmQKW9vb0ni94mZmImZmImZmImZmOk89bP/+3xKNHT/9ttvmjhxovr3769XXnlF69at07PPPiuHw6FevXopNTVVkhQaGup2v9DQUNe21NRUhYSEuG338vJShQoV3NacfQb97H2mpqbmC90jRozQ0KFD8/WbkJAgf39/SVJwcLBq1aqlpKQkHTp0yLUmPDxc4eHh2rlzp9LS0lz1mjVrKiQkRJs3b9apU6dc9Xr16ikoKEgJCQluP/DGjRvL4XC4vb5dklq0aKGsrCxt3LjRVbPb7WrZsqXS0tK0fft2V93Pz09NmjTR4cOH9dtvv7nqgYGBql+/vlJSUrRv3z5XnZlK/0xHjhzRgAEDVE0nZDudIadfOfmkbJfO+oORVaWOTLu3fPZtdZspMzxKRm62HPvPek8Fm02Z4Q1kO50h70N7XWXT20dZVa6R/cRxeR3901V3+pZVdkik7OmH5JV20FXP9S+vnIrh8jqaIvuJY656TmCIcgND5X04WbbTf79PQ06FqsotW0GOA3tkZP/9BFl2cA1musSZqumE7rnnHkni94mZmImZmImZmImZmOk8M/n6+qooDPPspw3+YQ6HQy1atNCqVatctWeffVbr1q3T6tWrtWrVKrVu3VopKSmqUqWKa023bt1kGIamT5+u4cOHa+rUqdqxY4fbvkNCQjR06FA99dRT6tixoyIjI/XBBx+4tm/dulUNGjTQ1q1bVb9+fbf7FnSmu1q1ajpy5IgCAgIklc5napip9M+UkJCg1q1ba/D0RaoRFc1ZYWbK1/vebRs1pFtHrVmzRtHR0fw+MRMzMRMzMRMzMRMzFVLPyMhQ+fLllZaW5sqJBSnRM91VqlRRVFSUW61+/fr66quvJEmVK1eWJB04cMAtdB84cEDR0dGuNQcPHnTbR05Ojo4ePeq6f+XKlXXgwAG3NXm389aczcfHRz4+PvnqXl5e8vJy/5blHQznyvvhFrV+7n4vpm4YRoH1wnr0tM5MV/5MNptNWVlZMmWcCXLSmdBVEMODumEUUrdJRkH78LBeWI+e1pnpgjOZMpSdnX3mIfl9YqZCevS0zkzMJDFTYT16WmcmZpKYqbAePa1f6kwFrSlIib57eevWrfOdod65c6ciIiIknXlTtcqVK2vJkiWu7enp6Vq7dq1iYmIkSTExMTp+/Lg2bNjgWrN06VI5nU61atXKtWbFihWuf0hK0uLFi1W3bt18l5YDAAAAAFBcSjR09+vXT2vWrNHw4cO1e/duTZs2TR9++KHi4uIknXnmIT4+Xv/+9781d+5cbdq0ST179lRYWJjuvPNOSWfOjN9yyy167LHH9PPPP2vlypXq27evunfvrrCwMEnSAw88IIfDoT59+mjLli2aPn26xo0bp/79+5fU6AAAAACAq0CJXl7esmVLzZ49WwMHDtSwYcMUGRmpsWPHqkePHq41L774ok6cOKHHH39cx48f1/XXX6+FCxe6vWj9888/V9++fdW+fXvZbDZ17dpV48ePd20PDAzU999/r7i4ODVv3lyVKlXSoEGD+LgwAAAAAIClSvSN1K4U6enpCgwMvOAL5IHL3S+//KLmzZvr37OXKbJBdEm3g8tQ0pZEvXpXO23YsEHNmjUr6XYAAAAuW0XNiSV6eTkAAAAAAKUZoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwSImG7iFDhsgwDLevevXqubafPn1acXFxqlixosqWLauuXbvqwIEDbvtITk5W586dVaZMGYWEhGjAgAHKyclxW7Ns2TI1a9ZMPj4+ql27tqZMmfJPjAcAAAAAuMqV+JnuBg0aaP/+/a6vn376ybWtX79++vbbbzVz5kwtX75cKSkpuvvuu13bc3Nz1blzZ2VlZWnVqlWaOnWqpkyZokGDBrnWJCUlqXPnzrrxxhuVmJio+Ph4Pfroo1q0aNE/OicAAAAA4OrjVeINeHmpcuXK+eppaWn6+OOPNW3aNN10002SpMmTJ6t+/fpas2aNrr32Wn3//ffaunWrfvjhB4WGhio6Olqvv/66XnrpJQ0ZMkQOh0OTJk1SZGSkxowZI0mqX7++fvrpJ73zzjuKjY39R2cFAAAAAFxdSvxM965duxQWFqaaNWuqR48eSk5OliRt2LBB2dnZ6tChg2ttvXr1VL16da1evVqStHr1ajVq1EihoaGuNbGxsUpPT9eWLVtca87eR96avH0AAAAAAGCVEj3T3apVK02ZMkV169bV/v37NXToULVp00abN29WamqqHA6HgoKC3O4TGhqq1NRUSVJqaqpb4M7bnrftfGvS09N16tQp+fn55esrMzNTmZmZrtvp6emSpJycHNfrxW02m2w2m5xOp5xOp2ttXj03N1emaV6wbrfbZRhGvteh2+12SWcuoS9K3cvLS6ZputUNw5Ddbs/XY2F1Zir9MzmdTjkcDhkyJdOUDENyuvco4/+eizOdRavb7Gf2VWDdeWbbheqGcWb/hdXz9VhY3cZMlziTIVPe3t6SxO8TMzETMzETMzETMzHTeepn//f5lGjo7tSpk+u/GzdurFatWikiIkIzZswoMAz/U0aMGKGhQ4fmqyckJMjf31+SFBwcrFq1aikpKUmHDh1yrQkPD1d4eLh27typtLQ0V71mzZoKCQnR5s2bderUKVe9Xr16CgoKUkJCgtsPvHHjxnI4HFq/fr1bDy1atFBWVpY2btzoqtntdrVs2VJpaWnavn27q+7n56cmTZro8OHD+u2331z1wMBA1a9fXykpKdq3b5+rzkylf6YjR45owIABqqYTsp3OkNOvnHxStktn/cHIqlJHpt1bPvu2us2UGR4lIzdbjv27/i7abMoMbyDb6Qx5H9rrKpvePsqqco3sJ47L6+ifrrrTt6yyQyJlTz8kr7SDrnquf3nlVAyX19EU2U8cc9VzAkOUGxgq78PJsp3O+Lteoapyy1aQ48AeGdl/P0GWHVyDmS5xpmo6oXvuuUeS+H1iJmZiJmZiJmZiJmY6z0y+vr4qCsM8+2mDy0DLli3VoUMH3XzzzWrfvr2OHTvmdrY7IiJC8fHx6tevnwYNGqS5c+cqMTHRtT0pKUk1a9bUL7/8oqZNm6pt27Zq1qyZxo4d61ozefJkxcfHu/1Qz1bQme5q1arpyJEjCggIkFQ6n6lhptI/U0JCglq3bq3B0xepRlQ0Z4WZKV/ve7dt1JBuHbVmzRpFR0fz+8RMzMRMzMRMzMRMzFRIPSMjQ+XLl1daWporJxakxN9I7WwZGRnas2ePHnroITVv3lze3t5asmSJunbtKknasWOHkpOTFRMTI0mKiYnRG2+8oYMHDyokJESStHjxYgUEBCgqKsq15rvvvnN7nMWLF7v2URAfHx/5+Pjkq3t5ecnLy/1blncwnCvvh1vU+rn7vZi6YRgF1gvr0dM6M135M9lsNmVlZcmUcSbISWdCV0EMD+qGUUjdJhkF7cPDemE9elpnpgvOZMpQdnb2mYfk94mZCunR0zozMZPETIX16GmdmZhJYqbCevS0fqkzFbSmICX6RmovvPCCli9frr1792rVqlW66667ZLfbdf/99yswMFB9+vRR//799eOPP2rDhg3q3bu3YmJidO2110qSOnbsqKioKD300EP69ddftWjRIr366quKi4tzheYnn3xSv/32m1588UVt375d77//vmbMmKF+/fqV5OgAAAAAgKtAiZ7p3rdvn+6//34dOXJEwcHBuv7667VmzRoFBwdLkt555x3ZbDZ17dpVmZmZio2N1fvvv++6v91u17x58/TUU08pJiZG/v7+6tWrl4YNG+ZaExkZqfnz56tfv34aN26cwsPD9dFHH/FxYQAAAAAAy5Vo6P7yyy/Pu93X11cTJkzQhAkTCl0TERGR7/Lxc7Vr104JCQkX1SMAAAAAABerxD+nGwAAAACA0orQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFjE49C9cOFC/fTTT67bEyZMUHR0tB544AEdO3asWJsDAAAAAOBK5nHoHjBggNLT0yVJmzZt0vPPP69bb71VSUlJ6t+//0U3MnLkSBmGofj4eFft9OnTiouLU8WKFVW2bFl17dpVBw4ccLtfcnKyOnfurDJlyigkJEQDBgxQTk6O25ply5apWbNm8vHxUe3atTVlypSL7hMAAAAAgKLyOHQnJSUpKipKkvTVV1/ptttu0/DhwzVhwgQtWLDgoppYt26dPvjgAzVu3Nit3q9fP3377beaOXOmli9frpSUFN19992u7bm5uercubOysrK0atUqTZ06VVOmTNGgQYPc+u3cubNuvPFGJSYmKj4+Xo8++qgWLVp0Ub0CAAAAAFBUHoduh8OhkydPSpJ++OEHdezYUZJUoUIF1xlwT2RkZKhHjx76z3/+o/Lly7vqaWlp+vjjj/X222/rpptuUvPmzTV58mStWrVKa9askSR9//332rp1q/773/8qOjpanTp10uuvv64JEyYoKytLkjRp0iRFRkZqzJgxql+/vvr27at77rlH77zzjse9AgAAAADgCY9D9/XXX6/+/fvr9ddf188//6zOnTtLknbu3Knw8HCPG4iLi1Pnzp3VoUMHt/qGDRuUnZ3tVq9Xr56qV6+u1atXS5JWr16tRo0aKTQ01LUmNjZW6enp2rJli2vNufuOjY117QMAAAAAAKt4eXqH9957T08//bRmzZqliRMnqmrVqpKkBQsW6JZbbvFoX19++aV++eUXrVu3Lt+21NRUORwOBQUFudVDQ0OVmprqWnN24M7bnrftfGvS09N16tQp+fn55XvszMxMZWZmum7nncHPyclxvV7cZrPJZrPJ6XTK6XS61ubVc3NzZZrmBet2u12GYeR7Hbrdbpd05hL6otS9vLxkmqZb3TAM2e32fD0WVmem0j+T0+mUw+GQIVMyTckwJKd7jzL+77k401m0us1+Zl8F1p1ntl2obhhn9l9YPV+PhdVtzHSJMxky5e3tLUn8PjETMzETMzETMzETM52nfvZ/n4/Hobt69eqaN29evrqnl2v/8ccfeu6557R48WL5+vp62oalRowYoaFDh+arJyQkyN/fX5IUHBysWrVqKSkpSYcOHXKtCQ8PV3h4uHbu3Km0tDRXvWbNmgoJCdHmzZt16tQpV71evXoKCgpSQkKC2w+8cePGcjgcWr9+vVsPLVq0UFZWljZu3Oiq2e12tWzZUmlpadq+fbur7ufnpyZNmujw4cP67bffXPXAwEDVr19fKSkp2rdvn6vOTKV/piNHjmjAgAGqphOync6Q06+cfFK2S2f9wciqUkem3Vs++7a6zZQZHiUjN1uO/bv+LtpsygxvINvpDHkf2usqm94+yqpyjewnjsvr6J+uutO3rLJDImVPPySvtIOueq5/eeVUDJfX0RTZT/z9KQg5gSHKDQyV9+Fk2U5n/F2vUFW5ZSvIcWCPjOy/nyDLDq7BTJc4UzWd0D333CNJ/D4xEzMxEzMxEzMxEzOdZ6ai5ljDPPtpgyJyOp3avXu3Dh48mC/dt23btkj7mDNnju666y7XMw/SmWcfDMOQzWbTokWL1KFDBx07dsztbHdERITi4+PVr18/DRo0SHPnzlViYqJre1JSkmrWrKlffvlFTZs2Vdu2bdWsWTONHTvWtWby5MmKj493+6GeraAz3dWqVdORI0cUEBAgqXQ+U8NMpX+mhIQEtW7dWoOnL1KNqGjOCjNTvt73btuoId06as2aNYqOjub3iZmYiZmYiZmYiZmYqZB6RkaGypcvr7S0NFdOLIjHZ7rXrFmjBx54QL///rvb8HnNnDtMYdq3b69Nmza51Xr37q169erppZdeUrVq1eTt7a0lS5aoa9eukqQdO3YoOTlZMTExkqSYmBi98cYbOnjwoEJCQiRJixcvVkBAgOsd1mNiYvTdd9+5Pc7ixYtd+yiIj4+PfHx88tW9vLzk5eX+Lcs7GM519pMJRamfu9+LqRuGUWC9sB49rTPTlT+TzWZTVlaWTBlngpx0JnQVxPCgbhiF1G2SUdA+PKwX1qOndWa64EymDGVnZ595SH6fmKmQHj2tMxMzScxUWI+e1pmJmSRmKqxHT+uXOlNBawp87CKtOsuTTz6pFi1aaP78+apSpYoMo6B/TV5YuXLl1LBhQ7eav7+/Klas6Kr36dNH/fv3V4UKFRQQEKBnnnlGMTExuvbaayVJHTt2VFRUlB566CGNHj1aqampevXVVxUXF+cKzU8++aTee+89vfjii3rkkUe0dOlSzZgxQ/Pnz7+ovgEAAAAAKCqPQ/euXbs0a9Ys1a5d24p+3Lzzzjuy2Wzq2rWrMjMzFRsbq/fff9+13W63a968eXrqqacUExMjf39/9erVS8OGDXOtiYyM1Pz589WvXz+NGzdO4eHh+uijjxQbG2t5/wAAAACAq5vHobtVq1bavXu3JaF72bJlbrd9fX01YcIETZgwodD7RERE5Lt8/Fzt2rVTQkJCcbQIAAAAAECReRy6n3nmGT3//PNKTU1Vo0aNXB8tk6dx48bF1hwAAAAAAFcyj0N33puaPfLII66aYRgyTdOjN1IDAAAAAKC08zh0JyUlWdEHAAAAAACljsehOyIiwoo+AAAAAAAodTwO3Z9++ul5t/fs2fOimwEAAAAAoDTxOHQ/99xzbrezs7N18uRJORwOlSlThtANAAAAAMD/sXl6h2PHjrl9ZWRkaMeOHbr++uv1xRdfWNEjAAAAAABXJI9Dd0Hq1KmjkSNH5jsLDgAAAADA1axYQrckeXl5KSUlpbh2BwAAAADAFc/j13TPnTvX7bZpmtq/f7/ee+89tW7dutgaAwAAAADgSudx6L7zzjvdbhuGoeDgYN10000aM2ZMcfUFAAAAAMAVz+PQ7XQ6regDAAAAAIBS55Je022apkzTLK5eAAAAAAAoVS4qdH/66adq1KiR/Pz85Ofnp8aNG+uzzz4r7t4AAAAAALiieXx5+dtvv63XXntNffv2db1x2k8//aQnn3xShw8fVr9+/Yq9SQAAAAAArkQeh+53331XEydOVM+ePV21O+64Qw0aNNCQIUMI3QAAAAAA/B+PLy/fv3+/rrvuunz16667Tvv37y+WpgAAAAAAKA08Dt21a9fWjBkz8tWnT5+uOnXqFEtTAAAAAACUBh5fXj506FDdd999WrFihes13StXrtSSJUsKDOMAAAAAAFytPD7T3bVrV61du1aVKlXSnDlzNGfOHFWqVEk///yz7rrrLit6BAAAAADgiuTxmW5Jat68uf773/8Wdy8AAAAAAJQqF/U53QAAAAAA4MKKfKbbZrPJMIzzrjEMQzk5OZfcFAAAAAAApUGRQ/fs2bML3bZ69WqNHz9eTqezWJoCAAAAAKA0KHLo7tKlS77ajh079PLLL+vbb79Vjx49NGzYsGJtDgAAAACAK9lFvaY7JSVFjz32mBo1aqScnBwlJiZq6tSpioiIKO7+AAAAAAC4YnkUutPS0vTSSy+pdu3a2rJli5YsWaJvv/1WDRs2tKo/AAAAAACuWEW+vHz06NEaNWqUKleurC+++KLAy80BAAAAAMDfihy6X375Zfn5+al27dqaOnWqpk6dWuC6r7/+utiaAwAAAADgSlbk0N2zZ88LfmQYAAAAAAD4W5FD95QpUyxsAwAAAACA0uei3r0cAAAAAABcGKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsUKXQ3a9ZMx44dkyQNGzZMJ0+etLQpAAAAAABKgyKF7m3btunEiROSpKFDhyojI8PSpgAAAAAAKA2K9JFh0dHR6t27t66//nqZpqm33npLZcuWLXDtoEGDirVBAAAAAACuVEUK3VOmTNHgwYM1b948GYahBQsWyMsr/10NwyB0AwAAAADwf4oUuuvWrasvv/xSkmSz2bRkyRKFhIRY2hgAAAAAAFe6IoXuszmdTiv6AAAAAACg1PE4dEvSnj17NHbsWG3btk2SFBUVpeeee061atUq1uYAAAAAALiSefw53YsWLVJUVJR+/vlnNW7cWI0bN9batWvVoEEDLV682IoeAQAAAAC4Inl8pvvll19Wv379NHLkyHz1l156STfffHOxNQcAAAAAwJXM4zPd27ZtU58+ffLVH3nkEW3durVYmgIAAAAAoDTwOHQHBwcrMTExXz0xMZF3NAcAAAAA4CweX17+2GOP6fHHH9dvv/2m6667TpK0cuVKjRo1Sv379y/2BgEAAAAAuFJ5HLpfe+01lStXTmPGjNHAgQMlSWFhYRoyZIieffbZYm8QAAAAAIArlceh2zAM9evXT/369dNff/0lSSpXrlyxNwYAAAAAwJXuoj6nOw9hGwAAAACAwnn8RmoAAAAAAKBoCN0AAAAAAFiE0A0AAAAAgEU8Ct3Z2dlq3769du3aZVU/AAAAAACUGh6Fbm9vb23cuNGqXgAAAAAAKFU8vrz8wQcf1Mcff2xFLwAAAAAAlCoef2RYTk6OPvnkE/3www9q3ry5/P393ba//fbbxdYcAAAAAABXMo9D9+bNm9WsWTNJ0s6dO922GYZRPF0BAAAAAFAKeBy6f/zxRyv6AAAAAACg1LnojwzbvXu3Fi1apFOnTkmSTNMstqYAAAAAACgNPA7dR44cUfv27XXNNdfo1ltv1f79+yVJffr00fPPP1/sDQIAAAAAcKXyOHT369dP3t7eSk5OVpkyZVz1++67TwsXLizW5gAAAAAAuJJ5/Jru77//XosWLVJ4eLhbvU6dOvr999+LrTEAAAAAAK50Hp/pPnHihNsZ7jxHjx6Vj49PsTQFAAAAAEBp4HHobtOmjT799FPXbcMw5HQ6NXr0aN14443F2hwAAAAAAFcyjy8vHz16tNq3b6/169crKytLL774orZs2aKjR49q5cqVVvQIAAAAAMAVyeMz3Q0bNtTOnTt1/fXXq0uXLjpx4oTuvvtuJSQkqFatWh7ta+LEiWrcuLECAgIUEBCgmJgYLViwwLX99OnTiouLU8WKFVW2bFl17dpVBw4ccNtHcnKyOnfurDJlyigkJEQDBgxQTk6O25ply5apWbNm8vHxUe3atTVlyhRPxwYAAAAAwGMen+mWpMDAQP2///f/LvnBw8PDNXLkSNWpU0emaWrq1Knq0qWLEhIS1KBBA/Xr10/z58/XzJkzFRgYqL59++ruu+92nVHPzc1V586dVblyZa1atUr79+9Xz5495e3treHDh0uSkpKS1LlzZz355JP6/PPPtWTJEj366KOqUqWKYmNjL3kGAAAAAAAKY5imaXp6p2PHjunjjz/Wtm3bJElRUVHq3bu3KlSocMkNVahQQW+++abuueceBQcHa9q0abrnnnskSdu3b1f9+vW1evVqXXvttVqwYIFuu+02paSkKDQ0VJI0adIkvfTSSzp06JAcDodeeuklzZ8/X5s3b3Y9Rvfu3XX8+PEif8RZenq6AgMDlZaWpoCAgEueESgpv/zyi5o3b65/z16myAbRJd0OLkNJWxL16l3ttGHDBjVr1qyk2wEAALhsFTUnenyme8WKFbr99tsVGBioFi1aSJLGjx+vYcOG6dtvv1Xbtm0vquHc3FzNnDlTJ06cUExMjDZs2KDs7Gx16NDBtaZevXqqXr26K3SvXr1ajRo1cgVuSYqNjdVTTz2lLVu2qGnTplq9erXbPvLWxMfHF9pLZmamMjMzXbfT09MlSTk5Oa5L1202m2w2m5xOp5xOp2ttXj03N1dnP59RWN1ut8swjHyXxNvtdtf3pSh1Ly8vmabpVjcMQ3a7PV+PhdWZqfTP5HQ65XA4ZMiUTFMyDMnp3qOM/3vVieksWt1mP7OvAuvOM9suVDeMM/svrJ6vx8LqNma6xJkMmfL29pYkfp+YiZmYiZmYiZmYiZnOUz/7v8/H49AdFxen++67TxMnTnQb4Omnn1ZcXJw2bdrk0f42bdqkmJgYnT59WmXLltXs2bMVFRWlxMREORwOBQUFua0PDQ1VamqqJCk1NdUtcOdtz9t2vjXp6ek6deqU/Pz88vU0YsQIDR06NF89ISFB/v7+kqTg4GDVqlVLSUlJOnTokGtNeHi4wsPDtXPnTqWlpbnqNWvWVEhIiDZv3qxTp0656vXq1VNQUJASEhLcfuCNGzeWw+HQ+vXr3Xpo0aKFsrKytHHjRlfNbrerZcuWSktL0/bt2111Pz8/NWnSRIcPH9Zvv/3mqgcGBqp+/fpKSUnRvn37XHVmKv0zHTlyRAMGDFA1nZDtdIacfuXkk7JdOusPRlaVOjLt3vLZt9VtpszwKBm52XLs3/V30WZTZngD2U5nyPvQXlfZ9PZRVpVrZD9xXF5H/3TVnb5llR0SKXv6IXmlHXTVc/3LK6diuLyOpsh+4pirnhMYotzAUHkfTpbtdMbf9QpVlVu2ghwH9sjI/vsJsuzgGsx0iTNV0wnX1UX8PjETMzETMzETMzETMxU+k6+vr4rC48vL/fz8lJiYqLp167rVd+zYoejoaLdvSFFkZWUpOTlZaWlpmjVrlj766CMtX75ciYmJ6t27t9sZZ0n617/+pRtvvFGjRo3S448/rt9//12LFi1ybT958qT8/f313XffqVOnTrrmmmvUu3dvDRw40LXmu+++U+fOnXXy5MkCQ3dBZ7qrVaumI0eOuC4bKI3P1DBT6Z8pISFBrVu31uDpi1QjKpqzwsyUr/e92zZqSLeOWrNmjaKjo/l9YiZmYiZmYiZmYiZmKqSekZGh8uXLF//l5c2aNdO2bdvyhe5t27apSZMmnu5ODodDtWvXliQ1b95c69at07hx43TfffcpKytLx48fdzvbfeDAAVWuXFmSVLlyZf38889u+8t7d/Oz15z7jucHDhxQQEBAgYFbknx8fOTj45Ov7uXlJS8v929Z3sFwrrwfblHr5+73YuqGYRRYL6xHT+vMdOXPZLPZlJWVJVPGmSAnnQldBTE8qBtGIXWbZBS0Dw/rhfXoaZ2ZLjiTKUPZ2dlnHpLfJ2YqpEdP68zETBIzFdajp3VmYiaJmQrr0dP6pc5U0JoCH7soi84+Ff/ss8/queee0+7du3XttddKktasWaMJEyZo5MiRRXrQ83E6ncrMzFTz5s3l7e2tJUuWqGvXrpLOnE1PTk5WTEyMJCkmJkZvvPGGDh48qJCQEEnS4sWLFRAQoKioKNea7777zu0xFi9e7NoHAAAAAABWKVLojo6OlmEYbqf1X3zxxXzrHnjgAd13331FfvCBAweqU6dOql69uv766y9NmzZNy5Yt06JFixQYGKg+ffqof//+qlChggICAvTMM88oJibGFfY7duyoqKgoPfTQQxo9erRSU1P16quvKi4uznWm+sknn9R7772nF198UY888oiWLl2qGTNmaP78+UXuEwAAAACAi1Gk0J2UlGTJgx88eFA9e/bU/v37FRgYqMaNG2vRokW6+eabJUnvvPOObDabunbtqszMTMXGxur999933d9ut2vevHl66qmnFBMTI39/f/Xq1UvDhg1zrYmMjNT8+fPVr18/jRs3TuHh4froo4/4jG4AAAAAgOWKFLojIiIsefCPP/74vNt9fX01YcIETZgwodA1ERER+S4fP1e7du2UkJBwUT0CAAAAAHCxPH4jNenMx8j89NNPOnjwYL7PJnv22WeLpTEAAAAAAK50HofuKVOm6IknnpDD4VDFihVlGH+/La9hGIRuAAAAAAD+j8eh+7XXXtOgQYM0cODAIr9FOgAAAAAAVyOPU/PJkyfVvXt3AjcAAAAAABfgcXLu06ePZs6caUUvAAAAAACUKh5fXj5ixAjddtttWrhwoRo1aiRvb2+37W+//XaxNQcAAAAAwJXsokL3okWLVLduXUnK90ZqAAAAAADgDI9D95gxY/TJJ5/o4YcftqAdAAAAAABKD49f0+3j46PWrVtb0QsAAAAAAKWKx6H7ueee07vvvmtFLwAAAAAAlCoeX17+888/a+nSpZo3b54aNGiQ743Uvv7662JrDgAAAACAK5nHoTsoKEh33323Fb0AAAAAAFCqeBy6J0+ebEUfAAAAAACUOh6/phsAAAAAABSNx2e6IyMjz/t53L/99tslNQQAAAAAQGnhceiOj493u52dna2EhAQtXLhQAwYMKK6+AAAAAAC44nkcup977rkC6xMmTND69esvuSEAAAAAAEqLYntNd6dOnfTVV18V1+4AAAAAALjiFVvonjVrlipUqFBcuwMAAAAA4Irn8eXlTZs2dXsjNdM0lZqaqkOHDun9998v1uYAAAAAALiSeRy677zzTrfbNptNwcHBateunerVq1dcfQEAAAAAcMXzOHQPHjzYij4AAAAAACh1iu013QAAAAAAwF2Rz3TbbDa313IXxDAM5eTkXHJTAAAAAACUBkUO3bNnzy502+rVqzV+/Hg5nc5iaQoAAAAAgNKgyKG7S5cu+Wo7duzQyy+/rG+//VY9evTQsGHDirU5AAAAAACuZBf1mu6UlBQ99thjatSokXJycpSYmKipU6cqIiKiuPsDAAAAAOCK5VHoTktL00svvaTatWtry5YtWrJkib799ls1bNjQqv4AAAAAALhiFfny8tGjR2vUqFGqXLmyvvjiiwIvNwcAAAAAAH8rcuh++eWX5efnp9q1a2vq1KmaOnVqgeu+/vrrYmsOAAAAAIArWZFDd8+ePS/4kWEAAAAAAOBvRQ7dU6ZMsbANAAAAAABKn4t693IAAAAAAHBhhG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCIlGrpHjBihli1bqly5cgoJCdGdd96pHTt2uK05ffq04uLiVLFiRZUtW1Zdu3bVgQMH3NYkJyerc+fOKlOmjEJCQjRgwADl5OS4rVm2bJmaNWsmHx8f1a5dW1OmTLF6PAAAAADAVa5EQ/fy5csVFxenNWvWaPHixcrOzlbHjh114sQJ15p+/frp22+/1cyZM7V8+XKlpKTo7rvvdm3Pzc1V586dlZWVpVWrVmnq1KmaMmWKBg0a5FqTlJSkzp0768Ybb1RiYqLi4+P16KOPatGiRf/ovAAAAACAq4tXST74woUL3W5PmTJFISEh2rBhg9q2bau0tDR9/PHHmjZtmm666SZJ0uTJk1W/fn2tWbNG1157rb7//ntt3bpVP/zwg0JDQxUdHa3XX39dL730koYMGSKHw6FJkyYpMjJSY8aMkSTVr19fP/30k9555x3Fxsb+43MDAAAAAK4Ol9VrutPS0iRJFSpUkCRt2LBB2dnZ6tChg2tNvXr1VL16da1evVqStHr1ajVq1EihoaGuNbGxsUpPT9eWLVtca87eR96avH0AAAAAAGCFEj3TfTan06n4+Hi1bt1aDRs2lCSlpqbK4XAoKCjIbW1oaKhSU1Nda84O3Hnb87adb016erpOnTolPz8/t22ZmZnKzMx03U5PT5ck5eTkuF4rbrPZZLPZ5HQ65XQ6XWvz6rm5uTJN84J1u90uwzDyvQbdbrdLOnP5fFHqXl5eMk3TrW4Yhux2e74eC6szU+mfyel0yuFwyJApmaZkGJLTvUcZ//dcnOksWt1mP7OvAuvOM9suVDeMM/svrJ6vx8LqNma6xJkMmfL29pYkfp+YiZmYiZmYiZmYiZnOUz/7v8/nsgndcXFx2rx5s3766aeSbkUjRozQ0KFD89UTEhLk7+8vSQoODlatWrWUlJSkQ4cOudaEh4crPDxcO3fudJ25l6SaNWsqJCREmzdv1qlTp1z1evXqKSgoSAkJCW4/8MaNG8vhcGj9+vVuPbRo0UJZWVnauHGjq2a329WyZUulpaVp+/btrrqfn5+aNGmiw4cP67fffnPVAwMDVb9+faWkpGjfvn2uOjOV/pmOHDmiAQMGqJpOyHY6Q06/cvJJ2S6d9Qcjq0odmXZv+ezb6jZTZniUjNxsOfbv+rtosykzvIFspzPkfWivq2x6+yiryjWynzgur6N/uupO37LKDomUPf2QvNIOuuq5/uWVUzFcXkdTZD9xzFXPCQxRbmCovA8ny3Y64+96harKLVtBjgN7ZGT//QRZdnANZrrEmarphO655x5J4veJmZiJmZiJmZiJmZjpPDP5+vqqKAzz7KcNSkjfvn31zTffaMWKFYqMjHTVly5dqvbt2+vYsWNuZ7sjIiIUHx+vfv36adCgQZo7d64SExNd25OSklSzZk398ssvatq0qdq2batmzZpp7NixrjWTJ09WfHy82w82T0FnuqtVq6YjR44oICBAUul8poaZSv9MCQkJat26tQZPX6QaUdGcFWamfL3v3bZRQ7p11Jo1axQdHc3vEzMxEzMxEzMxEzMxUyH1jIwMlS9fXmlpaa6cWJASPdNtmqaeeeYZzZ49W8uWLXML3JLUvHlzeXt7a8mSJerataskaceOHUpOTlZMTIwkKSYmRm+88YYOHjyokJAQSdLixYsVEBCgqKgo15rvvvvObd+LFy927eNcPj4+8vHxyVf38vKSl5f7tyzvYDhX3g+3qPVz93sxdcMwCqwX1qOndWa68mey2WzKysqSKeNMkJPOhK6CGB7UDaOQuk0yCtqHh/XCevS0zkwXnMmUoezs7DMPye8TMxXSo6d1ZmImiZkK69HTOjMxk8RMhfXoaf1SZypoTYGPXaRVFomLi9O0adP0zTffqFy5cq7XYAcGBsrPz0+BgYHq06eP+vfvrwoVKiggIEDPPPOMYmJidO2110qSOnbsqKioKD300EMaPXq0UlNT9eqrryouLs4VnJ988km99957evHFF/XII49o6dKlmjFjhubPn19iswMAAAAASr8SfffyiRMnKi0tTe3atVOVKlVcX9OnT3eteeedd3Tbbbepa9euatu2rSpXrqyvv/7atd1ut2vevHmy2+2KiYnRgw8+qJ49e2rYsGGuNZGRkZo/f74WL16sJk2aaMyYMfroo4/4uDAAAAAAgKVK/PLyC/H19dWECRM0YcKEQtdERETku3z8XO3atVNCQoLHPQIAAAAAcLEuq8/pBgAAAACgNCF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYJESDd0rVqzQ7bffrrCwMBmGoTlz5rhtN01TgwYNUpUqVeTn56cOHTpo165dbmuOHj2qHj16KCAgQEFBQerTp48yMjLc1mzcuFFt2rSRr6+vqlWrptGjR1s9GgAAAAAAJRu6T5w4oSZNmmjChAkFbh89erTGjx+vSZMmae3atfL391dsbKxOnz7tWtOjRw9t2bJFixcv1rx587RixQo9/vjjru3p6enq2LGjIiIitGHDBr355psaMmSIPvzwQ8vnAwAAAABc3bxK8sE7deqkTp06FbjNNE2NHTtWr776qrp06SJJ+vTTTxUaGqo5c+aoe/fu2rZtmxYuXKh169apRYsWkqR3331Xt956q9566y2FhYXp888/V1ZWlj755BM5HA41aNBAiYmJevvtt93COQAAAAAAxa1EQ/f5JCUlKTU1VR06dHDVAgMD1apVK61evVrdu3fX6tWrFRQU5ArcktShQwfZbDatXbtWd911l1avXq22bdvK4XC41sTGxmrUqFE6duyYypcvn++xMzMzlZmZ6bqdnp4uScrJyVFOTo4kyWazyWazyel0yul0utbm1XNzc2Wa5gXrdrtdhmG49nt2XZJyc3OLVPfy8pJpmm51wzBkt9vz9VhYnZlK/0xOp1MOh0OGTMk0JcOQnO49yvi/C2BMZ9HqNvuZfRVYd57ZdqG6YZzZf2H1fD0WVrcx0yXOZMiUt7e3JPH7xEzMxEzMxEzMxEzMdJ762f99Ppdt6E5NTZUkhYaGutVDQ0Nd21JTUxUSEuK23cvLSxUqVHBbExkZmW8fedsKCt0jRozQ0KFD89UTEhLk7+8vSQoODlatWrWUlJSkQ4cOudaEh4crPDxcO3fuVFpamqtes2ZNhYSEaPPmzTp16pSrXq9ePQUFBSkhIcHtB964cWM5HA6tX7/erYcWLVooKytLGzdudNXsdrtatmyptLQ0bd++3VX38/NTkyZNdPjwYf3222+uemBgoOrXr6+UlBTt27fPVWem0j/TkSNHNGDAAFXTCdlOZ8jpV04+Kduls/5gZFWpI9PuLZ99W91mygyPkpGbLcf+s95XwWZTZngD2U5nyPvQXlfZ9PZRVpVrZD9xXF5H/3TVnb5llR0SKXv6IXmlHXTVc/3LK6diuLyOpsh+4pirnhMYotzAUHkfTpbt9N/v1ZBToapyy1aQ48AeGdl/P0GWHVyDmS5xpmo6oXvuuUeS+H1iJmZiJmZiJmZiJmY6z0y+vr4qCsM8+2mDEmQYhmbPnq0777xTkrRq1Sq1bt1aKSkpqlKlimtdt27dZBiGpk+fruHDh2vq1KnasWOH275CQkI0dOhQPfXUU+rYsaMiIyP1wQcfuLZv3bpVDRo00NatW1W/fv18vRR0prtatWo6cuSIAgICJJXOZ2qYqfTPlJCQoNatW2vw9EWqERXNWWFmytf73m0bNaRbR61Zs0bR0dH8PjETMzETMzETMzETMxVSz8jIUPny5ZWWlubKiQW5bM90V65cWZJ04MABt9B94MABRUdHu9YcPHjQ7X45OTk6evSo6/6VK1fWgQMH3Nbk3c5bcy4fHx/5+Pjkq3t5ecnLy/1blncwnCvvh1vU+rn7vZi6YRgF1gvr0dM6M135M9lsNmVlZcmUcSbISWdCV0EMD+qGUUjdJhkF7cPDemE9elpnpgvOZMpQdnb2mYfk94mZCunR0zozMZPETIX16GmdmZhJYqbCevS0fqkzFbSmIJft53RHRkaqcuXKWrJkiauWnp6utWvXKiYmRpIUExOj48ePa8OGDa41S5culdPpVKtWrVxrVqxY4fpHpCQtXrxYdevWLfDScgAAAAAAikuJhu6MjAwlJiYqMTFR0pk3T0tMTFRycrIMw1B8fLz+/e9/a+7cudq0aZN69uypsLAw1yXo9evX1y233KLHHntMP//8s1auXKm+ffuqe/fuCgsLkyQ98MADcjgc6tOnj7Zs2aLp06dr3Lhx6t+/fwlNDQAAAAC4WpTo5eXr16/XjTfe6LqdF4R79eqlKVOm6MUXX9SJEyf0+OOP6/jx47r++uu1cOFCtxesf/755+rbt6/at28vm82mrl27avz48a7tgYGB+v777xUXF6fmzZurUqVKGjRoEB8XBgAAAACwXImG7nbt2rm9KP5chmFo2LBhGjZsWKFrKlSooGnTpp33cRo3bqz//e9/F90nAAAAAAAX47J9TTcAAAAAAFc6QjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFvEq6QZQvJKTk3X48OGSbgOXqW3btpV0CwAAAMBVhdBdiiQnJ6te/fo6dfJkSbeCy1xWZlZJtwAAAABcFQjdpcjhw4d16uRJPf3WhwqrdU1Jt4PL0K/LF2vm2DeUk5NT0q3gMsdVETifSpUqqXr16iXdBgAAVwRCdykUVusaRTaILuk2cBlK2bOzpFvAZe74oQMyDEMPPvhgSbeCy5hfmTLavm0bwRsAgCIgdAMAXE6mp8k0TfV+fbxqNWxc0u3gMpSyZ6fef+FxHT58mNANAEARELoBAPlUiazNFTMAAADFgI8MAwAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCJeJd0AAAC48mzbtq2kW8BlrFKlSqpevXpJtwEAlwVCNwAAKLLjhw7IMAw9+OCDJd0KLmN+Zcpo+7ZtBG8A0FUWuidMmKA333xTqampatKkid59913961//Kum2AAC4YpxMT5Npmur9+njVati4pNvBZShlz069/8LjOnz4MKEbAHQVhe7p06erf//+mjRpklq1aqWxY8cqNjZWO3bsUEhISEm3BwDAFaVKZG1FNogu6TYAALjsXTVvpPb222/rscceU+/evRUVFaVJkyapTJky+uSTT0q6NQAAAABAKXVVnOnOysrShg0bNHDgQFfNZrOpQ4cOWr16dQl2BgAAUDrxZnu4kMzMTPn4+JR0G7iMlZY3ZbwqQvfhw4eVm5ur0NBQt3poaKi2b9+eb31mZqYyMzNdt9PS0iRJR48eVU5OjqQzod1ms8npdMrpdLrW5tVzc3NlmuYF63a7XYZhuPZ7dl2ScnNzi1T38vLSX3/9JW9vbyVv/VWZJzMkSaYM1/+e7Xx1Q+Y5NUnFVlcBj1lY3fPemen89QNJu+Xt7a192zfLZjhLxUxFrzNTUXo/kLRbXl5e+n3bJtkMZ6mYqSh1Zip6PWXPTknSvu2bZTec56y/MmcqjT+nkpxpd+LPcjgc6t27t6Qz/2ZxOp3y8vKSYfx9j5ycHJmmWWjd29vbbd/Z2dmS5FHdMAx5ef39z13TNJWTk1No3Wazuf6tJUlOp1O5ubmy2+2y2f6+QJSZimcmw7ApKyuzVM2UV2em4pnJx9dXP69dq6pVq7rqxZmfTNN0qxuGIbvdni/jFVbPyMhwzXw+hnmhFaVASkqKqlatqlWrVikmJsZVf/HFF7V8+XKtXbvWbf2QIUM0dOjQf7pNAAAAAMAV5o8//lB4eHih26+KM92VKlWS3W7XgQMH3OoHDhxQ5cqV860fOHCg+vfv77rtdDp19OhRVaxY0e3Zl8tNenq6qlWrpj/++EMBAQEl3Q4uQxwjuBCOEVwIxwguhGMERcFxgtLANE399ddfCgsLO++6qyJ0OxwONW/eXEuWLNGdd94p6UyQXrJkifr27ZtvvY+PT77XlwQFBf0DnRaPgIAA/njhvDhGcCEcI7gQjhFcCMcIioLjBFe6wMDAC665KkK3JPXv31+9evVSixYt9K9//Utjx47ViRMnXK83AgAAAACguF01ofu+++7ToUOHNGjQIKWmpio6OloLFy7M9+ZqAAAAAAAUl6smdEtS3759C7ycvLTw8fHR4MGD+egFFIpjBBfCMYIL4RjBhXCMoCg4TnA1uSrevRwAAAAAgJJgu/ASAAAAAABwMQjdAAAAAABYhNANAAAAAIBFCN2lwIoVK3T77bcrLCxMhmFozpw5Jd0SLiMjRoxQy5YtVa5cOYWEhOjOO+/Ujh07SrotXGYmTpyoxo0buz4vNSYmRgsWLCjptnAZGzlypAzDUHx8fEm3gsvEkCFDZBiG21e9evVKui1cZv788089+OCDqlixovz8/NSoUSOtX7++pNsCLEXoLgVOnDihJk2aaMKECSXdCi5Dy5cvV1xcnNasWaPFixcrOztbHTt21IkTJ0q6NVxGwsPDNXLkSG3YsEHr16/XTTfdpC5dumjLli0l3RouQ+vWrdMHH3ygxo0bl3QruMw0aNBA+/fvd3399NNPJd0SLiPHjh1T69at5e3trQULFmjr1q0aM2aMypcvX9KtAZa6qj4yrLTq1KmTOnXqVNJt4DK1cOFCt9tTpkxRSEiINmzYoLZt25ZQV7jc3H777W6333jjDU2cOFFr1qxRgwYNSqgrXI4yMjLUo0cP/ec//9G///3vkm4HlxkvLy9Vrly5pNvAZWrUqFGqVq2aJk+e7KpFRkaWYEfAP4Mz3cBVJi0tTZJUoUKFEu4El6vc3Fx9+eWXOnHihGJiYkq6HVxm4uLi1LlzZ3Xo0KGkW8FlaNeuXQoLC1PNmjXVo0cPJScnl3RLuIzMnTtXLVq00L333quQkBA1bdpU//nPf0q6LcBynOkGriJOp1Px8fFq3bq1GjZsWNLt4DKzadMmxcTE6PTp0ypbtqxmz56tqKiokm4Ll5Evv/xSv/zyi9atW1fSreAy1KpVK02ZMkV169bV/v37NXToULVp00abN29WuXLlSro9XAZ+++03TZw4Uf3799crr7yidevW6dlnn5XD4VCvXr1Kuj3AMoRu4CoSFxenzZs38xo7FKhu3bpKTExUWlqaZs2apV69emn58uUEb0iS/vjjDz333HNavHixfH19S7odXIbOfqlb48aN1apVK0VERGjGjBnq06dPCXaGy4XT6VSLFi00fPhwSVLTpk21efNmTZo0idCNUo3Ly4GrRN++fTVv3jz9+OOPCg8PL+l2cBlyOByqXbu2mjdvrhEjRqhJkyYaN25cSbeFy8SGDRt08OBBNWvWTF5eXvLy8tLy5cs1fvx4eXl5KTc3t6RbxGUmKChI11xzjXbv3l3SreAyUaVKlXxP5NavX5+XIaDU40w3UMqZpqlnnnlGs2fP1rJly3jDEhSZ0+lUZmZmSbeBy0T79u21adMmt1rv3r1Vr149vfTSS7Lb7SXUGS5XGRkZ2rNnjx566KGSbgWXidatW+f72NKdO3cqIiKihDoC/hmE7lIgIyPD7VnkpKQkJSYmqkKFCqpevXoJdobLQVxcnKZNm6ZvvvlG5cqVU2pqqiQpMDBQfn5+JdwdLhcDBw5Up06dVL16df3111+aNm2ali1bpkWLFpV0a7hMlCtXLt97Qfj7+6tixYq8RwQkSS+88IJuv/12RUREKCUlRYMHD5bdbtf9999f0q3hMtGvXz9dd911Gj58uLp166aff/5ZH374oT788MOSbg2wFKG7FFi/fr1uvPFG1+3+/ftLknr16qUpU6aUUFe4XEycOFGS1K5dO7f65MmT9fDDD//zDeGydPDgQfXs2VP79+9XYGCgGjdurEWLFunmm28u6dYAXCH27dun+++/X0eOHFFwcLCuv/56rVmzRsHBwSXdGi4TLVu21OzZszVw4EANGzZMkZGRGjt2rHr06FHSrQGWMkzTNEu6CQAAAAAASiPeSA0AAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwBw1dm7d68Mw1BiYmJJt+Kyfft2XXvttfL19VV0dPQl7cswDM2ZM6dY+ipNpkyZoqCgoJJuAwBwlSF0AwD+cQ8//LAMw9DIkSPd6nPmzJFhGCXUVckaPHiw/P39tWPHDi1ZsqTQdampqXrmmWdUs2ZN+fj4qFq1arr99tvPe5/LycMPP6w777yzRB77vvvu086dOy9pH8uWLZNhGDp+/HjxNAUAKPUI3QCAEuHr66tRo0bp2LFjJd1KscnKyrro++7Zs0fXX3+9IiIiVLFixQLX7N27V82bN9fSpUv15ptvatOmTVq4cKFuvPFGxcXFXfRjF8WlzGaFi+nHz89PISEhFnQDAEDhCN0AgBLRoUMHVa5cWSNGjCh0zZAhQ/Jdaj127FjVqFHDdTvvzOnw4cMVGhqqoKAgDRs2TDk5ORowYIAqVKig8PBwTZ48Od/+t2/fruuuu06+vr5q2LChli9f7rZ98+bN6tSpk8qWLavQ0FA99NBDOnz4sGt7u3bt1LdvX8XHx6tSpUqKjY0tcA6n06lhw4YpPDxcPj4+io6O1sKFC13bDcPQhg0bNGzYMBmGoSFDhhS4n6efflqGYejnn39W165ddc0116hBgwbq37+/1qxZ47b28OHDuuuuu1SmTBnVqVNHc+fOdW3Lzc1Vnz59FBkZKT8/P9WtW1fjxo1zu3/e9/WNN95QWFiY6tatK0n67LPP1KJFC5UrV06VK1fWAw88oIMHD7rdd8uWLbrtttsUEBCgcuXKqU2bNtqzZ4+GDBmiqVOn6ptvvpFhGDIMQ8uWLZMk/fHHH+rWrZuCgoJUoUIFdenSRXv37r1gP++//77q1KkjX19fhYaG6p577inweyflv7w87/j67LPPVKNGDQUGBqp79+7666+/Ct3HhWRmZuqFF15Q1apV5e/vr1atWrlmPLuHefPmqW7duipTpozuuecenTx5UlOnTlWNGjVUvnx5Pfvss8rNzXXdr0aNGvr3v/+tnj17qmzZsoqIiNDcuXN16NAhdenSRWXLllXjxo21fv16132OHDmi+++/X1WrVlWZMmXUqFEjffHFFxc9GwDg4hC6AQAlwm63a/jw4Xr33Xe1b9++S9rX0qVLlZKSohUrVujtt9/W4MGDddttt6l8+fJau3atnnzyST3xxBP5HmfAgAF6/vnnlZCQoJiYGN1+++06cuSIJOn48eO66aab1LRpU61fv14LFy7UgQMH1K1bN7d9TJ06VQ6HQytXrtSkSZMK7G/cuHEaM2aM3nrrLW3cuFGxsbG64447tGvXLknS/v371aBBAz3//PPav3+/XnjhhXz7OHr0qBYuXKi4uDj5+/vn237ua5WHDh2qbt26aePGjbr11lvVo0cPHT16VNKZJwHCw8M1c+ZMbd26VYMGDdIrr7yiGTNmuO1jyZIl2rFjhxYvXqx58+ZJkrKzs/X666/r119/1Zw5c7R37149/PDDrvv8+eefatu2rXx8fLR06VJt2LBBjzzyiHJycvTCCy+oW7duuuWWW7R//37t379f1113nbKzsxUbG6ty5crpf//7n1auXKmyZcvqlltucTujfW4/69ev17PPPqthw4Zpx44dWrhwodq2bVvgz6Awe/bs0Zw5czRv3jzNmzdPy5cvz/eyB0/07dtXq1ev1pdffqmNGzfq3nvv1S233OL6WUvSyZMnNX78eH355ZdauHChli1bprvuukvfffedvvvuO3322Wf64IMPNGvWLLd9v/POO2rdurUSEhLUuXNnPfTQQ+rZs6cefPBB/fLLL6pVq5Z69uwp0zQlSadPn1bz5s01f/58bd68WY8//rgeeugh/fzzzxc9HwDgIpgAAPzDevXqZXbp0sU0TdO89tprzUceecQ0TdOcPXu2efb/NQ0ePNhs0qSJ233feecdMyIiwm1fERERZm5urqtWt25ds02bNq7bOTk5pr+/v/nFF1+YpmmaSUlJpiRz5MiRrjXZ2dlmeHi4OWrUKNM0TfP11183O3bs6PbYf/zxhynJ3LFjh2mapnnDDTeYTZs2veC8YWFh5htvvOFWa9mypfn000+7bjdp0sQcPHhwoftYu3atKcn8+uuvL/h4ksxXX33VdTsjI8OUZC5YsKDQ+8TFxZldu3Z13e7Vq5cZGhpqZmZmnvex1q1bZ0oy//rrL9M0TXPgwIFmZGSkmZWVVeD6s3/2eT777DOzbt26ptPpdNUyMzNNPz8/c9GiRYX289VXX5kBAQFmenr6eXvMM3nyZDMwMNB1e/DgwWaZMmXc7j9gwACzVatWhe7jxx9/NCWZx44dy7ft999/N+12u/nnn3+61du3b28OHDjQ1YMkc/fu3a7tTzzxhFmmTBnX99A0TTM2NtZ84oknXLcjIiLMBx980HV7//79piTztddec9VWr15tSjL3799faP+dO3c2n3/++UK3AwCKn1cJZX0AACRJo0aN0k033VTg2d2iatCggWy2vy/eCg0NVcOGDV237Xa7KlasmO8y6JiYGNd/e3l5qUWLFtq2bZsk6ddff9WPP/6osmXL5nu8PXv26JprrpEkNW/e/Ly9paenKyUlRa1bt3art27dWr/++msRJ5Tr7GVRNW7c2PXf/v7+CggIcJt/woQJ+uSTT5ScnKxTp04pKysr36X8jRo1ksPhcKtt2LBBQ4YM0a+//qpjx47J6XRKkpKTkxUVFaXExES1adNG3t7eRe71119/1e7du1WuXDm3+unTp7Vnz55C+7n55psVERGhmjVr6pZbbtEtt9ziuqS+qGrUqOH2uFWqVMl3nBTVpk2blJub6zo28mRmZrq9Tr9MmTKqVauW63ZoaKhq1KjhdqyFhobm6+Psn2loaKikM9+Tc2sHDx5U5cqVlZubq+HDh2vGjBn6888/lZWVpczMTI++PwCAS0foBgCUqLZt2yo2NlYDBw50u0xZkmw2W76wmZ2dnW8f5wY8wzAKrOUFxKLIyMjQ7bffrlGjRuXbVqVKFdd/F3SptxXq1KkjwzC0ffv2Iq0/3/xffvmlXnjhBY0ZM0YxMTEqV66c3nzzTa1du9btPufOduLECcXGxio2Nlaff/65goODlZycrNjYWNdl4H5+fh7PlpGRoebNm+vzzz/Pty04OLjQfsqVK6dffvlFy5Yt0/fff69BgwZpyJAhWrduXZE/GuxSj5OzZWRkyG63a8OGDbLb7W7bzg7UF3u8nr0m713+C6rl3e/NN9/UuHHjNHbsWDVq1Ej+/v6Kj4+/7N4UDwBKO0I3AKDEjRw5UtHR0a43x8oTHBys1NRUmabpChTF+dnaa9ascb0GOCcnRxs2bFDfvn0lSc2aNdNXX32lGjVqyMvr4v/vMiAgQGFhYVq5cqVuuOEGV33lypX617/+VeT9VKhQQbGxsZowYYKeffbZfAH0+PHjRQ6aK1eu1HXXXaenn37aVTv7jHJhtm/friNHjmjkyJGqVq2aJLm9cZd05mzs1KlTlZ2dXeDZbofD4fYGYdKZ7/X06dMVEhKigICAIs2Qx8vLSx06dFCHDh00ePBgBQUFaenSpbr77rs92k9xaNq0qXJzc3Xw4EG1adPmH3/8c61cuVJdunTRgw8+KOlMGN+5c6eioqJKuDMAuLrwRmoAgBLXqFEj9ejRQ+PHj3ert2vXTocOHdLo0aO1Z88eTZgwQQsWLCi2x50wYYJmz56t7du3Ky4uTseOHdMjjzwiSYqLi9PRo0d1//33a926ddqzZ48WLVqk3r175wuNFzJgwACNGjVK06dP144dO/Tyyy8rMTFRzz33nMf95ubm6l//+pe++uor7dq1S9u2bdP48ePdLpW/kDp16mj9+vVatGiRdu7cqddee03r1q274P2qV68uh8Ohd999V7/99pvmzp2r119/3W1N3759lZ6eru7du2v9+vXatWuXPvvsM+3YsUPSmcu5N27cqB07dujw4cPKzs5Wjx49VKlSJXXp0kX/+9//lJSUpGXLlunZZ58975vszZs3T+PHj1diYqJ+//13ffrpp3I6nfmevLHCpk2blJiY6Pr69ddfdc0116hHjx7q2bOnvv76ayUlJennn3/WiBEjNH/+fMt7OledOnW0ePFirVq1Stu2bdMTTzyhAwcO/ON9AMDVjtANALgsDBs2LN/ltPXr19f777+vCRMmqEmTJvr5558v6bXf5xo5cqRGjhypJk2a6KefftLcuXNVqVIlSXKdnc7NzVXHjh3VqFEjxcfHKygoyO3140Xx7LPPqn///nr++efVqFEjLVy4UHPnzlWdOnU82k/NmjX1yy+/6MYbb9Tzzz+vhg0b6uabb9aSJUs0ceLEIu/niSee0N1336377rtPrVq10pEjR9zOehcmODhYU6ZM0cyZMxUVFaWRI0fqrbfecltTsWJFLV26VBkZGbrhhhvUvHlz/ec//3Gd9X7sscdUt25dtWjRQsHBwVq5cqXKlCmjFStWqHr16rr77rtVv3599enTR6dPnz7vme+goCB9/fXXuummm1S/fn1NmjRJX3zxhRo0aFDk78XFatu2rZo2ber6yntt/+TJk9WzZ089//zzqlu3ru68806tW7dO1atXt7ync7366qtq1qyZYmNj1a5dO1WuXFl33nnnP94HAFztDNPTd2YBAAAAAABFwpluAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIv8fokTwMN2Tbz8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Addtional"
      ],
      "metadata": {
        "id": "oTFduDb4lcNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Frequency-Matched Polysemy Comparison\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define bins (you can tweak these)\n",
        "bins = [30, 60, 100, 200, 500, 1000]\n",
        "labels = [\"30–59\", \"60–99\", \"100–199\", \"200–499\", \"500+\"]\n",
        "\n",
        "# Function to assign bins\n",
        "def assign_bin(n):\n",
        "    for i in range(len(bins)-1):\n",
        "        if bins[i] <= n < bins[i+1]:\n",
        "            return labels[i]\n",
        "    if n >= bins[-1]:\n",
        "        return labels[-1]\n",
        "    return None\n",
        "\n",
        "en[\"freq_bin\"] = en[\"n_instances\"].apply(assign_bin)\n",
        "zh[\"freq_bin\"] = zh[\"n_instances\"].apply(assign_bin)\n",
        "\n",
        "# Remove words outside bins\n",
        "en_bin = en.dropna(subset=[\"freq_bin\"])\n",
        "zh_bin = zh.dropna(subset=[\"freq_bin\"])\n",
        "\n",
        "# Prepare result storage\n",
        "bin_results = []\n",
        "\n",
        "for bin_label in labels:\n",
        "    en_subset = en_bin[en_bin[\"freq_bin\"] == bin_label][\"k_hdbscan\"]\n",
        "    zh_subset = zh_bin[zh_bin[\"freq_bin\"] == bin_label][\"k_hdbscan\"]\n",
        "\n",
        "    if len(en_subset) < 5 or len(zh_subset) < 5:\n",
        "        continue\n",
        "\n",
        "    from scipy.stats import mannwhitneyu\n",
        "    U, p = mannwhitneyu(en_subset, zh_subset, alternative=\"two-sided\")\n",
        "\n",
        "    result = {\n",
        "        \"freq_bin\": bin_label,\n",
        "        \"en_mean_k\": en_subset.mean(),\n",
        "        \"zh_mean_k\": zh_subset.mean(),\n",
        "        \"n_en\": len(en_subset),\n",
        "        \"n_zh\": len(zh_subset),\n",
        "        \"p_value\": p\n",
        "    }\n",
        "\n",
        "    bin_results.append(result)\n",
        "\n",
        "# Convert to DataFrame\n",
        "bin_df = pd.DataFrame(bin_results)\n",
        "print(\"\\n── Frequency-Stratified Results ──\")\n",
        "print(bin_df)\n",
        "\n",
        "bin_df.to_csv(OUTPUT_DIR / \"frequency_matched_comparison.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx8IccoOleSW",
        "outputId": "6f655eaa-f332-41de-a91e-a462fbcb79ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Frequency-Matched Polysemy Comparison\n",
            "============================================================\n",
            "\n",
            "── Frequency-Stratified Results ──\n",
            "  freq_bin  en_mean_k  zh_mean_k  n_en  n_zh       p_value\n",
            "0    30–59   1.325397   1.065217   252   276  4.982427e-14\n",
            "1    60–99   1.572414   1.171429   145   140  4.544249e-11\n",
            "2  100–199   1.696970   1.195652   132    92  1.876753e-09\n",
            "3  200–499   1.866667   1.300000    75    50  8.446254e-05\n",
            "4     500+   2.250000   1.250000    32    16  1.294092e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "x = range(len(bin_df))\n",
        "plt.plot(x, bin_df[\"en_mean_k\"], marker=\"o\", label=\"English\")\n",
        "plt.plot(x, bin_df[\"zh_mean_k\"], marker=\"o\", label=\"Chinese\")\n",
        "\n",
        "plt.xticks(x, bin_df[\"freq_bin\"])\n",
        "plt.ylabel(\"Mean Induced Polysemy (k)\")\n",
        "plt.xlabel(\"Frequency Bin\")\n",
        "plt.title(\"Frequency-Matched Polysemy Comparison\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"frequency_matched_plot.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qHVvs4irllg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Robustness check"
      ],
      "metadata": {
        "id": "W41WSj5KnBEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.1 Build lemma co-occurence pairs"
      ],
      "metadata": {
        "id": "wyAb9EFDnKgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Step 8: Overlap-Only Robustness Check\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load per-instance sense labels\n",
        "en_labels = pd.read_csv(DATA_DIR / \"english_sense_labels.csv\")\n",
        "zh_labels = pd.read_csv(DATA_DIR / \"chinese_sense_labels.csv\")\n",
        "\n",
        "# Merge on verse_id to get co-occurring lemmas\n",
        "merged = en_labels.merge(\n",
        "    zh_labels,\n",
        "    on=\"verse_id\",\n",
        "    suffixes=(\"_en\", \"_zh\")\n",
        ")\n",
        "\n",
        "# Count lemma co-occurrence pairs\n",
        "pair_counts = (\n",
        "    merged.groupby([\"lemma_en\", \"lemma_zh\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"co_occurrences\")\n",
        ")\n",
        "\n",
        "# Keep only strong overlaps (at least 10 shared verses)\n",
        "pair_counts = pair_counts[pair_counts[\"co_occurrences\"] >= 10]\n",
        "\n",
        "print(f\"Total aligned lemma pairs: {len(pair_counts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXgP7i1knDfH",
        "outputId": "9a18b112-9ce2-4cbd-e585-c23f87caa20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Step 8: Overlap-Only Robustness Check\n",
            "============================================================\n",
            "Total aligned lemma pairs: 4882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.2 Identify overlapping lemma sets"
      ],
      "metadata": {
        "id": "u1oNGrC2nXPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmas that participate in aligned pairs\n",
        "en_overlap = set(pair_counts[\"lemma_en\"])\n",
        "zh_overlap = set(pair_counts[\"lemma_zh\"])\n",
        "\n",
        "print(f\"English overlapping lemmas: {len(en_overlap)}\")\n",
        "print(f\"Chinese overlapping lemmas: {len(zh_overlap)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E216lrC8naUB",
        "outputId": "0b508e45-e0a6-438e-e871-f5602b14eb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English overlapping lemmas: 596\n",
            "Chinese overlapping lemmas: 540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.3 Restrict WSI results to overlap lemmas only"
      ],
      "metadata": {
        "id": "501ny_HVniSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_overlap_df = en[en[\"lemma\"].isin(en_overlap)]\n",
        "zh_overlap_df = zh[zh[\"lemma\"].isin(zh_overlap)]\n",
        "\n",
        "print(f\"Filtered EN lemmas: {len(en_overlap_df)}\")\n",
        "print(f\"Filtered ZH lemmas: {len(zh_overlap_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQC1rwEhnn-d",
        "outputId": "6882b059-6045-4ffa-89a6-0339ff144d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered EN lemmas: 596\n",
            "Filtered ZH lemmas: 540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.4 Run Mann-Whitney on overlap only"
      ],
      "metadata": {
        "id": "cddRJrvynsPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "U, p = mannwhitneyu(\n",
        "    en_overlap_df[\"k_hdbscan\"],\n",
        "    zh_overlap_df[\"k_hdbscan\"],\n",
        "    alternative=\"two-sided\"\n",
        ")\n",
        "\n",
        "print(\"\\n── Overlap-Only Statistical Comparison ──\")\n",
        "print(f\"EN mean k: {en_overlap_df['k_hdbscan'].mean():.3f}\")\n",
        "print(f\"ZH mean k: {zh_overlap_df['k_hdbscan'].mean():.3f}\")\n",
        "print(f\"p-value: {p:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWvrEsZsnxpC",
        "outputId": "06d1c816-7b24-46dc-9073-5f42c29d1f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "── Overlap-Only Statistical Comparison ──\n",
            "EN mean k: 1.599\n",
            "ZH mean k: 1.141\n",
            "p-value: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.5 Run M"
      ],
      "metadata": {
        "id": "6yCdED9WoA_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Frequency-Matched Polysemy Comparison (Overlap Only)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define bins\n",
        "bins = [30, 60, 100, 200, 500, 1000]\n",
        "labels = [\"30–59\", \"60–99\", \"100–199\", \"200–499\", \"500+\"]\n",
        "\n",
        "def assign_bin(n):\n",
        "    for i in range(len(bins)-1):\n",
        "        if bins[i] <= n < bins[i+1]:\n",
        "            return labels[i]\n",
        "    if n >= bins[-1]:\n",
        "        return labels[-1]\n",
        "    return None\n",
        "\n",
        "# Assign bins to overlap dataframes directly\n",
        "en_overlap_df = en_overlap_df.copy()\n",
        "zh_overlap_df = zh_overlap_df.copy()\n",
        "\n",
        "en_overlap_df[\"freq_bin\"] = en_overlap_df[\"n_instances\"].apply(assign_bin)\n",
        "zh_overlap_df[\"freq_bin\"] = zh_overlap_df[\"n_instances\"].apply(assign_bin)\n",
        "\n",
        "# Remove words outside bins\n",
        "en_bin_overlap_df = en_overlap_df.dropna(subset=[\"freq_bin\"])\n",
        "zh_bin_overlap_df = zh_overlap_df.dropna(subset=[\"freq_bin\"])\n",
        "\n",
        "bin_results = []\n",
        "\n",
        "for bin_label in labels:\n",
        "    en_subset = en_bin_overlap_df[\n",
        "        en_bin_overlap_df[\"freq_bin\"] == bin_label\n",
        "    ][\"k_hdbscan\"]\n",
        "\n",
        "    zh_subset = zh_bin_overlap_df[\n",
        "        zh_bin_overlap_df[\"freq_bin\"] == bin_label\n",
        "    ][\"k_hdbscan\"]\n",
        "\n",
        "    if len(en_subset) < 5 or len(zh_subset) < 5:\n",
        "        continue\n",
        "\n",
        "    from scipy.stats import mannwhitneyu\n",
        "    U, p = mannwhitneyu(en_subset, zh_subset, alternative=\"two-sided\")\n",
        "\n",
        "    bin_results.append({\n",
        "        \"freq_bin\": bin_label,\n",
        "        \"en_mean_k\": en_subset.mean(),\n",
        "        \"zh_mean_k\": zh_subset.mean(),\n",
        "        \"n_en\": len(en_subset),\n",
        "        \"n_zh\": len(zh_subset),\n",
        "        \"p_value\": p\n",
        "    })\n",
        "\n",
        "bin_df = pd.DataFrame(bin_results)\n",
        "\n",
        "print(\"\\n── Frequency-Stratified Results (Overlap Only) ──\")\n",
        "print(bin_df)\n",
        "\n",
        "bin_df.to_csv(\n",
        "    OUTPUT_DIR / \"frequency_matched_comparison_overlap_df.csv\",\n",
        "    index=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE16SdJXoE-X",
        "outputId": "bd1544a5-f2c4-4243-b1fd-b013fdd0b999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Frequency-Matched Polysemy Comparison (Overlap Only)\n",
            "============================================================\n",
            "\n",
            "── Frequency-Stratified Results (Overlap Only) ──\n",
            "  freq_bin  en_mean_k  zh_mean_k  n_en  n_zh       p_value\n",
            "0    30–59   1.363208   1.060729   212   247  1.542733e-15\n",
            "1    60–99   1.572414   1.177778   145   135  1.600625e-10\n",
            "2  100–199   1.696970   1.195652   132    92  1.876753e-09\n",
            "3  200–499   1.866667   1.300000    75    50  8.446254e-05\n",
            "4     500+   2.250000   1.250000    32    16  1.294092e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Bootstrap Stability"
      ],
      "metadata": {
        "id": "BeOmq9ZWqWEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.1 Bootstrap function"
      ],
      "metadata": {
        "id": "gll9oc_3r5Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def bootstrap_k(embeddings, n_runs=20, sample_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Bootstrap stability for a single lemma.\n",
        "\n",
        "    Returns:\n",
        "        mode_k     : most frequent induced k across runs\n",
        "        stability  : proportion of runs equal to mode_k\n",
        "        all_ks     : list of k from each run\n",
        "    \"\"\"\n",
        "    n = len(embeddings)\n",
        "\n",
        "    if n < 20:\n",
        "        return 1, 1.0, [1]\n",
        "\n",
        "    ks = []\n",
        "\n",
        "    for _ in range(n_runs):\n",
        "        sample_size = int(sample_ratio * n)\n",
        "        idx = np.random.choice(n, sample_size, replace=False)\n",
        "        subset = embeddings[idx]\n",
        "\n",
        "        k, _ = induce_senses_hdbscan(subset)\n",
        "        ks.append(k)\n",
        "\n",
        "    counter = Counter(ks)\n",
        "    mode_k = counter.most_common(1)[0][0]\n",
        "    stability = counter[mode_k] / n_runs\n",
        "\n",
        "    return mode_k, stability, ks"
      ],
      "metadata": {
        "id": "O2S2zyAUqaHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.2 Run Bootstrap for Entire Language"
      ],
      "metadata": {
        "id": "Ov3WhxFPsApT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_bootstrap_for_language(lang: str, n_runs=20):\n",
        "    print(f\"\\n[{lang.upper()}] Running bootstrap stability...\")\n",
        "\n",
        "    embeddings_file = DATA_DIR / f\"{lang}_embeddings.npz\"\n",
        "    results_file = DATA_DIR / f\"{lang}_wsi_results.csv\"\n",
        "\n",
        "    data = np.load(embeddings_file, allow_pickle=True)\n",
        "    lemmas_array = data[\"lemmas\"]\n",
        "    embeddings = data[\"embeddings\"]\n",
        "\n",
        "    df = pd.read_csv(results_file)\n",
        "\n",
        "    stability_records = []\n",
        "\n",
        "    unique_lemmas = df[\"lemma\"].values\n",
        "\n",
        "    for i, lemma in enumerate(unique_lemmas):\n",
        "        mask = (lemmas_array == lemma)\n",
        "        lemma_embeds = embeddings[mask]\n",
        "\n",
        "        mode_k, stability, ks = bootstrap_k(\n",
        "            lemma_embeds,\n",
        "            n_runs=n_runs,\n",
        "            sample_ratio=0.8\n",
        "        )\n",
        "\n",
        "        stability_records.append({\n",
        "            \"lemma\": lemma,\n",
        "            \"n_instances\": len(lemma_embeds),\n",
        "            \"k_bootstrap_mode\": mode_k,\n",
        "            \"stability\": stability\n",
        "        })\n",
        "\n",
        "        if (i + 1) % 50 == 0 or (i + 1) == len(unique_lemmas):\n",
        "            print(f\"  {i+1}/{len(unique_lemmas)} lemmas\", end=\"\\r\")\n",
        "\n",
        "    stability_df = pd.DataFrame(stability_records)\n",
        "\n",
        "    out_path = DATA_DIR / f\"{lang}_bootstrap_stability.csv\"\n",
        "    stability_df.to_csv(out_path, index=False)\n",
        "\n",
        "    print(f\"\\n[{lang.upper()}] Saved bootstrap results → {out_path.name}\")\n",
        "\n",
        "    return stability_df"
      ],
      "metadata": {
        "id": "bowr4jXmqwiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.3 Run for both languages"
      ],
      "metadata": {
        "id": "u_7aY601sKcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_boot = run_bootstrap_for_language(\"english\", n_runs=20)\n",
        "zh_boot = run_bootstrap_for_language(\"chinese\", n_runs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "355FlbU6q1aG",
        "outputId": "bff313c3-5faa-4b98-bf82-4fa58edf18f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ENGLISH] Running bootstrap stability...\n",
            "  636/636 lemmas\n",
            "[ENGLISH] Saved bootstrap results → english_bootstrap_stability.csv\n",
            "\n",
            "[CHINESE] Running bootstrap stability...\n",
            "  574/574 lemmas\n",
            "[CHINESE] Saved bootstrap results → chinese_bootstrap_stability.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.4 Compare stability across languages"
      ],
      "metadata": {
        "id": "91yrFQYzrD8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Bootstrap Stability Comparison\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"EN mean stability: {en_boot['stability'].mean():.3f}\")\n",
        "print(f\"ZH mean stability: {zh_boot['stability'].mean():.3f}\")\n",
        "\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "U, p = mannwhitneyu(\n",
        "    en_boot[\"stability\"],\n",
        "    zh_boot[\"stability\"],\n",
        "    alternative=\"two-sided\"\n",
        ")\n",
        "\n",
        "print(f\"Stability difference p-value: {p:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PYHszdHrC9f",
        "outputId": "33e436eb-fb34-491d-d583-58cb2b58348f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Bootstrap Stability Comparison\n",
            "============================================================\n",
            "EN mean stability: 0.916\n",
            "ZH mean stability: 0.973\n",
            "Stability difference p-value: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.5 Compare stability for polysemous lemmas only"
      ],
      "metadata": {
        "id": "wTfUtKzgrTVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_poly = en_boot[en_boot[\"k_bootstrap_mode\"] > 1]\n",
        "zh_poly = zh_boot[zh_boot[\"k_bootstrap_mode\"] > 1]\n",
        "\n",
        "print(\"\\nPolysemous-only stability:\")\n",
        "print(f\"EN mean stability: {en_poly['stability'].mean():.3f}\")\n",
        "print(f\"ZH mean stability: {zh_poly['stability'].mean():.3f}\")\n",
        "\n",
        "U_poly, p_poly = mannwhitneyu(\n",
        "    en_poly[\"stability\"],\n",
        "    zh_poly[\"stability\"],\n",
        "    alternative=\"two-sided\"\n",
        ")\n",
        "\n",
        "print(f\"Polysemous stability p-value: {p_poly:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3605LZWcrYNp",
        "outputId": "a1f295f4-b55e-45b5-87e1-38350595214d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Polysemous-only stability:\n",
            "EN mean stability: 0.883\n",
            "ZH mean stability: 0.854\n",
            "Polysemous stability p-value: 0.342006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Regression Model"
      ],
      "metadata": {
        "id": "kAr7OjsnbXZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.1 Merge and Prepare Data"
      ],
      "metadata": {
        "id": "BzqKaIejbiBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure 'en' and 'zh' DataFrames are available.\n",
        "DATA_DIR = Path(\"/content\") / \"bible_data\"\n",
        "en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "# Add language label\n",
        "en[\"language\"] = 1   # English\n",
        "zh[\"language\"] = 0   # Chinese\n",
        "\n",
        "# Combine\n",
        "df = pd.concat([en, zh], ignore_index=True)\n",
        "\n",
        "# Log frequency\n",
        "df[\"log_freq\"] = np.log(df[\"n_instances\"])\n",
        "\n",
        "# Response variable\n",
        "df[\"k\"] = df[\"k_hdbscan\"]"
      ],
      "metadata": {
        "id": "69Zdq-RxbZsx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.2 Poisson Regression"
      ],
      "metadata": {
        "id": "PhvJ61cRb6rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poisson_model = smf.glm(\n",
        "    formula=\"k ~ language + log_freq\",\n",
        "    data=df,\n",
        "    family=sm.families.Poisson()\n",
        ").fit()\n",
        "\n",
        "print(poisson_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YEWKBAucDTx",
        "outputId": "79bf8af4-e70b-4bc2-b6bd-7fd305c047fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:                      k   No. Observations:                 1210\n",
            "Model:                            GLM   Df Residuals:                     1207\n",
            "Model Family:                 Poisson   Df Model:                            2\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -1446.1\n",
            "Date:                Thu, 26 Feb 2026   Deviance:                       220.94\n",
            "Time:                        05:37:37   Pearson chi2:                     250.\n",
            "No. Iterations:                     4   Pseudo R-squ. (CS):            0.05398\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept     -0.4792      0.125     -3.839      0.000      -0.724      -0.235\n",
            "language       0.2947      0.051      5.821      0.000       0.195       0.394\n",
            "log_freq       0.1397      0.027      5.189      0.000       0.087       0.192\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.3 Check for Overdispersion"
      ],
      "metadata": {
        "id": "_fv0QS8QccAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_k = df[\"k\"].mean()\n",
        "var_k = df[\"k\"].var()\n",
        "\n",
        "print(\"Mean k:\", mean_k)\n",
        "print(\"Variance k:\", var_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gGrteaicfT5",
        "outputId": "53a2e3d8-415a-425a-848a-ffc0700c5de3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean k: 1.3644628099173555\n",
            "Variance k: 0.3906301909234532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.4 Negative Binomial Regression"
      ],
      "metadata": {
        "id": "3cjAPf_4c0N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = smf.glm(\n",
        "    formula=\"k ~ language + log_freq\",\n",
        "    data=df,\n",
        "    family=sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "print(nb_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bco6Qhdqc8Qv",
        "outputId": "3a1dbd80-66fe-4fbc-e781-1f3e72a1df08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:                      k   No. Observations:                 1210\n",
            "Model:                            GLM   Df Residuals:                     1207\n",
            "Model Family:        NegativeBinomial   Df Model:                            2\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -1935.1\n",
            "Date:                Thu, 26 Feb 2026   Deviance:                       84.510\n",
            "Time:                        05:37:46   Pearson chi2:                     101.\n",
            "No. Iterations:                     5   Pseudo R-squ. (CS):            0.02261\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept     -0.4739      0.199     -2.378      0.017      -0.864      -0.083\n",
            "language       0.2892      0.077      3.755      0.000       0.138       0.440\n",
            "log_freq       0.1392      0.044      3.171      0.002       0.053       0.225\n",
            "==============================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.5 Interpret Language Coefficient"
      ],
      "metadata": {
        "id": "-RMnIFIadCr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beta_lang = nb_model.params[\"language\"]\n",
        "p_lang = nb_model.pvalues[\"language\"]\n",
        "\n",
        "print(\"Language coefficient:\", beta_lang)\n",
        "print(\"p-value:\", p_lang)\n",
        "\n",
        "# Incidence Rate Ratio\n",
        "irr = np.exp(beta_lang)\n",
        "print(\"Incidence Rate Ratio (English vs Chinese):\", irr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1rm2MPBdJrn",
        "outputId": "d7f336bf-df35-472c-cb9e-8ee8145852e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language coefficient: 0.28917247215206215\n",
            "p-value: 0.00017334477343979366\n",
            "Incidence Rate Ratio (English vs Chinese): 1.3353220145305185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.6 Visualization"
      ],
      "metadata": {
        "id": "PwUsQtwpeTbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create frequency range\n",
        "freq_range = np.linspace(df[\"log_freq\"].min(), df[\"log_freq\"].max(), 100)\n",
        "\n",
        "# Create prediction dataframe\n",
        "pred_df_en = pd.DataFrame({\n",
        "    \"language\": 1,\n",
        "    \"log_freq\": freq_range\n",
        "})\n",
        "\n",
        "pred_df_zh = pd.DataFrame({\n",
        "    \"language\": 0,\n",
        "    \"log_freq\": freq_range\n",
        "})\n",
        "\n",
        "# Predict expected k\n",
        "pred_en = poisson_model.predict(pred_df_en)\n",
        "pred_zh = poisson_model.predict(pred_df_zh)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(freq_range, pred_en, label=\"English\", linewidth=2)\n",
        "plt.plot(freq_range, pred_zh, label=\"Chinese\", linewidth=2)\n",
        "plt.xlabel(\"Log Frequency\")\n",
        "plt.ylabel(\"Predicted Sense Count (k)\")\n",
        "plt.title(\"Predicted Polysemy by Frequency and Language (Poisson GLM)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "DGFF37pdeWq5",
        "outputId": "ce87b260-5e74-4919-9169-e26d4871a4fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Qualitative Analysis"
      ],
      "metadata": {
        "id": "O3m1UJnseHjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 6: Qualitative Analysis — Sense Cluster Inspection\n",
        "=========================================================\n",
        "For each polysemous lemma, retrieves representative example verses\n",
        "for each induced sense cluster. This supports the qualitative\n",
        "analysis section of the paper, demonstrating that clusters correspond\n",
        "to meaningful, interpretable senses.\n",
        "\n",
        "Also generates a LaTeX-ready table of top polysemous words\n",
        "for both languages (for paper Table 3).\n",
        "\n",
        "Outputs:\n",
        "  - output/qualitative_en_top_polysemous.txt   (sense examples)\n",
        "  - output/qualitative_zh_top_polysemous.txt\n",
        "  - output/table_top_polysemous_latex.tex       (LaTeX table)\n",
        "  - output/polysemy_profile_comparison.csv      (wide comparison table)\n",
        "\n",
        "Usage:\n",
        "  python 06_qualitative_analysis.py\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR    = Path(\"/content\") / \"bible_data\"\n",
        "OUTPUT_DIR = Path(\"/content\") / \"output\"\n",
        "# DATA_DIR   = Path(__file__).parent.parent / \"data\"\n",
        "# OUTPUT_DIR = Path(__file__).parent.parent / \"output\"\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "TOP_N_WORDS       = 20   # Top N most polysemous lemmas per language\n",
        "EXAMPLES_PER_SENSE = 2   # Number of example verses per cluster\n",
        "\n",
        "\n",
        "# ─── Sense Example Retrieval ─────────────────────────────────────────────────\n",
        "\n",
        "def get_sense_examples(\n",
        "    lang: str,\n",
        "    top_n: int = TOP_N_WORDS,\n",
        "    examples_per_sense: int = EXAMPLES_PER_SENSE,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    For the top_n most polysemous lemmas, retrieve example contexts\n",
        "    for each induced sense cluster.\n",
        "\n",
        "    Returns a formatted string ready for a paper's qualitative appendix.\n",
        "    \"\"\"\n",
        "    results_df = pd.read_csv(DATA_DIR / f\"{lang}_wsi_results.csv\")\n",
        "    labels_df  = pd.read_csv(DATA_DIR / f\"{lang}_sense_labels.csv\")\n",
        "    nouns_df   = pd.read_csv(DATA_DIR / f\"{lang}_nouns.csv\")\n",
        "\n",
        "    # Top polysemous by k_ward\n",
        "    poly = results_df[results_df[\"k_ward\"] > 1].nlargest(top_n, \"k_ward\")\n",
        "\n",
        "    # Merge labels with original contexts\n",
        "    merged = labels_df.merge(\n",
        "        nouns_df[[\"lemma\", \"verse_id\", \"context\"]].drop_duplicates(),\n",
        "        on=[\"lemma\", \"verse_id\"],\n",
        "        how=\"left\",\n",
        "    )\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"{'='*60}\")\n",
        "    lines.append(f\"QUALITATIVE SENSE ANALYSIS — {lang.upper()}\")\n",
        "    lines.append(f\"Top {top_n} Most Polysemous Nouns (WSI, Ward Clustering)\")\n",
        "    lines.append(f\"{'='*60}\\n\")\n",
        "\n",
        "    for _, row in poly.iterrows():\n",
        "        lemma = row[\"lemma\"]\n",
        "        k     = int(row[\"k_ward\"])\n",
        "        n_occ = int(row[\"n_occurrences\"])\n",
        "        sil   = row.get(\"silhouette_ward\", \"N/A\")\n",
        "\n",
        "        lines.append(f\"Lemma: '{lemma}'  |  k={k}  |  n={n_occ}  |  silhouette={sil}\")\n",
        "        lines.append(\"-\" * 50)\n",
        "\n",
        "        lemma_data = merged[merged[\"lemma\"] == lemma]\n",
        "\n",
        "        for cluster_id in range(k):\n",
        "            cluster_rows = lemma_data[lemma_data[\"cluster_ward\"] == cluster_id]\n",
        "            lines.append(f\"  Sense {cluster_id + 1} ({len(cluster_rows)} occurrences):\")\n",
        "\n",
        "            # Sample diverse examples\n",
        "            sample = cluster_rows.dropna(subset=[\"context\"]).head(examples_per_sense)\n",
        "            for _, ex in sample.iterrows():\n",
        "                ctx = str(ex[\"context\"])[:200].replace(\"\\n\", \" \")\n",
        "                lines.append(f\"    • {ex['verse_id']}: {ctx}\")\n",
        "\n",
        "        lines.append(\"\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# ─── LaTeX Table Generation ──────────────────────────────────────────────────\n",
        "\n",
        "def generate_latex_table(top_n: int = 15) -> str:\n",
        "    \"\"\"\n",
        "    Generate a LaTeX longtable comparing top polysemous nouns in both languages.\n",
        "    Format:\n",
        "      Rank | English Lemma | EN k | Chinese Lemma | ZH k\n",
        "    \"\"\"\n",
        "    en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "    zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "    en_top = en.nlargest(top_n, \"k_ward\")[[\"lemma\", \"k_ward\", \"n_occurrences\"]].reset_index(drop=True)\n",
        "    zh_top = zh.nlargest(top_n, \"k_ward\")[[\"lemma\", \"k_ward\", \"n_occurrences\"]].reset_index(drop=True)\n",
        "\n",
        "    lines = [\n",
        "        r\"\\begin{table}[h]\",\n",
        "        r\"\\centering\",\n",
        "        r\"\\caption{Top Polysemous Common Nouns by Induced Sense Count (k): English vs. Chinese}\",\n",
        "        r\"\\label{tab:top_polysemous}\",\n",
        "        r\"\\begin{tabular}{clccclcc}\",\n",
        "        r\"\\toprule\",\n",
        "        r\"Rank & English Lemma & EN $k$ & EN $n$ & & Chinese Lemma & ZH $k$ & ZH $n$ \\\\\",\n",
        "        r\"\\midrule\",\n",
        "    ]\n",
        "\n",
        "    for i in range(top_n):\n",
        "        en_row = en_top.iloc[i] if i < len(en_top) else None\n",
        "        zh_row = zh_top.iloc[i] if i < len(zh_top) else None\n",
        "\n",
        "        en_lemma = en_row[\"lemma\"]                  if en_row is not None else \"\"\n",
        "        en_k     = int(en_row[\"k_ward\"])            if en_row is not None else \"\"\n",
        "        en_n     = int(en_row[\"n_occurrences\"])     if en_row is not None else \"\"\n",
        "        zh_lemma = zh_row[\"lemma\"]                  if zh_row is not None else \"\"\n",
        "        zh_k     = int(zh_row[\"k_ward\"])            if zh_row is not None else \"\"\n",
        "        zh_n     = int(zh_row[\"n_occurrences\"])     if zh_row is not None else \"\"\n",
        "\n",
        "        lines.append(\n",
        "            f\"{i+1} & {en_lemma} & {en_k} & {en_n} & & {zh_lemma} & {zh_k} & {zh_n} \\\\\\\\\"\n",
        "        )\n",
        "\n",
        "    lines += [\n",
        "        r\"\\bottomrule\",\n",
        "        r\"\\end{tabular}\",\n",
        "        r\"\\end{table}\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# ─── Wide Comparison Profile ─────────────────────────────────────────────────\n",
        "\n",
        "def generate_comparison_profile() -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create a summary comparison table for paper Table 2.\n",
        "    \"\"\"\n",
        "    en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "    zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "    def profile(df: pd.DataFrame, lang: str) -> dict:\n",
        "        return {\n",
        "            \"Language\":            lang,\n",
        "            \"Total lemmas\":        len(df),\n",
        "            \"Mean k (Ward)\":       round(df[\"k_ward\"].mean(), 3),\n",
        "            \"Median k (Ward)\":     round(df[\"k_ward\"].median(), 3),\n",
        "            \"Std k (Ward)\":        round(df[\"k_ward\"].std(ddof=1), 3),\n",
        "            \"% Monosemous (k=1)\":  round((df[\"k_ward\"] == 1).mean() * 100, 1),\n",
        "            \"% Polysemous (k>1)\":  round((df[\"k_ward\"] > 1).mean() * 100, 1),\n",
        "            \"Max k\":               int(df[\"k_ward\"].max()),\n",
        "            \"Mean k (KMeans)\":     round(df[\"k_kmeans\"].mean(), 3),\n",
        "            \"Agreement (Ward=KM)\": round((df[\"k_ward\"] == df[\"k_kmeans\"]).mean() * 100, 1),\n",
        "        }\n",
        "\n",
        "    rows = [profile(en, \"English\"), profile(zh, \"Chinese\")]\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "d6Rm4f_vdq7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "# DATA_DIR and OUTPUT_DIR are defined in previous cells and are globally accessible.\n",
        "# For example, they are set in cell d6Rm4f_vdq7A.\n",
        "# DATA_DIR    = Path(\"/content\") / \"bible_data\"\n",
        "# OUTPUT_DIR = Path(\"/content\") / \"output\"\n",
        "# OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "TOP_N_WORDS       = 20   # Top N most polysemous lemmas per language\n",
        "EXAMPLES_PER_SENSE = 2   # Number of example verses per cluster\n",
        "\n",
        "# ─── Sense Example Retrieval (Corrected) ─────────────────────────────────────────────────\n",
        "\n",
        "def get_sense_examples(\n",
        "    lang: str,\n",
        "    top_n: int = TOP_N_WORDS,\n",
        "    examples_per_sense: int = EXAMPLES_PER_SENSE,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    For the top_n most polysemous lemmas, retrieve example contexts\n",
        "    for each induced sense cluster.\n",
        "\n",
        "    Returns a formatted string ready for a paper's qualitative appendix.\n",
        "    \"\"\"\n",
        "    results_df = pd.read_csv(DATA_DIR / f\"{lang}_wsi_results.csv\")\n",
        "    labels_df  = pd.read_csv(DATA_DIR / f\"{lang}_sense_labels.csv\")\n",
        "    nouns_df   = pd.read_csv(DATA_DIR / f\"{lang}_nouns.csv\")\n",
        "\n",
        "    # Top polysemous by k_hdbscan (was k_ward)\n",
        "    poly = results_df[results_df[\"k_hdbscan\"] > 1].nlargest(top_n, \"k_hdbscan\")\n",
        "\n",
        "    # Merge labels with original contexts\n",
        "    merged = labels_df.merge(\n",
        "        nouns_df[[\"lemma\", \"verse_id\", \"context\"]].drop_duplicates(),\n",
        "        on=[\"lemma\", \"verse_id\"],\n",
        "        how=\"left\",\n",
        "    )\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"{'='*60}\")\n",
        "    lines.append(f\"QUALITATIVE SENSE ANALYSIS — {lang.upper()}\")\n",
        "    # Updated title to reflect HDBSCAN\n",
        "    lines.append(f\"Top {top_n} Most Polysemous Nouns (WSI, HDBSCAN Clustering)\")\n",
        "    lines.append(f\"{'='*60}\\n\")\n",
        "\n",
        "    for _, row in poly.iterrows():\n",
        "        lemma = row[\"lemma\"]\n",
        "        # Use k_hdbscan\n",
        "        k     = int(row[\"k_hdbscan\"])\n",
        "        n_occ = int(row[\"n_instances\"])\n",
        "        # silhouette_ward is not available for HDBSCAN, so remove or set to N/A\n",
        "        # sil   = row.get(\"silhouette_ward\", \"N/A\") # Removed\n",
        "\n",
        "        # Updated output line, removed silhouette score\n",
        "        lines.append(f\"Lemma: '{lemma}'  |  k={k}  |  n={n_occ}\")\n",
        "        lines.append(\"-\" * 50)\n",
        "\n",
        "        lemma_data = merged[merged[\"lemma\"] == lemma]\n",
        "\n",
        "        for cluster_id in range(k):\n",
        "            # Use cluster_hdbscan\n",
        "            cluster_rows = lemma_data[lemma_data[\"cluster_hdbscan\"] == cluster_id]\n",
        "            lines.append(f\"  Sense {cluster_id + 1} ({len(cluster_rows)} occurrences):\")\n",
        "\n",
        "            # Sample diverse examples\n",
        "            sample = cluster_rows.dropna(subset=[\"context\"]).head(examples_per_sense)\n",
        "            for _, ex in sample.iterrows():\n",
        "                ctx = str(ex[\"context\"])[:200].replace(\"\\n\", \" \")\n",
        "                lines.append(f\"    • {ex['verse_id']}: {ctx}\")\n",
        "\n",
        "        lines.append(\"\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# ─── LaTeX Table Generation (Corrected) ──────────────────────────────────────────────────\n",
        "\n",
        "def generate_latex_table(top_n: int = 15) -> str:\n",
        "    \"\"\"\n",
        "    Generate a LaTeX longtable comparing top polysemous nouns in both languages.\n",
        "    Format:\n",
        "      Rank | English Lemma | EN k | Chinese Lemma | ZH k\n",
        "    \"\"\"\n",
        "    en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "    zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "    # Use k_hdbscan for nlargest and column selection\n",
        "    en_top = en.nlargest(top_n, \"k_hdbscan\")[[\"lemma\", \"k_hdbscan\", \"n_instances\"]].reset_index(drop=True)\n",
        "    zh_top = zh.nlargest(top_n, \"k_hdbscan\")[[\"lemma\", \"k_hdbscan\", \"n_instances\"]].reset_index(drop=True)\n",
        "\n",
        "    lines = [\n",
        "        r\"\\begin{table}[h]\",\n",
        "        r\"\\centering\",\n",
        "        r\"\\caption{Top Polysemous Common Nouns by Induced Sense Count (k, HDBSCAN): English vs. Chinese}\", # Updated caption\n",
        "        r\"\\label{tab:top_polysemous}\",\n",
        "        r\"\\begin{tabular}{clccclcc}\",\n",
        "        r\"\\toprule\",\n",
        "        r\"Rank & English Lemma & EN $k$ & EN $n$ & & Chinese Lemma & ZH $k$ & ZH $n$ \\\\\",\n",
        "        r\"\\midrule\",\n",
        "    ]\n",
        "\n",
        "    for i in range(top_n):\n",
        "        en_row = en_top.iloc[i] if i < len(en_top) else None\n",
        "        zh_row = zh_top.iloc[i] if i < len(zh_top) else None\n",
        "\n",
        "        en_lemma = en_row[\"lemma\"]                  if en_row is not None else \"\"\n",
        "        en_k     = int(en_row[\"k_hdbscan\"])            if en_row is not None else \"\" # Use k_hdbscan\n",
        "        en_n     = int(en_row[\"n_instances\"])     if en_row is not None else \"\"\n",
        "        zh_lemma = zh_row[\"lemma\"]                  if zh_row is not None else \"\"\n",
        "        zh_k     = int(zh_row[\"k_hdbscan\"])            if zh_row is not None else \"\" # Use k_hdbscan\n",
        "        zh_n     = int(zh_row[\"n_instances\"])     if zh_row is not None else \"\"\n",
        "\n",
        "        lines.append(\n",
        "            f\"{i+1} & {en_lemma} & {en_k} & {en_n} & & {zh_lemma} & {zh_k} & {zh_n} \\\\\"\n",
        "        )\n",
        "\n",
        "    lines += [\n",
        "        r\"\\bottomrule\",\n",
        "        r\"\\end{tabular}\",\n",
        "        r\"\\end{table}\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# ─── Wide Comparison Profile (Copied for context) ─────────────────────────────────────────────────\n",
        "\n",
        "def generate_comparison_profile() -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create a summary comparison table for paper Table 2.\n",
        "    \"\"\"\n",
        "    en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "    zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "    def profile(df: pd.DataFrame, lang: str) -> dict:\n",
        "        return {\n",
        "            \"Language\":            lang,\n",
        "            \"Total lemmas\":        len(df),\n",
        "            \"Mean k (HDBSCAN)\":    round(df[\"k_hdbscan\"].mean(), 3), # Use k_hdbscan\n",
        "            \"Median k (HDBSCAN)\":  round(df[\"k_hdbscan\"].median(), 3), # Use k_hdbscan\n",
        "            \"Std k (HDBSCAN)\":     round(df[\"k_hdbscan\"].std(ddof=1), 3), # Use k_hdbscan\n",
        "            \"% Monosemous (k=1)\":  round((df[\"k_hdbscan\"] == 1).mean() * 100, 1), # Use k_hdbscan\n",
        "            \"% Polysemous (k>1)\":  round((df[\"k_hdbscan\"] > 1).mean() * 100, 1), # Use k_hdbscan\n",
        "            \"Max k\":               int(df[\"k_hdbscan\"].max()), # Use k_hdbscan\n",
        "            # Removed KMeans related metrics as they are no longer generated\n",
        "            # \"Mean k (KMeans)\":     round(df[\"k_kmeans\"].mean(), 3),\n",
        "            # \"Agreement (Ward=KM)\": round((df[\"k_ward\"] == df[\"k_kmeans\"]).mean() * 100, 1),\n",
        "        }\n",
        "\n",
        "    rows = [profile(en, \"English\"), profile(zh, \"Chinese\")]\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Step 6: Qualitative Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ── Sense examples ────────────────────────────────────────────\n",
        "for lang in [\"english\", \"chinese\"]:\n",
        "    text = get_sense_examples(lang)\n",
        "    out  = OUTPUT_DIR / f\"qualitative_{lang}_top_polysemous.txt\"\n",
        "    out.write_text(text, encoding=\"utf-8\")\n",
        "    print(f\"  [saved] {out.name}\")\n",
        "\n",
        "# ── LaTeX table ───────────────────────────────────────────────\n",
        "latex = generate_latex_table(top_n=15)\n",
        "tex_path = OUTPUT_DIR / \"table_top_polysemous_latex.tex\"\n",
        "tex_path.write_text(latex, encoding=\"utf-8\")\n",
        "print(f\"  [saved] {tex_path.name}\")\n",
        "\n",
        "# ── Comparison profile ────────────────────────────────────────\n",
        "profile = generate_comparison_profile()\n",
        "csv_path = OUTPUT_DIR / \"polysemy_profile_comparison.csv\"\n",
        "profile.to_csv(csv_path, index=False)\n",
        "print(f\"  [saved] {csv_path.name}\")\n",
        "print()\n",
        "print(profile.to_string(index=False))\n",
        "\n",
        "print(\"\\n✓ Step 6 complete.\\n\")"
      ],
      "metadata": {
        "id": "K9Gd4DVWeOYw",
        "outputId": "7c5ac391-1277-4f6a-bea4-9c6dbdaca453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Step 6: Qualitative Analysis\n",
            "============================================================\n",
            "  [saved] qualitative_english_top_polysemous.txt\n",
            "  [saved] qualitative_chinese_top_polysemous.txt\n",
            "  [saved] table_top_polysemous_latex.tex\n",
            "  [saved] polysemy_profile_comparison.csv\n",
            "\n",
            "Language  Total lemmas  Mean k (HDBSCAN)  Median k (HDBSCAN)  Std k (HDBSCAN)  % Monosemous (k=1)  % Polysemous (k>1)  Max k\n",
            " English           606             1.556                 1.0            0.682                53.1                46.9      5\n",
            " Chinese           574             1.138                 1.0            0.418                88.2                11.8      5\n",
            "\n",
            "✓ Step 6 complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "U, p = mannwhitneyu(niv_en[\"k_hdbscan\"], kjv_en[\"k_hdbscan\"])\n",
        "print(p)"
      ],
      "metadata": {
        "id": "7nQk_A_xStiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "edJRfctRS3si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7150f635",
        "outputId": "a4ef6ad8-667a-4eb3-c22e-d4e2a4c05a2e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure niv_en and kjv_en are available. If not, load them.\n",
        "# Assuming they are already loaded from previous steps\n",
        "# niv_en = pd.read_csv('/content/bible_data_niv/english_wsi_results.csv')\n",
        "# kjv_en = pd.read_csv('/content/bible_data/english_wsi_results.csv')\n",
        "\n",
        "# Combine the dataframes for plotting\n",
        "combined_k_hdbscan = pd.concat([\n",
        "    kjv_en[['k_hdbscan']].assign(Translation='KJV English'),\n",
        "    niv_en[['k_hdbscan']].assign(Translation='NIV English')\n",
        "])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.violinplot(data=combined_k_hdbscan, x='Translation', y='k_hdbscan', palette='viridis', inner='box')\n",
        "plt.title('Distribution of Induced Senses (k_hdbscan) for KJV vs. NIV English')\n",
        "plt.xlabel('Translation')\n",
        "plt.ylabel('Number of Induced Senses (k_hdbscan)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot to the output directory\n",
        "if 'OUTPUT_DIR' in locals() or 'OUTPUT_DIR' in globals():\n",
        "    plot_filename = OUTPUT_DIR / \"k_hdbscan_distribution_kjv_niv.png\"\n",
        "    plt.savefig(plot_filename, dpi=300)\n",
        "    print(f\"Saved plot to {plot_filename}\")\n",
        "else:\n",
        "    print(\"OUTPUT_DIR not defined. Plot not saved to file.\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot to /content/output/k_hdbscan_distribution_kjv_niv.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/bible_data/chinese*"
      ],
      "metadata": {
        "id": "1dVf5W-UNvZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output_kjv_cht_hdbscan.zip /content/output/"
      ],
      "metadata": {
        "id": "wnUe-3lgedhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4abb67-f427-4978-f172-2eef440f6a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/polysemy_profile_comparison.csv (deflated 24%)\n",
            "  adding: content/output/validation_correlation_zh.csv (deflated 47%)\n",
            "  adding: content/output/qualitative_english_top_polysemous.txt (deflated 70%)\n",
            "  adding: content/output/statistical_comparison.csv (deflated 31%)\n",
            "  adding: content/output/figures/ (stored 0%)\n",
            "  adding: content/output/figures/sense_distribution_english.png (deflated 18%)\n",
            "  adding: content/output/figures/wordnet_correlation_en.png (deflated 12%)\n",
            "  adding: content/output/figures/comparison_violinplot.png (deflated 9%)\n",
            "  adding: content/output/figures/sense_distribution_chinese.png (deflated 19%)\n",
            "  adding: content/output/validation_correlation_en.csv (deflated 54%)\n",
            "  adding: content/output/qualitative_chinese_top_polysemous.txt (deflated 65%)\n",
            "  adding: content/output/table_top_polysemous_latex.tex (deflated 43%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r data_kjv_cht_hdbscan.zip /content/bible_data/"
      ],
      "metadata": {
        "id": "Pj8aPu8Cfp1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a25265-ecec-4ef9-b37e-8a7b369c2a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/bible_data/ (stored 0%)\n",
            "  adding: content/bible_data/english_embeddings.npz (deflated 0%)\n",
            "  adding: content/bible_data/english_wsi_results.csv (deflated 54%)\n",
            "  adding: content/bible_data/english_verses.csv (deflated 70%)\n",
            "  adding: content/bible_data/english_noun_freq.csv (deflated 57%)\n",
            "  adding: content/bible_data/english_sense_labels.csv (deflated 82%)\n",
            "  adding: content/bible_data/english_nouns.csv (deflated 90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output\n",
        "!rm -rf bible_data"
      ],
      "metadata": {
        "id": "Xco5z30hrNhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ac45311"
      },
      "source": [
        "# Visualize Word Sense Clusters\n",
        "To visualize the word sense clusters for 'bread' and '餅', I will perform the following steps:\n",
        "\n",
        "1.  **Install UMAP**: Ensure the `umap-learn` library is installed for dimensionality reduction.\n",
        "2.  **Load Data**: Load the English and Chinese word embeddings (`english_embeddings.npz`, `chinese_embeddings.npz`) and sense labels (`english_sense_labels.csv`, `chinese_sense_labels.csv`).\n",
        "3.  **Filter by Lemma**: Select data specifically for the lemma 'bread' in English and '餅' (bǐng, meaning 'cake' or 'flatbread') in Chinese.\n",
        "4.  **Dimensionality Reduction**: Apply UMAP to reduce the high-dimensional embeddings of these lemmas to two dimensions (2D) for easier plotting.\n",
        "5.  **Plot Sense Clusters**: Create scatter plots for both 'bread' and '餅', where each point represents an occurrence of the word, and its color indicates the induced sense cluster. Add a legend to distinguish between senses.\n",
        "6.  **Review Plots**: Examine the generated plots to visually assess the separation and distinctness of the induced sense clusters for both lemmas.\n",
        "\n",
        "This visualization will help in qualitatively understanding how well the clustering algorithm separated the different meanings of these words based on their contextual embeddings.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import umap\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration\n",
        "DATA_DIR = Path(\"/content\") / \"bible_data\"\n",
        "OUTPUT_DIR = Path(\"/content\") / \"output\"\n",
        "FIG_DIR = OUTPUT_DIR / \"figures\"\n",
        "FIG_DIR.mkdir(exist_ok=True) # Ensure figures directory exists\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# --- Function to load data and filter by lemma ---\n",
        "def load_lemma_data(lang: str, lemma: str):\n",
        "    \"\"\"Loads embeddings and sense labels for a specific lemma.\"\"\"\n",
        "    embeddings_file = DATA_DIR / f\"{lang}_embeddings.npz\"\n",
        "    labels_file = DATA_DIR / f\"{lang}_sense_labels.csv\"\n",
        "\n",
        "    print(f\"Loading data for {lang} lemma '{lemma}'...\")\n",
        "\n",
        "    # Load embeddings and lemmas from .npz\n",
        "    data = np.load(embeddings_file, allow_pickle=True)\n",
        "    all_embeddings = data[\"embeddings\"]\n",
        "    all_lemmas = data[\"lemmas\"]\n",
        "    all_verse_ids = data[\"verse_ids\"]\n",
        "\n",
        "    # Filter for the specific lemma\n",
        "    lemma_mask = (all_lemmas == lemma)\n",
        "    lemma_embeddings = all_embeddings[lemma_mask]\n",
        "    lemma_verse_ids = all_verse_ids[lemma_mask]\n",
        "\n",
        "    # Load sense labels\n",
        "    labels_df = pd.read_csv(labels_file)\n",
        "    # Filter labels for the specific lemma and relevant verse_ids\n",
        "    lemma_labels_df = labels_df[\n",
        "        (labels_df[\"lemma\"] == lemma) & (labels_df[\"verse_id\"].isin(lemma_verse_ids))\n",
        "    ].copy()\n",
        "\n",
        "    # Ensure the order of labels matches the order of embeddings\n",
        "    # This assumes verse_ids in embeddings are unique enough or can be joined reliably\n",
        "    # If not, a more robust merge is needed using original index or full context\n",
        "    # For now, we'll align by verse_id, assuming embeddings and labels are generated from the same source order\n",
        "    lemma_labels_df = lemma_labels_df.set_index('verse_id').loc[lemma_verse_ids].reset_index()\n",
        "\n",
        "    if len(lemma_embeddings) != len(lemma_labels_df):\n",
        "        print(f\"Warning: Mismatch in count for '{lemma}'. Embeddings: {len(lemma_embeddings)}, Labels: {len(lemma_labels_df)}\")\n",
        "        # Attempt to reconcile by matching contexts if available, or just proceed with common.\n",
        "        # For simplicity, proceeding assuming verse_ids align after filtering\n",
        "        # If this causes issues, more rigorous data alignment might be needed.\n",
        "\n",
        "    # Only keep Ward clustering labels for visualization as per plan\n",
        "    sense_labels = lemma_labels_df[\"cluster_ward\"].values\n",
        "\n",
        "    print(f\"Found {len(lemma_embeddings)} occurrences for '{lemma}'.\")\n",
        "    return lemma_embeddings, sense_labels, lemma_verse_ids\n",
        "\n",
        "# --- Function for UMAP dimensionality reduction ---\n",
        "def apply_umap(embeddings: np.ndarray, n_components: int = 2):\n",
        "    \"\"\"Applies UMAP for dimensionality reduction.\"\"\"\n",
        "    print(f\"Applying UMAP to reduce embeddings to {n_components}D...\")\n",
        "    reducer = umap.UMAP(\n",
        "        n_components=n_components,\n",
        "        random_state=RANDOM_STATE,\n",
        "        metric='cosine', # Good for high-dimensional data like embeddings\n",
        "        n_jobs=-1 # Use all available cores\n",
        "    )\n",
        "    reduced_embeddings = reducer.fit_transform(embeddings)\n",
        "    return reduced_embeddings\n",
        "\n",
        "# --- Function to plot sense clusters ---\n",
        "def plot_sense_clusters(\n",
        "    reduced_embeddings: np.ndarray,\n",
        "    sense_labels: np.ndarray,\n",
        "    lemma: str,\n",
        "    lang: str,\n",
        "):\n",
        "    \"\"\"Generates a scatter plot of 2D embeddings, colored by sense cluster.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    unique_senses = sorted(np.unique(sense_labels))\n",
        "\n",
        "    # Use a color palette suitable for categorical data\n",
        "    palette = sns.color_palette(\"tab10\", n_colors=len(unique_senses))\n",
        "\n",
        "    for i, sense_id in enumerate(unique_senses):\n",
        "        mask = (sense_labels == sense_id)\n",
        "        plt.scatter(\n",
        "            reduced_embeddings[mask, 0],\n",
        "            reduced_embeddings[mask, 1],\n",
        "            label=f\"Sense {sense_id + 1}\",\n",
        "            color=palette[i],\n",
        "            alpha=0.7,\n",
        "            s=50, # size of points\n",
        "            edgecolors='w', # white edge for better visibility\n",
        "            linewidth=0.5\n",
        "        )\n",
        "\n",
        "    plt.title(f\"UMAP Visualization of {lang.capitalize()} '{lemma}' Sense Clusters\", fontsize=14)\n",
        "    plt.xlabel(\"UMAP Component 1\", fontsize=12)\n",
        "    plt.ylabel(\"UMAP Component 2\", fontsize=12)\n",
        "    plt.legend(title=\"Sense Clusters\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "    plot_filename = FIG_DIR / f\"{lang}_{lemma}_sense_clusters_umap.png\"\n",
        "    plt.savefig(plot_filename, dpi=300)\n",
        "    plt.show()\n",
        "    print(f\"Saved plot to {plot_filename}\")\n",
        "\n",
        "# --- Main execution ---\n",
        "print(\"--- Starting Sense Cluster Visualization ---\")\n",
        "\n",
        "# 1. English 'bread'\n",
        "en_lemma = \"bread\"\n",
        "en_embeddings, en_labels, _ = load_lemma_data(\"english\", en_lemma)\n",
        "if len(en_embeddings) > 0:\n",
        "    en_reduced_embeddings = apply_umap(en_embeddings)\n",
        "    plot_sense_clusters(en_reduced_embeddings, en_labels, en_lemma, \"english\")\n",
        "else:\n",
        "    print(f\"No embeddings found for English lemma '{en_lemma}'. Skipping visualization.\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Chinese '餅'\n",
        "zh_lemma = \"餅\"\n",
        "zh_embeddings, zh_labels, _ = load_lemma_data(\"chinese\", zh_lemma)\n",
        "if len(zh_embeddings) > 0:\n",
        "    zh_reduced_embeddings = apply_umap(zh_embeddings)\n",
        "    plot_sense_clusters(zh_reduced_embeddings, zh_labels, zh_lemma, \"chinese\")\n",
        "else:\n",
        "    print(f\"No embeddings found for Chinese lemma '{zh_lemma}'. Skipping visualization.\")\n",
        "\n",
        "print(\"\\n--- Sense Cluster Visualization Complete ---\")\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import umap\n",
        "from pathlib import Path\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "DATA_DIR = Path(\"/content\") / \"bible_data\"\n",
        "OUTPUT_DIR = Path(\"/content\") / \"output\"\n",
        "FIG_DIR = OUTPUT_DIR / \"figures\"\n",
        "FIG_DIR.mkdir(exist_ok=True) # Ensure figures directory exists\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# --- Function to load data and filter by lemma ---\n",
        "def load_lemma_data(lang: str, lemma: str):\n",
        "    \"\"\"\n",
        "    Loads embeddings and sense labels for a specific lemma, ensuring proper alignment.\n",
        "    This version slices directly from the full embeddings and labels arrays using global indices.\n",
        "    \"\"\"\n",
        "    embeddings_file = DATA_DIR / f\"{lang}_embeddings.npz\"\n",
        "    labels_file = DATA_DIR / f\"{lang}_sense_labels.csv\"\n",
        "\n",
        "    print(f\"Loading data for {lang} lemma '{lemma}'...\")\n",
        "\n",
        "    if not embeddings_file.exists():\n",
        "        raise FileNotFoundError(f\"Embeddings file not found: {embeddings_file}\")\n",
        "    if not labels_file.exists():\n",
        "        raise FileNotFoundError(f\"Labels file not found: {labels_file}\")\n",
        "\n",
        "    # Load all data from the .npz file\n",
        "    npz_data = np.load(embeddings_file, allow_pickle=True)\n",
        "    all_embeddings_npz = npz_data[\"embeddings\"]\n",
        "    all_lemmas_npz = npz_data[\"lemmas\"]\n",
        "\n",
        "    # Load all sense labels from the .csv file\n",
        "    labels_df_full = pd.read_csv(labels_file)\n",
        "    all_cluster_ward_labels_full = labels_df_full['cluster_ward'].values\n",
        "\n",
        "    # Identify the global indices of occurrences for the target lemma\n",
        "    lemma_indices = np.where(all_lemmas_npz == lemma)[0]\n",
        "\n",
        "    if len(lemma_indices) == 0:\n",
        "        print(f\"No occurrences found for lemma '{lemma}' in {lang} data. Skipping.\")\n",
        "        return np.array([]), np.array([]), np.array([])\n",
        "\n",
        "    # Slice the embeddings and labels using these global indices\n",
        "    lemma_embeddings = all_embeddings_npz[lemma_indices]\n",
        "    lemma_sense_labels = all_cluster_ward_labels_full[lemma_indices]\n",
        "\n",
        "    # Final sanity check on lengths\n",
        "    if len(lemma_embeddings) != len(lemma_sense_labels):\n",
        "        raise ValueError(\n",
        "            f\"Final alignment failed for lemma '{lemma}'. \"\n",
        "            f\"Embeddings count: {len(lemma_embeddings)}, Labels count: {len(lemma_sense_labels)}. \"\n",
        "            \"This indicates a deep inconsistency in data generation which should be investigated in Step 2/3/4.\"\n",
        "        )\n",
        "\n",
        "    print(f\"Found {len(lemma_embeddings)} occurrences for '{lemma}', with aligned labels.\")\n",
        "    # Return None for verse_ids as they are not needed for plotting and the new method doesn't explicitly track them here.\n",
        "    return lemma_embeddings, lemma_sense_labels, None\n",
        "\n",
        "# --- Function for UMAP dimensionality reduction ---\n",
        "def apply_umap(embeddings: np.ndarray, n_components: int = 2):\n",
        "    \"\"\"Applies UMAP for dimensionality reduction.\"\"\"\n",
        "    print(f\"Applying UMAP to reduce embeddings to {n_components}D...\")\n",
        "    reducer = umap.UMAP(\n",
        "        n_components=n_components,\n",
        "        random_state=RANDOM_STATE,\n",
        "        metric='cosine', # Good for high-dimensional data like embeddings\n",
        "        n_jobs=-1 # Use all available cores\n",
        "    )\n",
        "    reduced_embeddings = reducer.fit_transform(embeddings)\n",
        "    return reduced_embeddings\n",
        "\n",
        "# --- Function to plot sense clusters ---\n",
        "def plot_sense_clusters(\n",
        "    reduced_embeddings: np.ndarray,\n",
        "    sense_labels: np.ndarray,\n",
        "    lemma: str,\n",
        "    lang: str,\n",
        "):\n",
        "    \"\"\"Generates a scatter plot of 2D embeddings, colored by sense cluster.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    unique_senses = sorted(np.unique(sense_labels))\n",
        "\n",
        "    # Use a color palette suitable for categorical data\n",
        "    palette = sns.color_palette(\"tab10\", n_colors=len(unique_senses))\n",
        "\n",
        "    for i, sense_id in enumerate(unique_senses):\n",
        "        mask = (sense_labels == sense_id)\n",
        "        plt.scatter(\n",
        "            reduced_embeddings[mask, 0],\n",
        "            reduced_embeddings[mask, 1],\n",
        "            label=f\"Sense {sense_id + 1}\",\n",
        "            color=palette[i],\n",
        "            alpha=0.7,\n",
        "            s=50, # size of points\n",
        "            edgecolors='w', # white edge for better visibility\n",
        "            linewidth=0.5\n",
        "        )\n",
        "\n",
        "    plt.title(f\"UMAP Visualization of {lang.capitalize()} '{lemma}' Sense Clusters\", fontsize=14)\n",
        "    plt.xlabel(\"UMAP Component 1\", fontsize=12)\n",
        "    plt.ylabel(\"UMAP Component 2\", fontsize=12)\n",
        "    plt.legend(title=\"Sense Clusters\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "    plot_filename = FIG_DIR / f\"{lang}_{lemma}_sense_clusters_umap.png\"\n",
        "    plt.savefig(plot_filename, dpi=300)\n",
        "    plt.show()\n",
        "    print(f\"Saved plot to {plot_filename}\")\n",
        "\n",
        "# --- Main execution ---\n",
        "print(\"--- Starting Sense Cluster Visualization ---\")\n",
        "\n",
        "# --- Font Configuration for Chinese Characters ---\n",
        "# Install a Chinese font (e.g., Noto Sans CJK)\n",
        "!apt-get update -qq > /dev/null\n",
        "!apt-get install -qq fonts-noto-cjk > /dev/null\n",
        "\n",
        "# Clear and rebuild matplotlib font cache\n",
        "# This is crucial for newly installed fonts to be recognized\n",
        "fm._load_fontmanager(try_read_cache=False)\n",
        "fm._fmcache = {} # Clear the font cache manually\n",
        "print(\"Matplotlib font cache cleared.\")\n",
        "\n",
        "# Find the path to a Noto Sans CJK font\n",
        "font_files = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
        "chosen_font_path = None\n",
        "for fpath in font_files:\n",
        "    if 'NotoSansCJK' in fpath:\n",
        "        chosen_font_path = fpath\n",
        "        break\n",
        "\n",
        "if chosen_font_path:\n",
        "    print(f\"Found Noto Sans CJK font at: {chosen_font_path}\")\n",
        "    # Add this specific font to font manager\n",
        "    fm.fontManager.addfont(chosen_font_path)\n",
        "\n",
        "    # Get the actual font name from the file\n",
        "    prop = fm.FontProperties(fname=chosen_font_path)\n",
        "    actual_font_name = prop.get_name()\n",
        "    print(f\"Actual font family name: {actual_font_name}\")\n",
        "\n",
        "    # Set generic font family to 'sans-serif'\n",
        "    plt.rcParams['font.family'] = ['sans-serif']\n",
        "    # Add the Chinese font to the beginning of the 'sans-serif' font list\n",
        "    # This makes it the preferred font for sans-serif text.\n",
        "    plt.rcParams['font.sans-serif'] = [actual_font_name] + plt.rcParams['font.sans-serif']\n",
        "    plt.rcParams['axes.unicode_minus'] = False # Fix minus sign display issues\n",
        "    # Set font size for better readability\n",
        "    plt.rcParams[\"font.size\"] = 11\n",
        "    plt.rcParams[\"axes.titlesize\"] = 13\n",
        "    plt.rcParams[\"axes.labelsize\"] = 12\n",
        "    print(f\"Matplotlib configured to use '{actual_font_name}'.\")\n",
        "else:\n",
        "    print(f\"Warning: No Noto Sans CJK font found after install. Chinese characters might not display correctly.\")\n",
        "\n",
        "# 1. English 'bread'\n",
        "en_lemma = \"bread\"\n",
        "en_embeddings, en_labels, _ = load_lemma_data(\"english\", en_lemma)\n",
        "if len(en_embeddings) > 0:\n",
        "    en_reduced_embeddings = apply_umap(en_embeddings)\n",
        "    plot_sense_clusters(en_reduced_embeddings, en_labels, en_lemma, \"english\")\n",
        "else:\n",
        "    print(f\"No embeddings found for English lemma '{en_lemma}'. Skipping visualization.\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Chinese '禮'\n",
        "# The user requested '禮' instead of '餅' in the previous run, so I'll keep '禮' for consistency with the traceback.\n",
        "zh_lemma = \"禮\"\n",
        "zh_embeddings, zh_labels, _ = load_lemma_data(\"chinese\", zh_lemma)\n",
        "if len(zh_embeddings) > 0:\n",
        "    zh_reduced_embeddings = apply_umap(zh_embeddings)\n",
        "    plot_sense_clusters(zh_reduced_embeddings, zh_labels, zh_lemma, \"chinese\")\n",
        "else:\n",
        "    print(f\"No embeddings found for Chinese lemma '{zh_lemma}'. Skipping visualization.\")\n",
        "\n",
        "print(\"\\n--- Sense Cluster Visualization Complete ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfoirPbZ4jrf",
        "outputId": "77a84a8a-bf6a-4e42-e7e8-7cb8a250a675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Sense Cluster Visualization ---\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Matplotlib font cache cleared.\n",
            "Found Noto Sans CJK font at: /usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc\n",
            "Actual font family name: Noto Sans CJK JP\n",
            "Matplotlib configured to use 'Noto Sans CJK JP'.\n",
            "Loading data for english lemma 'bread'...\n",
            "Found 254 occurrences for 'bread', with aligned labels.\n",
            "Applying UMAP to reduce embeddings to 2D...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot to /content/output/figures/english_bread_sense_clusters_umap.png\n",
            "\n",
            "\n",
            "Loading data for chinese lemma '禮'...\n",
            "Found 147 occurrences for '禮', with aligned labels.\n",
            "Applying UMAP to reduce embeddings to 2D...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot to /content/output/figures/chinese_禮_sense_clusters_umap.png\n",
            "\n",
            "--- Sense Cluster Visualization Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "950f8253",
        "outputId": "daf3ab9e-af82-40ab-ec47-ed070ac59885"
      },
      "source": [
        "print(\"--- Quantitative Metrics Comparison ---\")\n",
        "\n",
        "# Metrics for English 'bread'\n",
        "en_bread_metrics = en[en['lemma'] == 'bread']\n",
        "print(\"\\nEnglish 'bread' metrics:\")\n",
        "display(en_bread_metrics[['lemma', 'n_instances', 'k_ward', 'k_kmeans', 'silhouette_ward', 'agreement_pct']])\n",
        "\n",
        "# Metrics for Chinese '禮'\n",
        "zh_li_metrics = zh[zh['lemma'] == '禮']\n",
        "print(\"\\nChinese '禮' metrics:\")\n",
        "display(zh_li_metrics[['lemma', 'n_instances', 'k_ward', 'k_kmeans', 'silhouette_ward', 'agreement_pct']])\n",
        "\n",
        "print(\"\\n--- End of Quantitative Metrics Comparison ---\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Quantitative Metrics Comparison ---\n",
            "\n",
            "English 'bread' metrics:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    lemma  n_instances  k_ward  k_kmeans  silhouette_ward  agreement_pct\n",
              "59  bread          254       8         5           0.3638           56.3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f488b025-3d62-48e0-9191-046126846fd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>n_instances</th>\n",
              "      <th>k_ward</th>\n",
              "      <th>k_kmeans</th>\n",
              "      <th>silhouette_ward</th>\n",
              "      <th>agreement_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>bread</td>\n",
              "      <td>254</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>0.3638</td>\n",
              "      <td>56.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f488b025-3d62-48e0-9191-046126846fd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f488b025-3d62-48e0-9191-046126846fd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f488b025-3d62-48e0-9191-046126846fd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n--- End of Quantitative Metrics Comparison ---\\\")\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"lemma\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"bread\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_instances\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 254,\n        \"max\": 254,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k_ward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k_kmeans\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"silhouette_ward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3637999892234802,\n        \"max\": 0.3637999892234802,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3637999892234802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agreement_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 56.3,\n        \"max\": 56.3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          56.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chinese '禮' metrics:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    lemma  n_instances  k_ward  k_kmeans  silhouette_ward  agreement_pct\n",
              "385     禮          147       2         7           0.3775          39.46"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80c91c0b-1efe-4b75-a076-7e2a887b8226\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>n_instances</th>\n",
              "      <th>k_ward</th>\n",
              "      <th>k_kmeans</th>\n",
              "      <th>silhouette_ward</th>\n",
              "      <th>agreement_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>禮</td>\n",
              "      <td>147</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.3775</td>\n",
              "      <td>39.46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80c91c0b-1efe-4b75-a076-7e2a887b8226')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80c91c0b-1efe-4b75-a076-7e2a887b8226 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80c91c0b-1efe-4b75-a076-7e2a887b8226');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n--- End of Quantitative Metrics Comparison ---\\\")\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"lemma\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u79ae\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_instances\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 147,\n        \"max\": 147,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k_ward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k_kmeans\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"silhouette_ward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3774999976158142,\n        \"max\": 0.3774999976158142,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3774999976158142\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agreement_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 39.46,\n        \"max\": 39.46,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          39.46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- End of Quantitative Metrics Comparison ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.read_csv(\"/content/bible_data/chinese_wsi_results.csv\")\n",
        "polysemous = results[results['k_hdbscan'] > 1].sort_values('n_instances', ascending=False)\n",
        "print(polysemous[['lemma', 'n_instances', 'k_hdbscan']].head(20))"
      ],
      "metadata": {
        "id": "SPzgYOhpf8ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7245a686-35d3-4c14-ae39-d4be5b73ae6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    lemma  n_instances  k_hdbscan\n",
            "16      人         9228          2\n",
            "111     地         1378          2\n",
            "378    祭司          857          2\n",
            "363    眾人          663          2\n",
            "162    子孫          429          4\n",
            "236    支派          374          2\n",
            "534    門徒          335          2\n",
            "159    婦人          312          2\n",
            "559    首領          276          2\n",
            "439     肘          269          4\n",
            "133     壇          267          2\n",
            "414    罪孽          241          2\n",
            "214    惡人          224          2\n",
            "105     國          221          2\n",
            "444     腳          202          2\n",
            "9      主人          182          2\n",
            "51     全地          174          2\n",
            "142    天使          173          2\n",
            "423    義人          166          2\n",
            "318     燈          131          2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_en = pd.read_csv(\"/content/bible_data/english_wsi_results.csv\")\n",
        "polysemous_en = results_en[results_en['k_hdbscan'] > 1].sort_values('n_instances', ascending=False)\n",
        "print(polysemous_en[['lemma', 'n_instances', 'k_hdbscan']].head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4iiRKxib6pI",
        "outputId": "59576ca7-349b-45da-a027-c71caa893b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        lemma  n_instances  k_hdbscan\n",
            "322       man         3927          2\n",
            "513       son         2929          2\n",
            "288      king         2533          4\n",
            "131       day         2037          2\n",
            "248      hand         1296          3\n",
            "186    father         1289          3\n",
            "364  offering         1026          2\n",
            "624      word          984          2\n",
            "563      time          950          4\n",
            "416    priest          903          2\n",
            "632      year          857          4\n",
            "392     place          852          4\n",
            "603       way          818          3\n",
            "88       city          814          2\n",
            "63    brother          784          2\n",
            "254     heart          781          2\n",
            "480   servant          767          2\n",
            "557     thing          745          3\n",
            "350    nation          708          2\n",
            "500       sin          668          2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3a45b27"
      },
      "source": [
        "# Compare KJV & NIV HDBSCAN\n",
        "## Load KJV English Results\n",
        "\n",
        "Rename the current `en` DataFrame to `kjv_en`.\n",
        "\n",
        "## Load NIV English Results\n",
        "\n",
        "Load the English WSI results from the `/content/bible_data_niv/` directory into a new `niv_en` DataFrame.\n",
        "\n",
        "## Perform Mann-Whitney U Test\n",
        "\n",
        "Execute the Mann-Whitney U test comparing `k_hdbscan` for NIV English and KJV English and print the p-value.\n",
        "```python\n",
        "kjv_en = en\n",
        "niv_en = pd.read_csv('/content/bible_data_niv/english_wsi_results.csv')\n",
        "\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "U, p = mannwhitneyu(niv_en[\"k_hdbscan\"], kjv_en[\"k_hdbscan\"])\n",
        "print(f\"Mann-Whitney U test p-value: {p:.6f}\")\n",
        "\n",
        "print(\"\\nKJV English k_hdbscan mean:\", kjv_en[\"k_hdbscan\"].mean())\n",
        "print(\"NIV English k_hdbscan mean:\", niv_en[\"k_hdbscan\"].mean())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fc708c3"
      },
      "source": [
        "## Load KJV English Results\n",
        "\n",
        "### Subtask:\n",
        "Rename the current 'en' DataFrame to 'kjv_en'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ab03dce"
      },
      "source": [
        "**Reasoning**:\n",
        "To rename the DataFrame, I will assign the current 'en' DataFrame to a new variable named 'kjv_en'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3952b3b2",
        "outputId": "3f58b9c2-8556-45a3-ecc7-23490514500a"
      },
      "source": [
        "kjv_en = en\n",
        "print(\"DataFrame 'en' has been renamed to 'kjv_en'.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame 'en' has been renamed to 'kjv_en'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17e4c2d9"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to load the English WSI results for NIV into a new DataFrame named `niv_en` from the `/content/bible_data_niv/` directory, as per the main task's instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97804532",
        "outputId": "a736301e-552d-46b1-951f-fcbc79d33a23"
      },
      "source": [
        "niv_en = pd.read_csv('/content/bible_data_niv/english_wsi_results.csv')\n",
        "print(\"NIV English WSI results loaded into 'niv_en' DataFrame.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NIV English WSI results loaded into 'niv_en' DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "327ec96b"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that both `kjv_en` and `niv_en` DataFrames are prepared, I will perform the Mann-Whitney U test to compare their `k_hdbscan` distributions and print the p-value along with the mean `k_hdbscan` for each DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f47bf74e",
        "outputId": "400391e0-16d7-4aaa-9e14-72fd38239959"
      },
      "source": [
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "U, p = mannwhitneyu(niv_en[\"k_hdbscan\"], kjv_en[\"k_hdbscan\"])\n",
        "print(f\"Mann-Whitney U test p-value: {p:.6f}\")\n",
        "\n",
        "print(\"\\nKJV English k_hdbscan mean:\", kjv_en[\"k_hdbscan\"].mean())\n",
        "print(\"NIV English k_hdbscan mean:\", niv_en[\"k_hdbscan\"].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mann-Whitney U test p-value: 0.872264\n",
            "\n",
            "KJV English k_hdbscan mean: 1.556105610561056\n",
            "NIV English k_hdbscan mean: 1.569182389937107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afa2b544"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **Was the current `en` DataFrame renamed to `kjv_en`?**\n",
        "    Yes, the `en` DataFrame was successfully renamed to `kjv_en`.\n",
        "*   **Were the NIV English WSI results loaded?**\n",
        "    Yes, the NIV English WSI results were loaded into a new `niv_en` DataFrame from the specified directory.\n",
        "*   **What was the p-value of the Mann-Whitney U test?**\n",
        "    The p-value for the Mann-Whitney U test comparing `k_hdbscan` for NIV English and KJV English was $0.872264$.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `en` DataFrame was successfully renamed to `kjv_en`.\n",
        "*   The NIV English WSI results were loaded into the `niv_en` DataFrame.\n",
        "*   The Mann-Whitney U test comparing the `k_hdbscan` values between NIV English and KJV English yielded a p-value of $0.872264$.\n",
        "*   The mean `k_hdbscan` for KJV English was approximately $1.556$.\n",
        "*   The mean `k_hdbscan` for NIV English was approximately $1.569$.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Given the high p-value of $0.872264$, there is no statistically significant difference in the `k_hdbscan` values between the KJV English and NIV English datasets at common significance levels (e.g., $\\alpha = 0.05$). This suggests that the distribution of `k_hdbscan` is similar for both translations.\n",
        "*   Future analysis could investigate other features or conduct similar comparative statistical tests on different metrics to understand potential nuances or differences between the translations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unique Chinese characters"
      ],
      "metadata": {
        "id": "XULQePgzZodf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the path to the chinese_noun_freq.csv file\n",
        "DATA_DIR = Path(\"/content\") / \"bible_data_niv\"\n",
        "chinese_freq_path = DATA_DIR / \"chinese_noun_freq.csv\"\n",
        "\n",
        "try:\n",
        "    # Load the Chinese noun frequency data\n",
        "    chinese_freq_df = pd.read_csv(chinese_freq_path)\n",
        "\n",
        "    # Initialize a set to store unique characters\n",
        "    unique_chars = set()\n",
        "\n",
        "    # Iterate through each lemma and add its characters to the set\n",
        "    for lemma in chinese_freq_df['lemma']:\n",
        "        for char in str(lemma):\n",
        "            unique_chars.add(char)\n",
        "\n",
        "    # Print the total number of unique characters\n",
        "    print(f\"Number of unique Chinese characters: {len(unique_chars)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {chinese_freq_path} was not found.\")\n",
        "    print(\"Please ensure that 'chinese_noun_freq.csv' has been generated by running the preprocessing steps for Chinese data.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKWeEAesZn_l",
        "outputId": "22d24aae-2a62-4765-ad54-d232e62b4e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique Chinese characters: 1990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure dataframes are loaded if not already in memory\n",
        "# Assuming DATA_DIR points to /content/bible_data/ for KJV English and /content/bible_data_niv/ for NIV Chinese\n",
        "DATA_DIR_NIV = Path(\"/content\") / \"bible_data_niv\"\n",
        "DATA_DIR_KJV = Path(\"/content\") / \"bible_data\"\n",
        "\n",
        "# Load Chinese noun frequency data (NIV)\n",
        "# The chinese_freq_df from previous execution referred to NIV Chinese data\n",
        "if 'chinese_freq_df' not in locals():\n",
        "    chinese_freq_df = pd.read_csv(DATA_DIR_NIV / \"chinese_noun_freq.csv\")\n",
        "\n",
        "# Load English noun frequency data (KJV)\n",
        "# The en_freq from previous execution referred to KJV English data\n",
        "en_freq_kjv = pd.read_csv(DATA_DIR_KJV / \"english_noun_freq.csv\")\n",
        "\n",
        "en_freq_niv = pd.read_csv(DATA_DIR_NIV / \"english_noun_freq.csv\")\n",
        "\n",
        "print(\"\\n--- Chinese Noun Character Analysis (NIV) ---\")\n",
        "\n",
        "# 1. Mean characters per Chinese noun\n",
        "chinese_freq_df['lemma_length'] = chinese_freq_df['lemma'].apply(len)\n",
        "mean_chars_zh = chinese_freq_df['lemma_length'].mean()\n",
        "print(f\"1. Mean characters per Chinese noun: {mean_chars_zh:.2f}\")\n",
        "\n",
        "# 2. % of Chinese nouns with length >=2 characters\n",
        "long_lemmas_zh = chinese_freq_df[chinese_freq_df['lemma_length'] >= 2]\n",
        "percent_long_zh = (len(long_lemmas_zh) / len(chinese_freq_df)) * 100\n",
        "print(f\"2. % of Chinese nouns with length >=2 characters: {percent_long_zh:.2f}%\")\n",
        "\n",
        "print(\"\\n--- Frequency Comparison (>=30 freq) ---\")\n",
        "\n",
        "# 3. Number of Chinese nouns >=30 freq vs English nouns >=30 freq\n",
        "chinese_high_freq_nouns = chinese_freq_df[chinese_freq_df['count'] >= 30]\n",
        "num_chinese_high_freq = len(chinese_high_freq_nouns)\n",
        "print(f\"3. Number of Chinese nouns >=30 freq (CUV): {num_chinese_high_freq}\")\n",
        "\n",
        "english_high_freq_nouns_kjv = en_freq_kjv[en_freq_kjv['count'] >= 30]\n",
        "num_english_high_freq_kjv = len(english_high_freq_nouns_kjv)\n",
        "print(f\"   Number of English nouns >=30 freq (KJV): {num_english_high_freq_kjv}\")\n",
        "\n",
        "english_high_freq_nouns_niv = en_freq_niv[en_freq_niv['count'] >= 30]\n",
        "num_english_high_freq_niv = len(english_high_freq_nouns_niv)\n",
        "print(f\"   Number of English nouns >=30 freq (NIV): {num_english_high_freq_niv}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHRemNlcaRVA",
        "outputId": "182daeb9-7f23-4fa6-870a-d388a3cb96cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Chinese Noun Character Analysis (NIV) ---\n",
            "1. Mean characters per Chinese noun: 2.02\n",
            "2. % of Chinese nouns with length >=2 characters: 90.31%\n",
            "\n",
            "--- Frequency Comparison (>=30 freq) ---\n",
            "3. Number of Chinese nouns >=30 freq (CUV): 574\n",
            "   Number of English nouns >=30 freq (KJV): 606\n",
            "   Number of English nouns >=30 freq (NIV): 636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- High Frequency Chinese Nouns (NIV) ---\")\n",
        "print(chinese_high_freq_nouns.head().to_string(index=False))\n",
        "\n",
        "print(\"\\n--- High Frequency English Nouns (KJV) ---\")\n",
        "print(english_high_freq_nouns.head().to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2tZadrcc53B",
        "outputId": "7fbbf410-c361-48de-9b3e-c2e32efe822b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- High Frequency Chinese Nouns (NIV) ---\n",
            "lemma  count  lemma_length\n",
            "    人   9228             1\n",
            "   兒子   2357             2\n",
            "    事   1564             1\n",
            "    話   1500             1\n",
            "    地   1378             1\n",
            "\n",
            "--- High Frequency English Nouns (KJV) ---\n",
            " lemma  count\n",
            "   man   4297\n",
            "   son   3201\n",
            "  king   2795\n",
            "   day   2611\n",
            "people   2145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Combine the dataframes for plotting\n",
        "combined_k_hdbscan_all = pd.concat([\n",
        "    kjv_en[['k_hdbscan']].assign(Translation='KJV English'),\n",
        "    niv_en[['k_hdbscan']].assign(Translation='NIV English'),\n",
        "    zh[['k_hdbscan']].assign(Translation='CUV Chinese')\n",
        "])\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.violinplot(data=combined_k_hdbscan_all, x='Translation', y='k_hdbscan', palette='viridis', inner='box')\n",
        "plt.title('Distribution of Induced Senses (k_hdbscan) for KJV, NIV English and CUV Chinese')\n",
        "plt.xlabel('Translation/Language Version')\n",
        "plt.ylabel('Number of Induced Senses (k_hdbscan)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot to the output directory\n",
        "if 'OUTPUT_DIR' in locals() or 'OUTPUT_DIR' in globals():\n",
        "    plot_filename = OUTPUT_DIR / \"k_hdbscan_distribution_all_versions.png\"\n",
        "    plt.savefig(plot_filename, dpi=300)\n",
        "    print(f\"Saved plot to {plot_filename}\")\n",
        "else:\n",
        "    print(\"OUTPUT_DIR not defined. Plot not saved to file.\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq17Xs3SiMr7",
        "outputId": "8a42e86a-5a75-4de2-d9db-b013c2f58bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot to /content/output/k_hdbscan_distribution_all_versions.png\n"
          ]
        }
      ]
    }
  ]
}
