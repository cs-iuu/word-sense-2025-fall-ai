{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac371f37d9b840d1924bc823a249ead4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb0cddb42e91497fbbf70480c88d1182",
              "IPY_MODEL_3f28f2652756453da13e4c648201c330",
              "IPY_MODEL_4dd05c92334e4055bff644915c111568"
            ],
            "layout": "IPY_MODEL_5310e8aa0d5b4eeba1afc20c35233770"
          }
        },
        "fb0cddb42e91497fbbf70480c88d1182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ac4180627c6440f8b76d4c8194704fe",
            "placeholder": "​",
            "style": "IPY_MODEL_c038bdd2ca2a46bcbc5534f6da50970e",
            "value": "config.json: 100%"
          }
        },
        "3f28f2652756453da13e4c648201c330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb7d23718b9547a88a4c4f6d7d82c717",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47b24e9be3d14f57bfce29d9b26d3f57",
            "value": 615
          }
        },
        "4dd05c92334e4055bff644915c111568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9ee7bc5c4ff47449b9f1d5f214afd88",
            "placeholder": "​",
            "style": "IPY_MODEL_7ed83647f4a04949a5a5b9deb8bd2f89",
            "value": " 615/615 [00:00&lt;00:00, 68.3kB/s]"
          }
        },
        "5310e8aa0d5b4eeba1afc20c35233770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac4180627c6440f8b76d4c8194704fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c038bdd2ca2a46bcbc5534f6da50970e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb7d23718b9547a88a4c4f6d7d82c717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b24e9be3d14f57bfce29d9b26d3f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9ee7bc5c4ff47449b9f1d5f214afd88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed83647f4a04949a5a5b9deb8bd2f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f74d4e59974442459f74a05485b43448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3f99ebba16e43c6a6263a611c741c2a",
              "IPY_MODEL_8f273586172042a89b4df85c955f805d",
              "IPY_MODEL_41341ca9ffed440e8135a8ab4747c5e2"
            ],
            "layout": "IPY_MODEL_d12d4e49405644409cbe6dcc287212dc"
          }
        },
        "c3f99ebba16e43c6a6263a611c741c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71b1186bbbff491eacd8e442888749f4",
            "placeholder": "​",
            "style": "IPY_MODEL_dc5c14eb3748412391df94fd1cee4f7e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8f273586172042a89b4df85c955f805d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd1883933524aa19c50beeaa676f702",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0055d36104984ade9514c499e7385790",
            "value": 25
          }
        },
        "41341ca9ffed440e8135a8ab4747c5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de291430c3c943189ece730a89988fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_ddf709e96cd3400da2ae83530e125da2",
            "value": " 25.0/25.0 [00:00&lt;00:00, 3.29kB/s]"
          }
        },
        "d12d4e49405644409cbe6dcc287212dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b1186bbbff491eacd8e442888749f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc5c14eb3748412391df94fd1cee4f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dd1883933524aa19c50beeaa676f702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0055d36104984ade9514c499e7385790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de291430c3c943189ece730a89988fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddf709e96cd3400da2ae83530e125da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9810101220cb466088b6f70b8cc6ee5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c17110793b2d4057a3ce9b8698a26ae8",
              "IPY_MODEL_76735abe71fc4361bb867f85c478859c",
              "IPY_MODEL_4092888895404747aef972e9cbb44b21"
            ],
            "layout": "IPY_MODEL_71fc157f24904fe7a819d5139adb596c"
          }
        },
        "c17110793b2d4057a3ce9b8698a26ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21d77a9efa54d33a64ae1d93ff1097f",
            "placeholder": "​",
            "style": "IPY_MODEL_6d30e54564eb4f93bb5782b62beb0081",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "76735abe71fc4361bb867f85c478859c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04c0474f83f045aca030bfd5841cd558",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_454e7b84784943acab6cbfeae3830519",
            "value": 5069051
          }
        },
        "4092888895404747aef972e9cbb44b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4de2075584e4eca929912043473b969",
            "placeholder": "​",
            "style": "IPY_MODEL_8e9b280c336c492e8ceaa2ce245c28a9",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 3.90MB/s]"
          }
        },
        "71fc157f24904fe7a819d5139adb596c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21d77a9efa54d33a64ae1d93ff1097f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d30e54564eb4f93bb5782b62beb0081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04c0474f83f045aca030bfd5841cd558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454e7b84784943acab6cbfeae3830519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4de2075584e4eca929912043473b969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e9b280c336c492e8ceaa2ce245c28a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd42cbed9787407cbf12a084ef52b06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59dd73e74b9443bd81c9ac057a9af18a",
              "IPY_MODEL_ccb799fa8a704dbc817a2f3bc2467182",
              "IPY_MODEL_0a47b4b5890948ad9aa7955d7ade2158"
            ],
            "layout": "IPY_MODEL_3e802067235a4ecc84516aefc74bc0b3"
          }
        },
        "59dd73e74b9443bd81c9ac057a9af18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d596d8e38884cd19cefb764197656bb",
            "placeholder": "​",
            "style": "IPY_MODEL_06c7fd2535d64212be48261fbca59a75",
            "value": "tokenizer.json: 100%"
          }
        },
        "ccb799fa8a704dbc817a2f3bc2467182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87a6e7d4177e429fa1370f1ad1125b59",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f8053c0df924dedbfb5214eff3a94fa",
            "value": 9096718
          }
        },
        "0a47b4b5890948ad9aa7955d7ade2158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f956d0b1904de0aa2425fcf532863f",
            "placeholder": "​",
            "style": "IPY_MODEL_7bc1bbe56106462c879a48b74347c89c",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 14.3MB/s]"
          }
        },
        "3e802067235a4ecc84516aefc74bc0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d596d8e38884cd19cefb764197656bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c7fd2535d64212be48261fbca59a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87a6e7d4177e429fa1370f1ad1125b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8053c0df924dedbfb5214eff3a94fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9f956d0b1904de0aa2425fcf532863f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bc1bbe56106462c879a48b74347c89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "991e09c7a16f40dc8d6350a3ed3130c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9534d0df168d4fa0af9c13bba9b4e45f",
              "IPY_MODEL_0887a6a2f412445ea5b5d5cbd09f303a",
              "IPY_MODEL_98167c4ed60e4321ab7fd6c6c50c42e1"
            ],
            "layout": "IPY_MODEL_5e898caf252746b496f927873d18188e"
          }
        },
        "9534d0df168d4fa0af9c13bba9b4e45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93ceee7ee20a43d1949b5023f0184429",
            "placeholder": "​",
            "style": "IPY_MODEL_68fa328d48dc4f2d94b9770711a513d2",
            "value": "model.safetensors: 100%"
          }
        },
        "0887a6a2f412445ea5b5d5cbd09f303a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bac691932efd44aa93130fe9dd9236c6",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09255333bab24257871d9617667ad411",
            "value": 1115567652
          }
        },
        "98167c4ed60e4321ab7fd6c6c50c42e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_081cb87b8bd64fb4b4bf4ae2f1a8fc72",
            "placeholder": "​",
            "style": "IPY_MODEL_5af76fdeea8f4e1b93f3c703a37ca8d4",
            "value": " 1.12G/1.12G [00:02&lt;00:00, 709MB/s]"
          }
        },
        "5e898caf252746b496f927873d18188e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ceee7ee20a43d1949b5023f0184429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68fa328d48dc4f2d94b9770711a513d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bac691932efd44aa93130fe9dd9236c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09255333bab24257871d9617667ad411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "081cb87b8bd64fb4b4bf4ae2f1a8fc72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af76fdeea8f4e1b93f3c703a37ca8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06d1864672a74d158d344584d7f39aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3c2b71df0564b7180ee48bbe28f3fcc",
              "IPY_MODEL_ff3404353f8048ccae8e6e1401ce7267",
              "IPY_MODEL_5cbcbbd27ee74a4a9a9be944815f2379"
            ],
            "layout": "IPY_MODEL_718b1119bf05474d8f14dfc04eef8339"
          }
        },
        "b3c2b71df0564b7180ee48bbe28f3fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_537937162fd74bb389b309ae666f06fd",
            "placeholder": "​",
            "style": "IPY_MODEL_a7d6f65d19fd4010aaff346135ba6bba",
            "value": "Loading weights: 100%"
          }
        },
        "ff3404353f8048ccae8e6e1401ce7267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad51513bd1434d6ba1c0af502f4c3cb3",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_783d4606b814485caa028c1080a224b0",
            "value": 199
          }
        },
        "5cbcbbd27ee74a4a9a9be944815f2379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dccba0fa4004754aa8c17763799b169",
            "placeholder": "​",
            "style": "IPY_MODEL_b26ccbc2770f456685a356b19850f0ed",
            "value": " 199/199 [00:00&lt;00:00, 951.87it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "718b1119bf05474d8f14dfc04eef8339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537937162fd74bb389b309ae666f06fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d6f65d19fd4010aaff346135ba6bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad51513bd1434d6ba1c0af502f4c3cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "783d4606b814485caa028c1080a224b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dccba0fa4004754aa8c17763799b169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26ccbc2770f456685a356b19850f0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-iuu/word-sense-2025-fall-ai/blob/main/notebooks/15.1.wsi_en_cht.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Preprocessing: Extract Common Nouns"
      ],
      "metadata": {
        "id": "OwnCnpqk0M7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy jieba pandas --break-system-packages\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "ZDh6BuKL3z-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 2: Preprocessing\n",
        "======================\n",
        "Tokenizes, POS-tags, and lemmatizes both corpora.\n",
        "Extracts common nouns only (no proper nouns, pronouns, or stopwords).\n",
        "Applies a minimum frequency threshold to filter rare words.\n",
        "\n",
        "Outputs:\n",
        "  - data/english_nouns.csv   : lemma, verse_id, token, context (full verse)\n",
        "  - data/chinese_nouns.csv   : lemma, verse_id, token, context\n",
        "  - data/english_noun_freq.csv\n",
        "  - data/chinese_noun_freq.csv\n",
        "\n",
        "Usage:\n",
        "  pip install spacy jieba pandas --break-system-packages\n",
        "  python -m spacy download en_core_web_sm\n",
        "  python 02_preprocessing.py\n",
        "\n",
        "Design decisions (paper §3.2):\n",
        "  - English: spaCy en_core_web_sm for tokenization, POS, lemmatization\n",
        "  - Chinese: jieba for word segmentation + custom POS (jieba.posseg)\n",
        "  - POS filters: English NOUN tag; Chinese POS prefix 'n' (common noun)\n",
        "  - Proper noun exclusion: English PROPN tag excluded; Chinese 'nr','ns','nt','nz' excluded\n",
        "  - Minimum frequency: MIN_FREQ = 30 (ensures sufficient WSI context)\n",
        "  - Stopwords: NLTK English stopwords; custom Chinese stopword list\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR = Path(\"/content\") / \"bible_data\"\n",
        "MIN_FREQ = 30          # Minimum occurrences per lemma for WSI\n",
        "MAX_CONTEXT_LEN = 512  # Characters — prevents overlong inputs to transformers\n",
        "\n",
        "# Chinese POS tags for common nouns (jieba.posseg notation)\n",
        "ZH_NOUN_PREFIXES = {\"n\"}           # Common noun prefix\n",
        "ZH_EXCLUDE_TAGS  = {\"nr\", \"ns\", \"nt\", \"nz\", \"nw\"}  # Proper nouns to exclude\n",
        "\n",
        "# ── Theological proper noun exclusion lists ───────────────────────────────────\n",
        "# These terms are proper nouns in English (God, Lord, Christ etc.) — excluded\n",
        "# by spaCy's PROPN tag — but are tagged as common nouns n by jieba in Chinese\n",
        "# due to the absence of capitalisation. They must be excluded explicitly from\n",
        "# the Chinese data to ensure cross-lingual comparability.\n",
        "#\n",
        "# English side: spaCy correctly tags God/Lord/Christ as PROPN (excluded).\n",
        "# Exception: \"Spirit\" (Holy Spirit) is sometimes tagged NOUN by spaCy, so it\n",
        "# is added to EN_THEOLOGICAL_EXCLUDE as a lemma-level backstop.\n",
        "#\n",
        "# Borderline cases kept in both languages:\n",
        "#   先知/prophet  — generic occupational noun, polysemous, common in both\n",
        "#   天使/angel    — generic supernatural being, common noun in both\n",
        "#   魔鬼/devil    — common noun in EN; jieba tags n in ZH\n",
        "\n",
        "ZH_THEOLOGICAL_EXCLUDE = {\n",
        "    # Core deity names / titles\n",
        "    \"神\",     # God (most frequent — 1244 occurrences)\n",
        "    \"主\",     # Lord\n",
        "    \"上帝\",   # God (formal)\n",
        "    \"耶和華\", # Yahweh / LORD\n",
        "    \"基督\",   # Christ\n",
        "    \"耶穌\",   # Jesus (also usually tagged nr, but belt-and-suspenders)\n",
        "    \"聖靈\",   # Holy Spirit\n",
        "    \"聖神\",   # Holy Spirit (alternate form in some CUV editions)\n",
        "    \"彌賽亞\", # Messiah\n",
        "    # Adversarial proper nouns\n",
        "    \"撒但\",   # Satan\n",
        "    \"別西卜\", # Beelzebub\n",
        "}\n",
        "\n",
        "EN_THEOLOGICAL_EXCLUDE = {\n",
        "    # Lemma-level backstop for cases where spaCy tags as NOUN not PROPN\n",
        "    \"spirit\",    # \"Holy Spirit\" — spaCy inconsistently tags as NOUN\n",
        "    \"ghost\",     # \"Holy Ghost\" (KJV form; rare in NIV but present)\n",
        "}\n",
        "\n",
        "# Path to custom jieba dictionary for biblical proper names\n",
        "JIEBA_DICT_PATH = Path(\"/content\") / \"bible_data\" / \"jieba_biblical_dict.txt\"\n",
        "\n",
        "# ── Post-segmentation POS correction ─────────────────────────────────────────\n",
        "# jieba's POS tagger runs independently of the segmentation dictionary and\n",
        "# can assign incorrect tags even for dictionary entries. These words are\n",
        "# forced to tag n after segmentation regardless of what the POS tagger assigned.\n",
        "#\n",
        "# 地: jieba assigns uv (虛詞/copular particle) in classical subject-predicate\n",
        "#     constructions like 地是空虛混沌 (Gen.1.2) because it parses 地 as a\n",
        "#     topic marker rather than a subject noun. This is a known jieba limitation\n",
        "#     with literary Chinese. Since English \"earth\" (freq=739) is always tagged\n",
        "#     NOUN by spaCy, forcing 地 to n is required for cross-lingual comparability.\n",
        "ZH_FORCE_NOUN_TAG = {\n",
        "    \"地\",   # earth/ground/land — incorrectly tagged uv in copular constructions\n",
        "}\n",
        "\n",
        "# ─── English Preprocessing ────────────────────────────────────────────────────\n",
        "\n",
        "\n",
        "def preprocess_english(verse_csv: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Process English verses with spaCy.\n",
        "    Returns long-format DataFrame: one row per noun occurrence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import spacy\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Run: pip install spacy --break-system-packages && python -m spacy download en_core_web_sm\")\n",
        "\n",
        "    print(\"  [EN] Loading spaCy model…\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"textcat\"])\n",
        "\n",
        "    df = pd.read_csv(verse_csv)\n",
        "    print(f\"  [EN] Processing {len(df):,} verses…\")\n",
        "\n",
        "    import time\n",
        "    records   = []\n",
        "    texts     = df[\"text\"].tolist()\n",
        "    verse_ids = df[\"verse_id\"].tolist()\n",
        "    total     = len(texts)\n",
        "    t0        = time.time()\n",
        "\n",
        "    for i, (doc, vid) in enumerate(zip(nlp.pipe(texts, batch_size=512), verse_ids), 1):\n",
        "        context = doc.text[:MAX_CONTEXT_LEN]\n",
        "        for token in doc:\n",
        "            # Keep only common nouns; exclude proper nouns and pronouns\n",
        "            if (\n",
        "                token.pos_ == \"NOUN\"\n",
        "                and not token.is_stop\n",
        "                and not token.is_punct\n",
        "                and len(token.lemma_) > 1\n",
        "                and token.lemma_.isalpha()\n",
        "                and token.lemma_.lower() not in EN_THEOLOGICAL_EXCLUDE\n",
        "            ):\n",
        "                records.append({\n",
        "                    \"verse_id\": vid,\n",
        "                    \"token\":    token.text,\n",
        "                    \"lemma\":    token.lemma_.lower(),\n",
        "                    \"context\":  context,\n",
        "                })\n",
        "        if i % 1000 == 0 or i == total:\n",
        "            elapsed = time.time() - t0\n",
        "            rate    = i / elapsed if elapsed > 0 else 0\n",
        "            eta_min = (total - i) / rate / 60 if rate > 0 else 0\n",
        "            print(f\"    … {i:,}/{total:,} verses  \"\n",
        "                  f\"({rate:.0f} v/s)  \"\n",
        "                  f\"ETA {eta_min:.1f} min  \"\n",
        "                  f\"nouns so far: {len(records):,}\",\n",
        "                  end=\"\\r\")\n",
        "\n",
        "    elapsed_total = time.time() - t0\n",
        "    print(f\"\\n  [EN] Done in {elapsed_total/60:.1f} min. \"\n",
        "          f\"Extracted {len(records):,} noun occurrences.\")\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "# ─── Chinese Preprocessing ────────────────────────────────────────────────────\n",
        "\n",
        "\n",
        "def preprocess_chinese(verse_csv: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Process Chinese verses with jieba (word segmentation + POS tagging).\n",
        "    Returns long-format DataFrame: one row per noun occurrence.\n",
        "\n",
        "    Performance notes:\n",
        "    - Uses itertuples() instead of iterrows() — ~10x faster for row iteration\n",
        "    - Progress printed every 1000 verses so you can monitor speed\n",
        "    - jieba is single-threaded by design; no further parallelism available\n",
        "      without multiprocessing (not needed — full Bible processes in ~5 min)\n",
        "\n",
        "    Note: jieba lemma == surface form for Chinese (no inflection).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import jieba\n",
        "        import jieba.posseg as pseg\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Run: pip install jieba --break-system-packages\")\n",
        "\n",
        "    # Load custom dictionary BEFORE any segmentation.\n",
        "    # This ensures biblical proper names (亞伯拉罕, 以色列 etc.) are treated\n",
        "    # as single tokens tagged nr/ns rather than being split into fragments\n",
        "    # that jieba mis-tags as common nouns n.\n",
        "    if JIEBA_DICT_PATH.exists():\n",
        "        jieba.load_userdict(str(JIEBA_DICT_PATH))\n",
        "        print(f\"  [ZH] Loaded biblical proper name dictionary: {JIEBA_DICT_PATH.name}\")\n",
        "    else:\n",
        "        print(f\"  [ZH] WARNING: custom dictionary not found at {JIEBA_DICT_PATH}\")\n",
        "        print(f\"       Proper names may be mis-segmented. Check data/ folder.\")\n",
        "\n",
        "    # Suppress jieba's per-sentence initialisation messages\n",
        "    jieba.setLogLevel(\"ERROR\")\n",
        "\n",
        "    # Load custom stopwords for Chinese\n",
        "    zh_stopwords = _load_chinese_stopwords()\n",
        "\n",
        "    df = pd.read_csv(verse_csv)\n",
        "    total = len(df)\n",
        "    print(f\"  [ZH] Processing {total:,} verses with jieba…\")\n",
        "    import time\n",
        "    t0 = time.time()\n",
        "\n",
        "    records = []\n",
        "    # itertuples() is ~10x faster than iterrows() — avoids per-row Series creation\n",
        "    for i, row in enumerate(df.itertuples(index=False), 1):\n",
        "        verse_id = row.verse_id\n",
        "        text     = str(row.text)\n",
        "        context  = text[:MAX_CONTEXT_LEN]\n",
        "\n",
        "        for word, flag in pseg.cut(text):\n",
        "            flag_str = str(flag)\n",
        "            # ── POS correction for known jieba mistagging in classical CUV ──\n",
        "            # jieba's POS tagger assigns uv (copular particle) to 地 in\n",
        "            # classical subject-predicate constructions (e.g. 地是空虛混沌).\n",
        "            # We force n to match English \"earth\" which spaCy always tags NOUN.\n",
        "            if word in ZH_FORCE_NOUN_TAG:\n",
        "                flag_str = \"n\"\n",
        "            # Accept common nouns only; skip proper nouns and theological terms\n",
        "            if (\n",
        "                flag_str[:1] in ZH_NOUN_PREFIXES\n",
        "                and flag_str not in ZH_EXCLUDE_TAGS\n",
        "                and word not in zh_stopwords\n",
        "                and word not in ZH_THEOLOGICAL_EXCLUDE\n",
        "                and len(word) >= 1\n",
        "                and not word.isdigit()\n",
        "            ):\n",
        "                records.append({\n",
        "                    \"verse_id\": verse_id,\n",
        "                    \"token\":    word,\n",
        "                    \"lemma\":    word,\n",
        "                    \"context\":  context,\n",
        "                })\n",
        "\n",
        "        # Progress every 1000 verses — shows verses/sec so you know it's running\n",
        "        if i % 1000 == 0 or i == total:\n",
        "            elapsed  = time.time() - t0\n",
        "            rate     = i / elapsed if elapsed > 0 else 0\n",
        "            eta_secs = (total - i) / rate if rate > 0 else 0\n",
        "            eta_min  = eta_secs / 60\n",
        "            print(f\"    … {i:,}/{total:,} verses  \"\n",
        "                  f\"({rate:.0f} v/s)  \"\n",
        "                  f\"ETA {eta_min:.1f} min  \"\n",
        "                  f\"nouns so far: {len(records):,}\",\n",
        "                  end=\"\\r\")\n",
        "\n",
        "    elapsed_total = time.time() - t0\n",
        "    print(f\"\\n  [ZH] Done in {elapsed_total/60:.1f} min. \"\n",
        "          f\"Extracted {len(records):,} noun occurrences.\")\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def _load_chinese_stopwords() -> set:\n",
        "    \"\"\"\n",
        "    Chinese function word stoplist for CUV Traditional (CHT) text.\n",
        "\n",
        "    Design decisions:\n",
        "    ─────────────────────────────────────────────────────────────\n",
        "    1. CHT variants included alongside CHS equivalents for all\n",
        "       characters that differ between scripts (說/说, 會/会, etc.)\n",
        "\n",
        "    2. 人 is NOT a stopword. It is a genuine common noun meaning\n",
        "       \"person / people / man / humanity\" and is highly polysemous\n",
        "       in biblical text. Jieba tags it as n (common noun) in most\n",
        "       contexts, so it passes the POS filter correctly. Removing it\n",
        "       would discard one of the most semantically rich words in the\n",
        "       corpus.\n",
        "\n",
        "    3. Pronouns (他/她/祂/你/我 etc.) are NOT listed here. They are\n",
        "       tagged by jieba as r (pronoun), which is already excluded by\n",
        "       the POS filter (we keep only n* tags). Listing them would be\n",
        "       redundant. The various gendered and honorific variants\n",
        "       (他/她/它/祂) all carry the r tag and are excluded uniformly.\n",
        "\n",
        "    4. This list covers only high-frequency grammatical function\n",
        "       words that jieba may occasionally mis-tag as nouns.\n",
        "       It is intentionally conservative.\n",
        "    ─────────────────────────────────────────────────────────────\n",
        "    \"\"\"\n",
        "    return {\n",
        "        # Structural particles (occasionally mis-tagged as n by jieba)\n",
        "        # NOTE: 地 is intentionally NOT listed here.\n",
        "        # In CUV literary style, 地 is overwhelmingly used as a noun\n",
        "        # (earth/land/ground) matching English \"earth\" (freq=739).\n",
        "        # The adverbial particle use of 地 is rare in classical biblical text.\n",
        "        # Removing it would create an asymmetry with English where \"earth\"\n",
        "        # is correctly retained as a high-frequency common noun.\n",
        "        \"的\", \"得\",\n",
        "        # Aspect markers — CHT: 著, CHS: 着\n",
        "        \"了\", \"著\", \"着\",\n",
        "        # Conjunctions / connectives\n",
        "        \"和\", \"與\", \"与\", \"及\", \"或\", \"但\", \"而\", \"且\",\n",
        "        # Adverbs sometimes mis-tagged\n",
        "        \"也\", \"都\", \"就\", \"才\", \"又\", \"還\", \"还\", \"已\",\n",
        "        \"很\", \"更\", \"最\", \"太\", \"非常\",\n",
        "        # Negation\n",
        "        \"不\", \"沒有\", \"没有\", \"未\", \"無\", \"无\",\n",
        "        # Existential / copular\n",
        "        \"是\", \"有\", \"在\",\n",
        "        # Determiners / quantifiers\n",
        "        \"一\", \"這\", \"这\", \"那\", \"各\", \"每\", \"某\", \"其\",\n",
        "        # Directional / locative words with no sense variation\n",
        "        \"上\", \"下\", \"中\", \"內\", \"内\", \"外\", \"前\", \"後\", \"后\",\n",
        "        \"裡\", \"里\", \"間\", \"间\",\n",
        "        # Common verbs jieba occasionally tags as nouns in CUV\n",
        "        \"說\", \"说\", \"看\", \"去\", \"來\", \"来\", \"到\", \"給\", \"给\",\n",
        "        \"要\", \"會\", \"会\",\n",
        "    }\n",
        "\n",
        "\n",
        "# ─── Frequency Filtering ──────────────────────────────────────────────────────\n",
        "\n",
        "\n",
        "def apply_frequency_filter(df: pd.DataFrame, min_freq: int = MIN_FREQ) -> tuple:\n",
        "    \"\"\"\n",
        "    Keep only lemmas appearing at least `min_freq` times.\n",
        "    Returns (filtered_df, freq_df).\n",
        "    \"\"\"\n",
        "    freq = df.groupby(\"lemma\").size().reset_index(name=\"count\")\n",
        "    freq = freq.sort_values(\"count\", ascending=False)\n",
        "    valid_lemmas = set(freq[freq[\"count\"] >= min_freq][\"lemma\"])\n",
        "    filtered = df[df[\"lemma\"].isin(valid_lemmas)].copy()\n",
        "    return filtered, freq\n",
        "\n",
        "\n",
        "# ─── Main ─────────────────────────────────────────────────────────────────────\n",
        "\n",
        "\n",
        "# def main():\n",
        "#     print(\"=\" * 60)\n",
        "#     print(\"Step 2: Preprocessing\")\n",
        "#     print(\"=\" * 60)\n",
        "\n",
        "#     # ── English ──────────────────────────────────────────────────\n",
        "#     en_raw = preprocess_english(DATA_DIR / \"english_verses.csv\")\n",
        "#     en_filtered, en_freq = apply_frequency_filter(en_raw)\n",
        "#     en_filtered.to_csv(DATA_DIR / \"english_nouns.csv\", index=False, encoding=\"utf-8\")\n",
        "#     en_freq.to_csv(DATA_DIR / \"english_noun_freq.csv\", index=False, encoding=\"utf-8\")\n",
        "#     print(f\"  [EN] {en_filtered['lemma'].nunique():,} lemmas ≥ {MIN_FREQ} occurrences retained.\")\n",
        "\n",
        "#     # ── Chinese ───────────────────────────────────────────────────\n",
        "#     zh_raw = preprocess_chinese(DATA_DIR / \"chinese_verses.csv\")\n",
        "#     zh_filtered, zh_freq = apply_frequency_filter(zh_raw)\n",
        "#     zh_filtered.to_csv(DATA_DIR / \"chinese_nouns.csv\", index=False, encoding=\"utf-8\")\n",
        "#     zh_freq.to_csv(DATA_DIR / \"chinese_noun_freq.csv\", index=False, encoding=\"utf-8\")\n",
        "#     print(f\"  [ZH] {zh_filtered['lemma'].nunique():,} lemmas ≥ {MIN_FREQ} occurrences retained.\")\n",
        "\n",
        "#     # ── Summary ───────────────────────────────────────────────────\n",
        "#     print(\"\\n── Preprocessing Summary ──\")\n",
        "#     print(f\"  EN noun tokens (filtered) : {len(en_filtered):,}\")\n",
        "#     print(f\"  EN unique lemmas          : {en_filtered['lemma'].nunique():,}\")\n",
        "#     print(f\"  ZH noun tokens (filtered) : {len(zh_filtered):,}\")\n",
        "#     print(f\"  ZH unique lemmas          : {zh_filtered['lemma'].nunique():,}\")\n",
        "\n",
        "#     print(\"\\n  Top 10 English nouns:\")\n",
        "#     print(en_freq.head(10).to_string(index=False))\n",
        "#     print(\"\\n  Top 10 Chinese nouns:\")\n",
        "#     print(zh_freq.head(10).to_string(index=False))\n",
        "\n",
        "#     print(\"\\n✓ Step 2 complete.\\n\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "id": "iApWnLav0Ltb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Step 2: Preprocessing\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ── English ──────────────────────────────────────────────────\n",
        "en_raw = preprocess_english(DATA_DIR / \"english_verses.csv\")\n",
        "en_filtered, en_freq = apply_frequency_filter(en_raw)\n",
        "en_filtered.to_csv(DATA_DIR / \"english_nouns.csv\", index=False, encoding=\"utf-8\")\n",
        "en_freq.to_csv(DATA_DIR / \"english_noun_freq.csv\", index=False, encoding=\"utf-8\")\n",
        "print(f\"  [EN] {en_filtered['lemma'].nunique():,} lemmas ≥ {MIN_FREQ} occurrences retained.\")\n",
        "\n",
        "# ── Chinese ───────────────────────────────────────────────────\n",
        "zh_raw = preprocess_chinese(DATA_DIR / \"chinese_verses.csv\")\n",
        "zh_filtered, zh_freq = apply_frequency_filter(zh_raw)\n",
        "zh_filtered.to_csv(DATA_DIR / \"chinese_nouns.csv\", index=False, encoding=\"utf-8\")\n",
        "zh_freq.to_csv(DATA_DIR / \"chinese_noun_freq.csv\", index=False, encoding=\"utf-8\")\n",
        "print(f\"  [ZH] {zh_filtered['lemma'].nunique():,} lemmas ≥ {MIN_FREQ} occurrences retained.\")\n",
        "\n",
        "# ── Summary ───────────────────────────────────────────────────\n",
        "print(\"\\n── Preprocessing Summary ──\")\n",
        "print(f\"  EN noun tokens (filtered) : {len(en_filtered):,}\")\n",
        "print(f\"  EN unique lemmas          : {en_filtered['lemma'].nunique():,}\")\n",
        "print(f\"  ZH noun tokens (filtered) : {len(zh_filtered):,}\")\n",
        "print(f\"  ZH unique lemmas          : {zh_filtered['lemma'].nunique():,}\")\n",
        "\n",
        "print(\"\\n  Top 10 English nouns:\")\n",
        "print(en_freq.head(10).to_string(index=False))\n",
        "print(\"\\n  Top 10 Chinese nouns:\")\n",
        "print(zh_freq.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\n✓ Step 2 complete.\\n\")\n"
      ],
      "metadata": {
        "id": "ldNNKu9q0emn",
        "outputId": "be4250b0-f700-434c-92e9-7f971225cbaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Step 2: Preprocessing\n",
            "============================================================\n",
            "  [EN] Loading spaCy model…\n",
            "  [EN] Processing 31,088 verses…\n",
            "    … 31,088/31,088 verses  (538 v/s)  ETA 0.0 min  nouns so far: 116,878\n",
            "  [EN] Done in 1.0 min. Extracted 116,878 noun occurrences.\n",
            "  [EN] 636 lemmas ≥ 30 occurrences retained.\n",
            "  [ZH] Loaded biblical proper name dictionary: jieba_biblical_dict.txt\n",
            "  [ZH] Processing 31,069 verses with jieba…\n",
            "    … 31,069/31,069 verses  (38 v/s)  ETA 0.0 min  nouns so far: 101,261\n",
            "  [ZH] Done in 13.7 min. Extracted 101,261 noun occurrences.\n",
            "  [ZH] 572 lemmas ≥ 30 occurrences retained.\n",
            "\n",
            "── Preprocessing Summary ──\n",
            "  EN noun tokens (filtered) : 98,195\n",
            "  EN unique lemmas          : 636\n",
            "  ZH noun tokens (filtered) : 72,998\n",
            "  ZH unique lemmas          : 572\n",
            "\n",
            "  Top 10 English nouns:\n",
            "   lemma  count\n",
            "     man   3927\n",
            "     son   2929\n",
            "    king   2533\n",
            "  people   2376\n",
            "     day   2037\n",
            "    land   1501\n",
            "    hand   1296\n",
            "  father   1289\n",
            "   house   1054\n",
            "offering   1026\n",
            "\n",
            "  Top 10 Chinese nouns:\n",
            "lemma  count\n",
            "    人   9184\n",
            "   兒子   2356\n",
            "    事   1562\n",
            "    話   1496\n",
            "    地   1373\n",
            "   時候   1339\n",
            "   祭司    855\n",
            "   百姓    827\n",
            "   弟兄    695\n",
            "    城    688\n",
            "\n",
            "✓ Step 2 complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Extract Context Embeddings"
      ],
      "metadata": {
        "id": "1CZa8ZJVWMeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers numpy pandas --break-system-packages"
      ],
      "metadata": {
        "id": "5F743oiHY2rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from typing import List, Tuple\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR    = Path(\"/content\") / \"bible_data\"\n",
        "MODEL_NAME  = \"xlm-roberta-base\"   # Multilingual; same model for EN and ZH\n",
        "BATCH_SIZE  = 32                   # Reduce to 8-16 if OOM on CPU\n",
        "LAYERS      = [-1, -2, -3, -4]     # Last 4 layers averaged (standard WSI practice)\n",
        "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MAX_SEQ_LEN = 128                  # Max subword tokens per sentence\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ─── Model Loading ────────────────────────────────────────────────────────────\n",
        "\n",
        "def load_model():\n",
        "    print(f\"  [model] Loading {MODEL_NAME}…\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model     = AutoModel.from_pretrained(MODEL_NAME, output_hidden_states=True)\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "# ─── Embedding Extraction ─────────────────────────────────────────────────────\n",
        "\n",
        "def get_target_embedding(\n",
        "    tokenizer,\n",
        "    model,\n",
        "    sentences:  List[str],\n",
        "    target_words: List[str],\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    For each (sentence, target_word) pair, extract the contextual embedding\n",
        "    of the target by:\n",
        "      1. Tokenizing the sentence\n",
        "      2. Finding subword token positions for the target word\n",
        "      3. Averaging hidden states across the last 4 layers at those positions\n",
        "      4. Mean-pooling across subwords for multi-token targets\n",
        "\n",
        "    Returns: np.ndarray of shape (N, hidden_dim)\n",
        "    \"\"\"\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in range(0, len(sentences), BATCH_SIZE):\n",
        "        batch_sents  = sentences[i : i + BATCH_SIZE]\n",
        "        batch_targets = target_words[i : i + BATCH_SIZE]\n",
        "\n",
        "        encoded = tokenizer(\n",
        "            batch_sents,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=MAX_SEQ_LEN,\n",
        "            return_offsets_mapping=True,\n",
        "        )\n",
        "        offset_mappings = encoded.pop(\"offset_mapping\")  # not passed to model\n",
        "\n",
        "        encoded = {k: v.to(DEVICE) for k, v in encoded.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encoded)\n",
        "\n",
        "        # Stack selected hidden layers: shape (n_layers, batch, seq_len, hidden)\n",
        "        hidden_states = torch.stack(\n",
        "            [outputs.hidden_states[l] for l in LAYERS], dim=0\n",
        "        )\n",
        "        # Mean over selected layers: (batch, seq_len, hidden)\n",
        "        layer_mean = hidden_states.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        input_ids = encoded[\"input_ids\"].cpu().numpy()\n",
        "\n",
        "        for j, (target, offsets_j) in enumerate(zip(batch_targets, offset_mappings)):\n",
        "            # Re-encode the target word alone to find its subword tokens\n",
        "            target_enc = tokenizer.encode(\n",
        "                target, add_special_tokens=False\n",
        "            )\n",
        "            # Find target subword positions in the sentence encoding\n",
        "            target_positions = _find_subword_positions(\n",
        "                input_ids[j].tolist(), target_enc\n",
        "            )\n",
        "            if target_positions:\n",
        "                token_emb = layer_mean[j][target_positions].mean(axis=0)\n",
        "            else:\n",
        "                # Fallback: mean-pool entire sequence (excluding [CLS]/[SEP])\n",
        "                seq_len = (input_ids[j] != tokenizer.pad_token_id).sum()\n",
        "                token_emb = layer_mean[j][1 : seq_len - 1].mean(axis=0)\n",
        "\n",
        "            all_embeddings.append(token_emb)\n",
        "\n",
        "        if (i // BATCH_SIZE) % 10 == 0:\n",
        "            print(f\"    … batch {i//BATCH_SIZE} / {len(sentences)//BATCH_SIZE}\", end=\"\\r\")\n",
        "\n",
        "    embeddings = np.array(all_embeddings, dtype=np.float32)\n",
        "    # L2 normalize for cosine-based clustering\n",
        "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    norms = np.where(norms == 0, 1, norms)\n",
        "    return embeddings / norms\n",
        "\n",
        "\n",
        "def _find_subword_positions(\n",
        "    sentence_ids: List[int], target_ids: List[int]\n",
        ") -> List[int]:\n",
        "    \"\"\"Find the start position of `target_ids` as a subsequence in `sentence_ids`.\"\"\"\n",
        "    n, m = len(sentence_ids), len(target_ids)\n",
        "    for start in range(n - m + 1):\n",
        "        if sentence_ids[start : start + m] == target_ids:\n",
        "            return list(range(start, start + m))\n",
        "    return []\n",
        "\n",
        "\n",
        "# ─── Per-language Pipeline ────────────────────────────────────────────────────\n",
        "\n",
        "def extract_embeddings_for_language(\n",
        "    lang: str,\n",
        "    noun_csv: Path,\n",
        "    tokenizer,\n",
        "    model,\n",
        ") -> None:\n",
        "    \"\"\"Load nouns, extract embeddings, and save as .npz.\"\"\"\n",
        "    out_path = DATA_DIR / f\"{lang}_embeddings.npz\"\n",
        "    if out_path.exists():\n",
        "        print(f\"  [{lang.upper()}] Embeddings already exist — skipping.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(noun_csv)\n",
        "    print(f\"  [{lang.upper()}] Extracting embeddings for {len(df):,} noun occurrences…\")\n",
        "\n",
        "    embeddings = get_target_embedding(\n",
        "        tokenizer,\n",
        "        model,\n",
        "        sentences    = df[\"context\"].tolist(),\n",
        "        target_words = df[\"token\"].tolist(),\n",
        "    )\n",
        "    print()  # newline after progress indicator\n",
        "\n",
        "    np.savez_compressed(\n",
        "        out_path,\n",
        "        embeddings = embeddings,\n",
        "        lemmas     = df[\"lemma\"].to_numpy(dtype=str),\n",
        "        verse_ids  = df[\"verse_id\"].to_numpy(dtype=str),\n",
        "        tokens     = df[\"token\"].to_numpy(dtype=str),\n",
        "    )\n",
        "    print(f\"  [{lang.upper()}] Saved {embeddings.shape} embeddings → {out_path.name}\")\n",
        "\n",
        "\n",
        "# ─── Main ─────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# def main():\n",
        "#     print(\"=\" * 60)\n",
        "#     print(\"Step 3: Contextual Embedding Extraction (XLM-R)\")\n",
        "#     print(\"=\" * 60)\n",
        "\n",
        "#     tokenizer, model = load_model()\n",
        "\n",
        "#     extract_embeddings_for_language(\n",
        "#         \"english\",\n",
        "#         DATA_DIR / \"english_nouns.csv\",\n",
        "#         tokenizer, model,\n",
        "#     )\n",
        "#     extract_embeddings_for_language(\n",
        "#         \"chinese\",\n",
        "#         DATA_DIR / \"chinese_nouns.csv\",\n",
        "#         tokenizer, model,\n",
        "#     )\n",
        "\n",
        "#     print(\"\\n✓ Step 3 complete.\\n\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJF9kXsnWQDa",
        "outputId": "6af6fa8c-a0c7-4d2d-f307-8a886901f4f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Step 3: Contextual Embedding Extraction (XLM-R)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "extract_embeddings_for_language(\n",
        "    \"english\",\n",
        "    DATA_DIR / \"english_nouns.csv\",\n",
        "    tokenizer, model,\n",
        ")\n",
        "extract_embeddings_for_language(\n",
        "    \"chinese\",\n",
        "    DATA_DIR / \"chinese_nouns.csv\",\n",
        "    tokenizer, model,\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Step 3 complete.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801,
          "referenced_widgets": [
            "ac371f37d9b840d1924bc823a249ead4",
            "fb0cddb42e91497fbbf70480c88d1182",
            "3f28f2652756453da13e4c648201c330",
            "4dd05c92334e4055bff644915c111568",
            "5310e8aa0d5b4eeba1afc20c35233770",
            "3ac4180627c6440f8b76d4c8194704fe",
            "c038bdd2ca2a46bcbc5534f6da50970e",
            "eb7d23718b9547a88a4c4f6d7d82c717",
            "47b24e9be3d14f57bfce29d9b26d3f57",
            "a9ee7bc5c4ff47449b9f1d5f214afd88",
            "7ed83647f4a04949a5a5b9deb8bd2f89",
            "f74d4e59974442459f74a05485b43448",
            "c3f99ebba16e43c6a6263a611c741c2a",
            "8f273586172042a89b4df85c955f805d",
            "41341ca9ffed440e8135a8ab4747c5e2",
            "d12d4e49405644409cbe6dcc287212dc",
            "71b1186bbbff491eacd8e442888749f4",
            "dc5c14eb3748412391df94fd1cee4f7e",
            "5dd1883933524aa19c50beeaa676f702",
            "0055d36104984ade9514c499e7385790",
            "de291430c3c943189ece730a89988fb7",
            "ddf709e96cd3400da2ae83530e125da2",
            "9810101220cb466088b6f70b8cc6ee5c",
            "c17110793b2d4057a3ce9b8698a26ae8",
            "76735abe71fc4361bb867f85c478859c",
            "4092888895404747aef972e9cbb44b21",
            "71fc157f24904fe7a819d5139adb596c",
            "c21d77a9efa54d33a64ae1d93ff1097f",
            "6d30e54564eb4f93bb5782b62beb0081",
            "04c0474f83f045aca030bfd5841cd558",
            "454e7b84784943acab6cbfeae3830519",
            "d4de2075584e4eca929912043473b969",
            "8e9b280c336c492e8ceaa2ce245c28a9",
            "bd42cbed9787407cbf12a084ef52b06c",
            "59dd73e74b9443bd81c9ac057a9af18a",
            "ccb799fa8a704dbc817a2f3bc2467182",
            "0a47b4b5890948ad9aa7955d7ade2158",
            "3e802067235a4ecc84516aefc74bc0b3",
            "6d596d8e38884cd19cefb764197656bb",
            "06c7fd2535d64212be48261fbca59a75",
            "87a6e7d4177e429fa1370f1ad1125b59",
            "5f8053c0df924dedbfb5214eff3a94fa",
            "c9f956d0b1904de0aa2425fcf532863f",
            "7bc1bbe56106462c879a48b74347c89c",
            "991e09c7a16f40dc8d6350a3ed3130c5",
            "9534d0df168d4fa0af9c13bba9b4e45f",
            "0887a6a2f412445ea5b5d5cbd09f303a",
            "98167c4ed60e4321ab7fd6c6c50c42e1",
            "5e898caf252746b496f927873d18188e",
            "93ceee7ee20a43d1949b5023f0184429",
            "68fa328d48dc4f2d94b9770711a513d2",
            "bac691932efd44aa93130fe9dd9236c6",
            "09255333bab24257871d9617667ad411",
            "081cb87b8bd64fb4b4bf4ae2f1a8fc72",
            "5af76fdeea8f4e1b93f3c703a37ca8d4",
            "06d1864672a74d158d344584d7f39aed",
            "b3c2b71df0564b7180ee48bbe28f3fcc",
            "ff3404353f8048ccae8e6e1401ce7267",
            "5cbcbbd27ee74a4a9a9be944815f2379",
            "718b1119bf05474d8f14dfc04eef8339",
            "537937162fd74bb389b309ae666f06fd",
            "a7d6f65d19fd4010aaff346135ba6bba",
            "ad51513bd1434d6ba1c0af502f4c3cb3",
            "783d4606b814485caa028c1080a224b0",
            "1dccba0fa4004754aa8c17763799b169",
            "b26ccbc2770f456685a356b19850f0ed"
          ]
        },
        "id": "ZwpfEQinX-ri",
        "outputId": "ea9838d4-7950-42ac-eb07-37b2635e9eb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Step 3: Contextual Embedding Extraction (XLM-R)\n",
            "============================================================\n",
            "  [model] Loading xlm-roberta-base…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac371f37d9b840d1924bc823a249ead4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f74d4e59974442459f74a05485b43448"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9810101220cb466088b6f70b8cc6ee5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd42cbed9787407cbf12a084ef52b06c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "991e09c7a16f40dc8d6350a3ed3130c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06d1864672a74d158d344584d7f39aed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "XLMRobertaModel LOAD REPORT from: xlm-roberta-base\n",
            "Key                       | Status     |  | \n",
            "--------------------------+------------+--+-\n",
            "lm_head.dense.bias        | UNEXPECTED |  | \n",
            "lm_head.dense.weight      | UNEXPECTED |  | \n",
            "lm_head.layer_norm.bias   | UNEXPECTED |  | \n",
            "lm_head.layer_norm.weight | UNEXPECTED |  | \n",
            "lm_head.bias              | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [ENGLISH] Extracting embeddings for 98,195 noun occurrences…\n",
            "\n",
            "  [ENGLISH] Saved (98195, 768) embeddings → english_embeddings.npz\n",
            "  [CHINESE] Extracting embeddings for 72,998 noun occurrences…\n",
            "\n",
            "  [CHINESE] Saved (72998, 768) embeddings → chinese_embeddings.npz\n",
            "\n",
            "✓ Step 3 complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: WSI Clustering"
      ],
      "metadata": {
        "id": "meHGlTr8aErA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn numpy pandas --break-system-packages"
      ],
      "metadata": {
        "id": "8Igdh2ErazoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 4: Word Sense Induction (WSI) via Agglomerative Clustering\n",
        "================================================================\n",
        "For each lemma in each language, clusters its contextual embeddings\n",
        "to induce word senses. The number of clusters k is determined\n",
        "automatically using the Silhouette Score (range 2–8) or set to 1\n",
        "if the word shows insufficient sense variation.\n",
        "\n",
        "Two clustering algorithms are run for robustness comparison:\n",
        "  (A) Agglomerative Hierarchical Clustering (Ward linkage)    — primary\n",
        "  (B) K-Means with k++ initialization                         — secondary\n",
        "\n",
        "Outputs:\n",
        "  - data/english_wsi_results.csv  : lemma, k_ward, k_kmeans, silhouette_ward, ...\n",
        "  - data/chinese_wsi_results.csv  : same\n",
        "  - data/english_sense_labels.csv : lemma, verse_id, cluster_ward, cluster_kmeans\n",
        "  - data/chinese_sense_labels.csv : same\n",
        "\n",
        "Usage:\n",
        "  pip install scikit-learn numpy pandas --break-system-packages\n",
        "  python 04_wsi_clustering.py\n",
        "\n",
        "Design decisions (paper §3.3):\n",
        "  - Ward linkage is preferred for lexical WSI (Ustalov et al. 2019)\n",
        "  - k range: 1–8 senses; beyond 8 is linguistically implausible for\n",
        "    the narrow domain of biblical text\n",
        "  - Silhouette threshold: if best_silhouette < SILHOUETTE_THRESHOLD,\n",
        "    k is set to 1 (monosemous)\n",
        "  - UMAP dimensionality reduction to 50D before clustering improves\n",
        "    silhouette stability (McInnes et al. 2018)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import normalize\n",
        "from typing import Tuple, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR    = Path(\"/content\") / \"bible_data\"\n",
        "# DATA_DIR             = Path(__file__).parent.parent / \"data\"\n",
        "K_RANGE              = range(2, 9)           # Test k = 2, 3, …, 8\n",
        "SILHOUETTE_THRESHOLD = 0.05                  # Below this → monosemous (k=1)\n",
        "MIN_INSTANCES        = 5                     # Min occurrences to attempt clustering\n",
        "USE_UMAP             = True                  # Reduce to 50D before clustering\n",
        "UMAP_N_COMPONENTS    = 50\n",
        "RANDOM_STATE         = 42\n",
        "\n",
        "\n",
        "# ─── Optional UMAP reduction ─────────────────────────────────────────────────\n",
        "\n",
        "def reduce_embeddings(embeddings: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Optionally reduce embedding dimensionality with UMAP before clustering.\n",
        "    UMAP (McInnes et al. 2018) improves cluster separation for high-dim data.\n",
        "    Falls back to PCA if umap-learn is not installed or if UMAP fails.\n",
        "    \"\"\"\n",
        "    if not USE_UMAP or embeddings.shape[0] <= MIN_INSTANCES: # Added <= MIN_INSTANCES for robustness\n",
        "        return embeddings\n",
        "\n",
        "    try:\n",
        "        import umap\n",
        "        # Ensure n_components is always less than the number of samples\n",
        "        n_components_umap = min(UMAP_N_COMPONENTS, embeddings.shape[0] - 1)\n",
        "        if n_components_umap <= 0: # Handle cases where n_samples is 1\n",
        "            return embeddings\n",
        "\n",
        "        reducer = umap.UMAP(\n",
        "            n_components=n_components_umap,\n",
        "            metric=\"cosine\",\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=1,\n",
        "        )\n",
        "        return reducer.fit_transform(embeddings)\n",
        "    except (ImportError, TypeError) as e: # Catch both ImportError and TypeError\n",
        "        if isinstance(e, ImportError):\n",
        "            print(\"    [warn] umap-learn not found — using PCA fallback. \"\n",
        "                  \"Install: pip install umap-learn --break-system-packages\")\n",
        "        else:\n",
        "            print(f\"    [warn] UMAP failed ({e}) — using PCA fallback for this lemma. \"\n",
        "                  f\"Embeddings shape: {embeddings.shape}\")\n",
        "        from sklearn.decomposition import PCA\n",
        "        # Ensure n_components for PCA is also less than number of samples and features\n",
        "        n_components_pca = min(UMAP_N_COMPONENTS, embeddings.shape[0] - 1, embeddings.shape[1])\n",
        "        if n_components_pca <= 0: # Handle cases where n_samples is 1\n",
        "            return embeddings\n",
        "        return PCA(n_components=n_components_pca, random_state=RANDOM_STATE).fit_transform(embeddings)\n",
        "\n",
        "\n",
        "# ─── Core WSI for a single lemma ─────────────────────────────────────────────\n",
        "\n",
        "def induce_senses_for_lemma(\n",
        "    embeddings: np.ndarray,\n",
        ") -> Tuple[int, int, float, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Given embeddings for all occurrences of a lemma, find the optimal k\n",
        "    using silhouette score for both Ward and KMeans clustering.\n",
        "\n",
        "    Returns:\n",
        "        k_ward, k_kmeans, best_silhouette_ward,\n",
        "        labels_ward (np.ndarray), labels_kmeans (np.ndarray)\n",
        "    \"\"\"\n",
        "    n = len(embeddings)\n",
        "\n",
        "    # Insufficient data → monosemous\n",
        "    if n < MIN_INSTANCES:\n",
        "        ones = np.zeros(n, dtype=int)\n",
        "        return 1, 1, 0.0, ones, ones\n",
        "\n",
        "    reduced = reduce_embeddings(embeddings)\n",
        "\n",
        "    best_k_ward, best_sil_ward, best_labels_ward   = 1, -1.0, np.zeros(n, dtype=int)\n",
        "    best_k_km,   best_sil_km,   best_labels_km     = 1, -1.0, np.zeros(n, dtype=int)\n",
        "\n",
        "    for k in K_RANGE:\n",
        "        if k >= n:\n",
        "            break  # Can't have more clusters than data points\n",
        "\n",
        "        # Ward agglomerative\n",
        "        try:\n",
        "            ward = AgglomerativeClustering(n_clusters=k, linkage=\"ward\")\n",
        "            labels_w = ward.fit_predict(reduced)\n",
        "            if len(np.unique(labels_w)) > 1:\n",
        "                sil_w = silhouette_score(reduced, labels_w, metric=\"euclidean\",\n",
        "                                         sample_size=min(1000, n))\n",
        "                if sil_w > best_sil_ward:\n",
        "                    best_sil_ward, best_k_ward, best_labels_ward = sil_w, k, labels_w\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # K-Means\n",
        "        try:\n",
        "            km = KMeans(n_clusters=k, random_state=RANDOM_STATE,\n",
        "                        n_init=10, max_iter=300)\n",
        "            labels_k = km.fit_predict(reduced)\n",
        "            if len(np.unique(labels_k)) > 1:\n",
        "                sil_k = silhouette_score(reduced, labels_k, metric=\"euclidean\",\n",
        "                                          sample_size=min(1000, n))\n",
        "                if sil_k > best_sil_km:\n",
        "                    best_sil_km, best_k_km, best_labels_km = sil_k, k, labels_k\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Apply monosemy threshold\n",
        "    if best_sil_ward < SILHOUETTE_THRESHOLD:\n",
        "        best_k_ward    = 1\n",
        "        best_labels_ward = np.zeros(n, dtype=int)\n",
        "\n",
        "    if best_sil_km < SILHOUETTE_THRESHOLD:\n",
        "        best_k_km    = 1\n",
        "        best_labels_km = np.zeros(n, dtype=int)\n",
        "\n",
        "    return (best_k_ward, best_k_km, max(best_sil_ward, 0.0),\n",
        "            best_labels_ward, best_labels_km)\n",
        "\n",
        "\n",
        "# ─── Per-language WSI Pipeline ───────────────────────────────────────────────\n",
        "\n",
        "def run_wsi_for_language(lang: str) -> None:\n",
        "    \"\"\"Load embeddings, run WSI for every lemma, save results.\"\"\"\n",
        "    emb_path     = DATA_DIR / f\"{lang}_embeddings.npz\"\n",
        "    result_path  = DATA_DIR / f\"{lang}_wsi_results.csv\"\n",
        "    labels_path  = DATA_DIR / f\"{lang}_sense_labels.csv\"\n",
        "\n",
        "    if result_path.exists():\n",
        "        print(f\"  [{lang.upper()}] WSI results already exist — skipping.\")\n",
        "        return\n",
        "\n",
        "    print(f\"  [{lang.upper()}] Loading embeddings…\")\n",
        "    data      = np.load(emb_path, allow_pickle=True)\n",
        "    embs      = data[\"embeddings\"].astype(np.float32)\n",
        "    lemmas    = data[\"lemmas\"].astype(str)\n",
        "    verse_ids = data[\"verse_ids\"].astype(str)\n",
        "    tokens    = data[\"tokens\"].astype(str)\n",
        "\n",
        "    unique_lemmas = np.unique(lemmas)\n",
        "    print(f\"  [{lang.upper()}] Running WSI for {len(unique_lemmas):,} lemmas…\")\n",
        "\n",
        "    summary_rows = []\n",
        "    label_rows   = []\n",
        "\n",
        "    for i, lemma in enumerate(unique_lemmas):\n",
        "        mask      = lemmas == lemma\n",
        "        lemma_emb = embs[mask]\n",
        "        n         = len(lemma_emb)\n",
        "\n",
        "        k_ward, k_km, sil_ward, lbl_ward, lbl_km = induce_senses_for_lemma(lemma_emb)\n",
        "\n",
        "        summary_rows.append({\n",
        "            \"lemma\":            lemma,\n",
        "            \"n_occurrences\":    n,\n",
        "            \"k_ward\":           k_ward,\n",
        "            \"k_kmeans\":         k_km,\n",
        "            \"silhouette_ward\":  round(sil_ward, 4),\n",
        "            \"polysemous_ward\":  int(k_ward > 1),\n",
        "            \"polysemous_kmeans\":int(k_km   > 1),\n",
        "        })\n",
        "\n",
        "        # Save per-occurrence sense labels\n",
        "        vid_subset = verse_ids[mask]\n",
        "        tok_subset = tokens[mask]\n",
        "        for j in range(n):\n",
        "            label_rows.append({\n",
        "                \"lemma\":        lemma,\n",
        "                \"verse_id\":     vid_subset[j],\n",
        "                \"token\":        tok_subset[j],\n",
        "                \"cluster_ward\": lbl_ward[j],\n",
        "                \"cluster_kmeans\": lbl_km[j],\n",
        "            })\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"    … {i:,}/{len(unique_lemmas):,} lemmas processed\", end=\"\\r\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    results_df = pd.DataFrame(summary_rows)\n",
        "    labels_df  = pd.DataFrame(label_rows)\n",
        "\n",
        "    results_df.to_csv(result_path, index=False, encoding=\"utf-8\")\n",
        "    labels_df.to_csv(labels_path,  index=False, encoding=\"utf-8\")\n",
        "\n",
        "    n_poly = (results_df[\"k_ward\"] > 1).sum()\n",
        "    mean_k = results_df[\"k_ward\"].mean()\n",
        "    print(f\"  [{lang.upper()}] Done. Mean k_ward={mean_k:.3f} | Polysemous lemmas: {n_poly}/{len(unique_lemmas)}\")\n",
        "\n",
        "\n",
        "# ─── Main ─────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# def main():\n",
        "#     print(\"=\" * 60)\n",
        "#     print(\"Step 4: Word Sense Induction (WSI)\")\n",
        "#     print(\"=\" * 60)\n",
        "\n",
        "#     run_wsi_for_language(\"english\")\n",
        "#     run_wsi_for_language(\"chinese\")\n",
        "\n",
        "#     # Quick comparison preview\n",
        "#     en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "#     zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "#     print(\"\\n── Quick Comparison Preview ──\")\n",
        "#     print(f\"  EN | mean senses/lemma (Ward) : {en['k_ward'].mean():.3f}\")\n",
        "#     print(f\"  ZH | mean senses/lemma (Ward) : {zh['k_ward'].mean():.3f}\")\n",
        "#     print(f\"  EN | % polysemous lemmas       : {(en['k_ward'] > 1).mean()*100:.1f}%\")\n",
        "#     print(f\"  ZH | % polysemous lemmas       : {(zh['k_ward'] > 1).mean()*100:.1f}%\")\n",
        "\n",
        "#     print(\"\\n✓ Step 4 complete.\\n\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "id": "wCI4OOXjYSNs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Step 4: Word Sense Induction (WSI)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "run_wsi_for_language(\"english\")\n",
        "run_wsi_for_language(\"chinese\")\n",
        "\n",
        "# Quick comparison preview\n",
        "en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "print(\"\\n── Quick Comparison Preview ──\")\n",
        "print(f\"  EN | mean senses/lemma (Ward) : {en['k_ward'].mean():.3f}\")\n",
        "print(f\"  ZH | mean senses/lemma (Ward) : {zh['k_ward'].mean():.3f}\")\n",
        "print(f\"  EN | % polysemous lemmas       : {(en['k_ward'] > 1).mean()*100:.1f}%\")\n",
        "print(f\"  ZH | % polysemous lemmas       : {(zh['k_ward'] > 1).mean()*100:.1f}%\")\n",
        "\n",
        "print(\"\\n✓ Step 4 complete.\\n\")"
      ],
      "metadata": {
        "id": "qUNKMUx1aRI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Validation and Statistical Analysis"
      ],
      "metadata": {
        "id": "lX7M7-Toc3Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk scipy matplotlib seaborn pandas numpy --break-system-packages"
      ],
      "metadata": {
        "id": "BvfDY1GpdndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "yu113JDddzl4",
        "outputId": "5ac788a6-7086-4627-a2a2-9d7bb72ca899",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 5: Validation and Statistical Analysis\n",
        "============================================\n",
        "Validates WSI-induced sense counts against gold-standard lexical resources:\n",
        "  - English: Princeton WordNet (via NLTK)\n",
        "  - Chinese:  Chinese WordNet (via Taiwanese CWN or HowNet)\n",
        "\n",
        "Also performs the core statistical comparison between languages:\n",
        "  - Mann-Whitney U test (non-parametric, appropriate for skewed count data)\n",
        "  - Cohen's d effect size\n",
        "  - Spearman correlation with WordNet sense counts (validation)\n",
        "  - Distribution plots (saved as PNG for inclusion in paper)\n",
        "\n",
        "Outputs:\n",
        "  - output/validation_correlation_en.csv\n",
        "  - output/validation_correlation_zh.csv   (if CWN available)\n",
        "  - output/statistical_comparison.csv\n",
        "  - output/figures/sense_distribution_en.png\n",
        "  - output/figures/sense_distribution_zh.png\n",
        "  - output/figures/comparison_boxplot.png\n",
        "  - output/figures/wordnet_correlation_en.png\n",
        "\n",
        "Usage:\n",
        "  pip install nltk scipy matplotlib seaborn pandas numpy --break-system-packages\n",
        "  python -c \"import nltk; nltk.download('wordnet')\"\n",
        "  python 05_validation_statistics.py\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from scipy import stats\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR    = Path(\"/content\") / \"bible_data\"\n",
        "OUTPUT_DIR = Path(\"/content\") / \"output\"\n",
        "# DATA_DIR   = Path(__file__).parent.parent / \"data\"\n",
        "# OUTPUT_DIR = Path(__file__).parent.parent / \"output\"\n",
        "FIG_DIR    = OUTPUT_DIR / \"figures\"\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "FIG_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"font.family\":  \"DejaVu Sans\",\n",
        "    \"font.size\":    11,\n",
        "    \"axes.titlesize\": 13,\n",
        "    \"axes.labelsize\": 12,\n",
        "})\n",
        "\n",
        "\n",
        "# ─── WordNet Validation (English) ────────────────────────────────────────────\n",
        "\n",
        "def get_wordnet_sense_counts(lemmas: list) -> dict:\n",
        "    \"\"\"\n",
        "    Look up the number of synsets for each lemma in Princeton WordNet.\n",
        "    Noun synsets only (pos='n').\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from nltk.corpus import wordnet as wn\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Run: pip install nltk --break-system-packages && \"\n",
        "                          \"python -c \\\"import nltk; nltk.download('wordnet')\\\"\")\n",
        "\n",
        "    counts = {}\n",
        "    for lemma in lemmas:\n",
        "        synsets = wn.synsets(lemma.lower(), pos=wn.NOUN)\n",
        "        counts[lemma] = len(synsets)\n",
        "    return counts\n",
        "\n",
        "\n",
        "def validate_english(en_results: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Correlate WSI-induced k_ward with WordNet sense counts for English nouns.\n",
        "    Returns a merged DataFrame with both counts.\n",
        "    \"\"\"\n",
        "    print(\"  [validate] Looking up Princeton WordNet sense counts…\")\n",
        "    lemmas = en_results[\"lemma\"].tolist()\n",
        "    wn_counts = get_wordnet_sense_counts(lemmas)\n",
        "\n",
        "    en_results = en_results.copy()\n",
        "    en_results[\"wn_senses\"] = en_results[\"lemma\"].map(wn_counts).fillna(0).astype(int)\n",
        "\n",
        "    # Keep only lemmas with at least 1 WordNet entry\n",
        "    valid = en_results[en_results[\"wn_senses\"] > 0].copy()\n",
        "\n",
        "    rho, p = stats.spearmanr(valid[\"k_ward\"], valid[\"wn_senses\"])\n",
        "    print(f\"  [validate] EN Spearman ρ(k_ward, WN_senses) = {rho:.3f}  p = {p:.4f}  \"\n",
        "          f\"(n={len(valid)})\")\n",
        "\n",
        "    return valid, rho, p\n",
        "\n",
        "\n",
        "# ─── Statistical Comparison ──────────────────────────────────────────────────\n",
        "\n",
        "def mann_whitney_comparison(\n",
        "    en_k: np.ndarray,\n",
        "    zh_k: np.ndarray,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Mann-Whitney U test comparing mean sense counts between EN and ZH.\n",
        "    Also computes Cohen's d and the common language effect size (CLES).\n",
        "    \"\"\"\n",
        "    u_stat, p_val = stats.mannwhitneyu(en_k, zh_k, alternative=\"two-sided\")\n",
        "    n1, n2        = len(en_k), len(zh_k)\n",
        "    cles          = u_stat / (n1 * n2)  # Common Language Effect Size\n",
        "\n",
        "    # Cohen's d (for reference alongside CLES)\n",
        "    pooled_std = np.sqrt(\n",
        "        ((n1 - 1) * en_k.std(ddof=1) ** 2 + (n2 - 1) * zh_k.std(ddof=1) ** 2)\n",
        "        / (n1 + n2 - 2)\n",
        "    )\n",
        "    cohens_d = (en_k.mean() - zh_k.mean()) / (pooled_std + 1e-9)\n",
        "\n",
        "    return {\n",
        "        \"en_mean_k\":   round(en_k.mean(), 4),\n",
        "        \"zh_mean_k\":   round(zh_k.mean(), 4),\n",
        "        \"en_median_k\": round(float(np.median(en_k)), 4),\n",
        "        \"zh_median_k\": round(float(np.median(zh_k)), 4),\n",
        "        \"en_std_k\":    round(en_k.std(ddof=1), 4),\n",
        "        \"zh_std_k\":    round(zh_k.std(ddof=1), 4),\n",
        "        \"U_statistic\": round(u_stat, 2),\n",
        "        \"p_value\":     round(p_val, 6),\n",
        "        \"CLES\":        round(cles, 4),\n",
        "        \"cohens_d\":    round(cohens_d, 4),\n",
        "        \"n_en\":        int(n1),\n",
        "        \"n_zh\":        int(n2),\n",
        "    }\n",
        "\n",
        "\n",
        "# ─── Figures ─────────────────────────────────────────────────────────────────\n",
        "\n",
        "def plot_sense_distribution(df: pd.DataFrame, lang: str, col: str = \"k_ward\") -> None:\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    counts = df[col].value_counts().sort_index()\n",
        "    ax.bar(counts.index, counts.values, color=\"#4C72B0\", edgecolor=\"white\", linewidth=0.5)\n",
        "    ax.set_xlabel(\"Number of Induced Senses (k)\")\n",
        "    ax.set_ylabel(\"Number of Lemmas\")\n",
        "    ax.set_title(f\"{lang.capitalize()} — Distribution of Induced Senses per Noun Lemma\")\n",
        "    ax.set_xticks(range(1, df[col].max() + 1))\n",
        "    fig.tight_layout()\n",
        "    path = FIG_DIR / f\"sense_distribution_{lang}.png\"\n",
        "    fig.savefig(path, dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(f\"  [fig] Saved: {path.name}\")\n",
        "\n",
        "\n",
        "def plot_comparison_boxplot(en_df: pd.DataFrame, zh_df: pd.DataFrame) -> None:\n",
        "    combined = pd.concat([\n",
        "        en_df[[\"k_ward\"]].assign(Language=\"English\"),\n",
        "        zh_df[[\"k_ward\"]].assign(Language=\"Chinese\"),\n",
        "    ])\n",
        "    fig, ax = plt.subplots(figsize=(7, 5))\n",
        "    sns.violinplot(data=combined, x=\"Language\", y=\"k_ward\",\n",
        "                   palette=[\"#4C72B0\", \"#DD8452\"], inner=\"box\", ax=ax)\n",
        "    ax.set_ylabel(\"Induced Senses per Lemma (k, Ward)\")\n",
        "    ax.set_title(\"Distribution of Polysemy Degree: English vs. Chinese Common Nouns\\n\"\n",
        "                 \"(Bible Parallel Corpus, WSI via XLM-R + Agglomerative Clustering)\")\n",
        "    fig.tight_layout()\n",
        "    path = FIG_DIR / \"comparison_violinplot.png\"\n",
        "    fig.savefig(path, dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(f\"  [fig] Saved: {path.name}\")\n",
        "\n",
        "\n",
        "def plot_wordnet_correlation(valid_df: pd.DataFrame, rho: float, p: float) -> None:\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    ax.scatter(valid_df[\"wn_senses\"], valid_df[\"k_ward\"],\n",
        "               alpha=0.4, s=20, color=\"#4C72B0\")\n",
        "    ax.set_xlabel(\"WordNet Noun Synset Count\")\n",
        "    ax.set_ylabel(\"WSI-Induced k (Ward)\")\n",
        "    ax.set_title(f\"Validation: WSI k vs. WordNet Senses (English Nouns)\\n\"\n",
        "                 f\"Spearman ρ = {rho:.3f}, p = {p:.4f}\")\n",
        "    # Trend line\n",
        "    m, b = np.polyfit(valid_df[\"wn_senses\"], valid_df[\"k_ward\"], 1)\n",
        "    x_line = np.linspace(valid_df[\"wn_senses\"].min(), valid_df[\"wn_senses\"].max(), 100)\n",
        "    ax.plot(x_line, m * x_line + b, color=\"red\", linewidth=1.5, linestyle=\"--\")\n",
        "    fig.tight_layout()\n",
        "    path = FIG_DIR / \"wordnet_correlation_en.png\"\n",
        "    fig.savefig(path, dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(f\"  [fig] Saved: {path.name}\")\n",
        "\n",
        "\n",
        "# ─── Main ─────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# def main():\n",
        "#     print(\"=\" * 60)\n",
        "#     print(\"Step 5: Validation and Statistical Analysis\")\n",
        "#     print(\"=\" * 60)\n",
        "\n",
        "#     en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "#     zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "#     # ── Validation (English vs. WordNet) ──────────────────────────\n",
        "#     valid_en, rho, p = validate_english(en)\n",
        "#     valid_en.to_csv(OUTPUT_DIR / \"validation_correlation_en.csv\", index=False)\n",
        "\n",
        "#     # ── Statistical Comparison ────────────────────────────────────\n",
        "#     stats_result = mann_whitney_comparison(\n",
        "#         en[\"k_ward\"].values,\n",
        "#         zh[\"k_ward\"].values,\n",
        "#     )\n",
        "#     stats_df = pd.DataFrame([stats_result])\n",
        "#     stats_df.to_csv(OUTPUT_DIR / \"statistical_comparison.csv\", index=False)\n",
        "\n",
        "#     print(\"\\n── Statistical Comparison Results ──\")\n",
        "#     for k, v in stats_result.items():\n",
        "#         print(f\"  {k:22s}: {v}\")\n",
        "\n",
        "#     # ── Figures ───────────────────────────────────────────────────\n",
        "#     plot_sense_distribution(en, \"english\")\n",
        "#     plot_sense_distribution(zh, \"chinese\")\n",
        "#     plot_comparison_boxplot(en, zh)\n",
        "#     plot_wordnet_correlation(valid_en, rho, p)\n",
        "\n",
        "#     # ── Interpretation ────────────────────────────────────────────\n",
        "#     print(\"\\n── Interpretation ──\")\n",
        "#     if stats_result[\"p_value\"] < 0.05:\n",
        "#         direction = \"English\" if stats_result[\"en_mean_k\"] > stats_result[\"zh_mean_k\"] else \"Chinese\"\n",
        "#         print(f\"  Significant difference found (p={stats_result['p_value']:.4f}).\")\n",
        "#         print(f\"  {direction} nouns show higher mean polysemy degree.\")\n",
        "#     else:\n",
        "#         print(f\"  No significant difference found (p={stats_result['p_value']:.4f}).\")\n",
        "\n",
        "#     d = abs(stats_result[\"cohens_d\"])\n",
        "#     magnitude = \"small\" if d < 0.2 else (\"medium\" if d < 0.5 else \"large\")\n",
        "#     print(f\"  Effect size: Cohen's d = {stats_result['cohens_d']:.3f} ({magnitude})\")\n",
        "#     print(f\"  Spearman ρ (EN WSI vs. WordNet): {rho:.3f} (p={p:.4f})\")\n",
        "\n",
        "#     print(\"\\n✓ Step 5 complete.\\n\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "id": "A2wqaZynajnY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Step 5: Validation and Statistical Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "# ── Validation (English vs. WordNet) ──────────────────────────\n",
        "valid_en, rho, p = validate_english(en)\n",
        "valid_en.to_csv(OUTPUT_DIR / \"validation_correlation_en.csv\", index=False)\n",
        "\n",
        "# ── Statistical Comparison ────────────────────────────────────\n",
        "stats_result = mann_whitney_comparison(\n",
        "    en[\"k_ward\"].values,\n",
        "    zh[\"k_ward\"].values,\n",
        ")\n",
        "stats_df = pd.DataFrame([stats_result])\n",
        "stats_df.to_csv(OUTPUT_DIR / \"statistical_comparison.csv\", index=False)\n",
        "\n",
        "print(\"\\n── Statistical Comparison Results ──\")\n",
        "for k, v in stats_result.items():\n",
        "    print(f\"  {k:22s}: {v}\")\n",
        "\n",
        "# ── Figures ───────────────────────────────────────────────────\n",
        "plot_sense_distribution(en, \"english\")\n",
        "plot_sense_distribution(zh, \"chinese\")\n",
        "plot_comparison_boxplot(en, zh)\n",
        "plot_wordnet_correlation(valid_en, rho, p)\n",
        "\n",
        "# ── Interpretation ────────────────────────────────────────────\n",
        "print(\"\\n── Interpretation ──\")\n",
        "if stats_result[\"p_value\"] < 0.05:\n",
        "    direction = \"English\" if stats_result[\"en_mean_k\"] > stats_result[\"zh_mean_k\"] else \"Chinese\"\n",
        "    print(f\"  Significant difference found (p={stats_result['p_value']:.4f}).\")\n",
        "    print(f\"  {direction} nouns show higher mean polysemy degree.\")\n",
        "else:\n",
        "    print(f\"  No significant difference found (p={stats_result['p_value']:.4f}).\")\n",
        "\n",
        "d = abs(stats_result[\"cohens_d\"])\n",
        "magnitude = \"small\" if d < 0.2 else (\"medium\" if d < 0.5 else \"large\")\n",
        "print(f\"  Effect size: Cohen's d = {stats_result['cohens_d']:.3f} ({magnitude})\")\n",
        "print(f\"  Spearman ρ (EN WSI vs. WordNet): {rho:.3f} (p={p:.4f})\")\n",
        "\n",
        "print(\"\\n✓ Step 5 complete.\\n\")\n"
      ],
      "metadata": {
        "id": "M1bzCPW5dCC_",
        "outputId": "cadaa7d4-369b-40c9-b314-b492219f209c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Step 5: Validation and Statistical Analysis\n",
            "============================================================\n",
            "  [validate] Looking up Princeton WordNet sense counts…\n",
            "  [validate] EN Spearman ρ(k_ward, WN_senses) = 0.020  p = 0.6191  (n=630)\n",
            "\n",
            "── Statistical Comparison Results ──\n",
            "  en_mean_k             : 3.3459\n",
            "  zh_mean_k             : 3.4738\n",
            "  en_median_k           : 2.0\n",
            "  zh_median_k           : 2.0\n",
            "  en_std_k              : 2.0931\n",
            "  zh_std_k              : 2.2647\n",
            "  U_statistic           : 182813.5\n",
            "  p_value               : 0.864495\n",
            "  CLES                  : 0.5025\n",
            "  cohens_d              : -0.0588\n",
            "  n_en                  : 636\n",
            "  n_zh                  : 572\n",
            "  [fig] Saved: sense_distribution_english.png\n",
            "  [fig] Saved: sense_distribution_chinese.png\n",
            "  [fig] Saved: comparison_violinplot.png\n",
            "  [fig] Saved: wordnet_correlation_en.png\n",
            "\n",
            "── Interpretation ──\n",
            "  No significant difference found (p=0.8645).\n",
            "  Effect size: Cohen's d = -0.059 (small)\n",
            "  Spearman ρ (EN WSI vs. WordNet): 0.020 (p=0.6191)\n",
            "\n",
            "✓ Step 5 complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Qualitative Analysis"
      ],
      "metadata": {
        "id": "O3m1UJnseHjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 6: Qualitative Analysis — Sense Cluster Inspection\n",
        "=========================================================\n",
        "For each polysemous lemma, retrieves representative example verses\n",
        "for each induced sense cluster. This supports the qualitative\n",
        "analysis section of the paper, demonstrating that clusters correspond\n",
        "to meaningful, interpretable senses.\n",
        "\n",
        "Also generates a LaTeX-ready table of top polysemous words\n",
        "for both languages (for paper Table 3).\n",
        "\n",
        "Outputs:\n",
        "  - output/qualitative_en_top_polysemous.txt   (sense examples)\n",
        "  - output/qualitative_zh_top_polysemous.txt\n",
        "  - output/table_top_polysemous_latex.tex       (LaTeX table)\n",
        "  - output/polysemy_profile_comparison.csv      (wide comparison table)\n",
        "\n",
        "Usage:\n",
        "  python 06_qualitative_analysis.py\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "# ─── Configuration ────────────────────────────────────────────────────────────\n",
        "\n",
        "DATA_DIR    = Path(\"/content\") / \"bible_data\"\n",
        "OUTPUT_DIR = Path(\"/content\") / \"output\"\n",
        "# DATA_DIR   = Path(__file__).parent.parent / \"data\"\n",
        "# OUTPUT_DIR = Path(__file__).parent.parent / \"output\"\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "TOP_N_WORDS       = 20   # Top N most polysemous lemmas per language\n",
        "EXAMPLES_PER_SENSE = 2   # Number of example verses per cluster\n",
        "\n",
        "\n",
        "# ─── Sense Example Retrieval ─────────────────────────────────────────────────\n",
        "\n",
        "def get_sense_examples(\n",
        "    lang: str,\n",
        "    top_n: int = TOP_N_WORDS,\n",
        "    examples_per_sense: int = EXAMPLES_PER_SENSE,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    For the top_n most polysemous lemmas, retrieve example contexts\n",
        "    for each induced sense cluster.\n",
        "\n",
        "    Returns a formatted string ready for a paper's qualitative appendix.\n",
        "    \"\"\"\n",
        "    results_df = pd.read_csv(DATA_DIR / f\"{lang}_wsi_results.csv\")\n",
        "    labels_df  = pd.read_csv(DATA_DIR / f\"{lang}_sense_labels.csv\")\n",
        "    nouns_df   = pd.read_csv(DATA_DIR / f\"{lang}_nouns.csv\")\n",
        "\n",
        "    # Top polysemous by k_ward\n",
        "    poly = results_df[results_df[\"k_ward\"] > 1].nlargest(top_n, \"k_ward\")\n",
        "\n",
        "    # Merge labels with original contexts\n",
        "    merged = labels_df.merge(\n",
        "        nouns_df[[\"lemma\", \"verse_id\", \"context\"]].drop_duplicates(),\n",
        "        on=[\"lemma\", \"verse_id\"],\n",
        "        how=\"left\",\n",
        "    )\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"{'='*60}\")\n",
        "    lines.append(f\"QUALITATIVE SENSE ANALYSIS — {lang.upper()}\")\n",
        "    lines.append(f\"Top {top_n} Most Polysemous Nouns (WSI, Ward Clustering)\")\n",
        "    lines.append(f\"{'='*60}\\n\")\n",
        "\n",
        "    for _, row in poly.iterrows():\n",
        "        lemma = row[\"lemma\"]\n",
        "        k     = int(row[\"k_ward\"])\n",
        "        n_occ = int(row[\"n_occurrences\"])\n",
        "        sil   = row.get(\"silhouette_ward\", \"N/A\")\n",
        "\n",
        "        lines.append(f\"Lemma: '{lemma}'  |  k={k}  |  n={n_occ}  |  silhouette={sil}\")\n",
        "        lines.append(\"-\" * 50)\n",
        "\n",
        "        lemma_data = merged[merged[\"lemma\"] == lemma]\n",
        "\n",
        "        for cluster_id in range(k):\n",
        "            cluster_rows = lemma_data[lemma_data[\"cluster_ward\"] == cluster_id]\n",
        "            lines.append(f\"  Sense {cluster_id + 1} ({len(cluster_rows)} occurrences):\")\n",
        "\n",
        "            # Sample diverse examples\n",
        "            sample = cluster_rows.dropna(subset=[\"context\"]).head(examples_per_sense)\n",
        "            for _, ex in sample.iterrows():\n",
        "                ctx = str(ex[\"context\"])[:200].replace(\"\\n\", \" \")\n",
        "                lines.append(f\"    • {ex['verse_id']}: {ctx}\")\n",
        "\n",
        "        lines.append(\"\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# ─── LaTeX Table Generation ──────────────────────────────────────────────────\n",
        "\n",
        "def generate_latex_table(top_n: int = 15) -> str:\n",
        "    \"\"\"\n",
        "    Generate a LaTeX longtable comparing top polysemous nouns in both languages.\n",
        "    Format:\n",
        "      Rank | English Lemma | EN k | Chinese Lemma | ZH k\n",
        "    \"\"\"\n",
        "    en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "    zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "    en_top = en.nlargest(top_n, \"k_ward\")[[\"lemma\", \"k_ward\", \"n_occurrences\"]].reset_index(drop=True)\n",
        "    zh_top = zh.nlargest(top_n, \"k_ward\")[[\"lemma\", \"k_ward\", \"n_occurrences\"]].reset_index(drop=True)\n",
        "\n",
        "    lines = [\n",
        "        r\"\\begin{table}[h]\",\n",
        "        r\"\\centering\",\n",
        "        r\"\\caption{Top Polysemous Common Nouns by Induced Sense Count (k): English vs. Chinese}\",\n",
        "        r\"\\label{tab:top_polysemous}\",\n",
        "        r\"\\begin{tabular}{clccclcc}\",\n",
        "        r\"\\toprule\",\n",
        "        r\"Rank & English Lemma & EN $k$ & EN $n$ & & Chinese Lemma & ZH $k$ & ZH $n$ \\\\\",\n",
        "        r\"\\midrule\",\n",
        "    ]\n",
        "\n",
        "    for i in range(top_n):\n",
        "        en_row = en_top.iloc[i] if i < len(en_top) else None\n",
        "        zh_row = zh_top.iloc[i] if i < len(zh_top) else None\n",
        "\n",
        "        en_lemma = en_row[\"lemma\"]                  if en_row is not None else \"\"\n",
        "        en_k     = int(en_row[\"k_ward\"])            if en_row is not None else \"\"\n",
        "        en_n     = int(en_row[\"n_occurrences\"])     if en_row is not None else \"\"\n",
        "        zh_lemma = zh_row[\"lemma\"]                  if zh_row is not None else \"\"\n",
        "        zh_k     = int(zh_row[\"k_ward\"])            if zh_row is not None else \"\"\n",
        "        zh_n     = int(zh_row[\"n_occurrences\"])     if zh_row is not None else \"\"\n",
        "\n",
        "        lines.append(\n",
        "            f\"{i+1} & {en_lemma} & {en_k} & {en_n} & & {zh_lemma} & {zh_k} & {zh_n} \\\\\\\\\"\n",
        "        )\n",
        "\n",
        "    lines += [\n",
        "        r\"\\bottomrule\",\n",
        "        r\"\\end{tabular}\",\n",
        "        r\"\\end{table}\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# ─── Wide Comparison Profile ─────────────────────────────────────────────────\n",
        "\n",
        "def generate_comparison_profile() -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create a summary comparison table for paper Table 2.\n",
        "    \"\"\"\n",
        "    en = pd.read_csv(DATA_DIR / \"english_wsi_results.csv\")\n",
        "    zh = pd.read_csv(DATA_DIR / \"chinese_wsi_results.csv\")\n",
        "\n",
        "    def profile(df: pd.DataFrame, lang: str) -> dict:\n",
        "        return {\n",
        "            \"Language\":            lang,\n",
        "            \"Total lemmas\":        len(df),\n",
        "            \"Mean k (Ward)\":       round(df[\"k_ward\"].mean(), 3),\n",
        "            \"Median k (Ward)\":     round(df[\"k_ward\"].median(), 3),\n",
        "            \"Std k (Ward)\":        round(df[\"k_ward\"].std(ddof=1), 3),\n",
        "            \"% Monosemous (k=1)\":  round((df[\"k_ward\"] == 1).mean() * 100, 1),\n",
        "            \"% Polysemous (k>1)\":  round((df[\"k_ward\"] > 1).mean() * 100, 1),\n",
        "            \"Max k\":               int(df[\"k_ward\"].max()),\n",
        "            \"Mean k (KMeans)\":     round(df[\"k_kmeans\"].mean(), 3),\n",
        "            \"Agreement (Ward=KM)\": round((df[\"k_ward\"] == df[\"k_kmeans\"]).mean() * 100, 1),\n",
        "        }\n",
        "\n",
        "    rows = [profile(en, \"English\"), profile(zh, \"Chinese\")]\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ─── Main ─────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# def main():\n",
        "#     print(\"=\" * 60)\n",
        "#     print(\"Step 6: Qualitative Analysis\")\n",
        "#     print(\"=\" * 60)\n",
        "\n",
        "#     # ── Sense examples ────────────────────────────────────────────\n",
        "#     for lang in [\"english\", \"chinese\"]:\n",
        "#         text = get_sense_examples(lang)\n",
        "#         out  = OUTPUT_DIR / f\"qualitative_{lang}_top_polysemous.txt\"\n",
        "#         out.write_text(text, encoding=\"utf-8\")\n",
        "#         print(f\"  [saved] {out.name}\")\n",
        "\n",
        "#     # ── LaTeX table ───────────────────────────────────────────────\n",
        "#     latex = generate_latex_table(top_n=15)\n",
        "#     tex_path = OUTPUT_DIR / \"table_top_polysemous_latex.tex\"\n",
        "#     tex_path.write_text(latex, encoding=\"utf-8\")\n",
        "#     print(f\"  [saved] {tex_path.name}\")\n",
        "\n",
        "#     # ── Comparison profile ────────────────────────────────────────\n",
        "#     profile = generate_comparison_profile()\n",
        "#     csv_path = OUTPUT_DIR / \"polysemy_profile_comparison.csv\"\n",
        "#     profile.to_csv(csv_path, index=False)\n",
        "#     print(f\"  [saved] {csv_path.name}\")\n",
        "#     print()\n",
        "#     print(profile.to_string(index=False))\n",
        "\n",
        "#     print(\"\\n✓ Step 6 complete.\\n\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "d6Rm4f_vdq7A"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Step 6: Qualitative Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ── Sense examples ────────────────────────────────────────────\n",
        "for lang in [\"english\", \"chinese\"]:\n",
        "    text = get_sense_examples(lang)\n",
        "    out  = OUTPUT_DIR / f\"qualitative_{lang}_top_polysemous.txt\"\n",
        "    out.write_text(text, encoding=\"utf-8\")\n",
        "    print(f\"  [saved] {out.name}\")\n",
        "\n",
        "# ── LaTeX table ───────────────────────────────────────────────\n",
        "latex = generate_latex_table(top_n=15)\n",
        "tex_path = OUTPUT_DIR / \"table_top_polysemous_latex.tex\"\n",
        "tex_path.write_text(latex, encoding=\"utf-8\")\n",
        "print(f\"  [saved] {tex_path.name}\")\n",
        "\n",
        "# ── Comparison profile ────────────────────────────────────────\n",
        "profile = generate_comparison_profile()\n",
        "csv_path = OUTPUT_DIR / \"polysemy_profile_comparison.csv\"\n",
        "profile.to_csv(csv_path, index=False)\n",
        "print(f\"  [saved] {csv_path.name}\")\n",
        "print()\n",
        "print(profile.to_string(index=False))\n",
        "\n",
        "print(\"\\n✓ Step 6 complete.\\n\")\n"
      ],
      "metadata": {
        "id": "K9Gd4DVWeOYw",
        "outputId": "0cd1de50-bf1b-4cc6-8eef-b8768586a79b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Step 6: Qualitative Analysis\n",
            "============================================================\n",
            "  [saved] qualitative_english_top_polysemous.txt\n",
            "  [saved] qualitative_chinese_top_polysemous.txt\n",
            "  [saved] table_top_polysemous_latex.tex\n",
            "  [saved] polysemy_profile_comparison.csv\n",
            "\n",
            "Language  Total lemmas  Mean k (Ward)  Median k (Ward)  Std k (Ward)  % Monosemous (k=1)  % Polysemous (k>1)  Max k  Mean k (KMeans)  Agreement (Ward=KM)\n",
            " English           636          3.346              2.0         2.093                 0.0               100.0      8            3.264                 81.4\n",
            " Chinese           572          3.474              2.0         2.265                 0.0               100.0      8            3.318                 78.7\n",
            "\n",
            "✓ Step 6 complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output.zip /content/output/"
      ],
      "metadata": {
        "id": "wnUe-3lgedhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r nt_data_niv_cuv.zip /content/bible_data/"
      ],
      "metadata": {
        "id": "Pj8aPu8Cfp1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9fDlK00Gf0Pn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}